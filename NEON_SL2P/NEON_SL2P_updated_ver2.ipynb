{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Part A: Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## SETUP 1: Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " LEAFToolbox - SL2P \n",
    " This notebook contains code blocks to run SL2P based on three different inputs, which are as follows:\n",
    "1. using SL2p 20m net and 10m net for processing NEON simulated data-output 10m result\n",
    "2. using SL2p 20m net for processing NEON simulated data-input 20m, output 20m result1\n",
    "3. using SL2p 20m net and 10m net for processing DSen2 data-input 10m, output 10m result\n",
    "4. using SL2p 20m net and 10m net for processing S2, 20m net output -20m, 10m net output -10m\n",
    "5. ALR estimate (input 10m band, output 10m, no nueral network net used in this procedure) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ee\n",
    "import time\n",
    "import math\n",
    "import csv\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import folium ; from folium import plugins\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy ; from scipy import stats\n",
    "import scipy.io as sio\n",
    "import sklearn as skl ; from sklearn import linear_model ; from sklearn import preprocessing\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "from collections import OrderedDict\n",
    "from sklearn.metrics import mean_squared_error \n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# import custom modules (files must be in same directory as this notebook)\n",
    "import module.feature_collections as fc\n",
    "import module.image_bands as ib\n",
    "import module.wrapper_nets as wn\n",
    "import module.ee_functions as ee_func\n",
    "import module.ALR_functions as alr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p>To authorize access needed by Earth Engine, open the following\n",
       "        URL in a web browser and follow the instructions:</p>\n",
       "        <p><a href=https://code.earthengine.google.com/client-auth?scopes=https%3A//www.googleapis.com/auth/earthengine%20https%3A//www.googleapis.com/auth/devstorage.full_control&request_id=4b3qyf71sGN8Cmb_SoMaFL-896PGFqWyOs3IcT1nwcA&tc=-Z_aBuyL73_8vFqPNiTxVxiKzPVO3VFa9h9yl8vCcL0&cc=pxy548tNkg8UM-lhK8neVb3OulwTdiwlVeAR7cpYsyc>https://code.earthengine.google.com/client-auth?scopes=https%3A//www.googleapis.com/auth/earthengine%20https%3A//www.googleapis.com/auth/devstorage.full_control&request_id=4b3qyf71sGN8Cmb_SoMaFL-896PGFqWyOs3IcT1nwcA&tc=-Z_aBuyL73_8vFqPNiTxVxiKzPVO3VFa9h9yl8vCcL0&cc=pxy548tNkg8UM-lhK8neVb3OulwTdiwlVeAR7cpYsyc</a></p>\n",
       "        <p>The authorization workflow will generate a code, which you should paste in the box below.</p>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter verification code:  4/1AVHEtk7FJu8sMEFaK7EAPVbhRqYV3Hi4GZW1LJf8fGLRq6Dwuoj8G1gJm3k\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Successfully saved authorization token.\n"
     ]
    }
   ],
   "source": [
    "ee.Authenticate()\n",
    "ee.Initialize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## SETUP 2: Define dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------\n",
    "# SELECT INPUT PARAMETERS\n",
    "# -----------------------\n",
    "\n",
    "# variable name\n",
    "# one of: 'fAPAR', 'fCOVER', 'LAI'\n",
    "#outputName = 'LAI'\n",
    "outputName = 'LAI'\n",
    "\n",
    "# site selection\n",
    "# one of: 'Geraldton', 'FoxCreek', 'Kouchibouguac', 'Ottawa',\n",
    "#         'Wabush', 'QueenCharlotte', 'Attawapiskat', 'Eastmain', 'Charlottetown', 'RedBay', 'EaglePlain', 'Kitchener'\n",
    "#siteSelect = 'Charlottetown'\n",
    "siteSelect = 'HOPB'\n",
    "#ABBY, HOPB, SERC, STEI, UNDE, MCDI,LENO, NOGP,JORN, SJER\n",
    "\n",
    "# assetfolder='users/GangHong2/NEON'\n",
    "\n",
    "assetfolder_REF  = 'users/ccrs12fy2022simha/DOWNSCALING_PROCESS/1_NEON10/REF'\n",
    "assetfolder_NULL  ='users/ccrs12fy2022simha/DOWNSCALING_PROCESS/2_NEON20/NULL'\n",
    "\n",
    "assetfolder_SOL_A  ='users/ccrs12fy2022simha/DOWNSCALING_PROCESS/3_DSEN2_S2/SOL_A'\n",
    "assetfolder_SOL_B  ='users/ccrs12fy2022simha/DOWNSCALING_PROCESS/1_NEON10/SOL_B'\n",
    "assetfolder_SOL_C  ='users/ccrs12fy2022simha/DOWNSCALING_PROCESS/5_ALR/SOL_C'\n",
    "\n",
    "assetfolder_RES_D  ='users/ccrs12fy2022simha/DOWNSCALING_PROCESS/3_DSEN2_S2/RES_D'\n",
    "assetfolder_RES_E  ='users/ccrs12fy2022simha/DOWNSCALING_PROCESS/4_S2/RES_E'\n",
    "assetfolder_RES_F  ='users/ccrs12fy2022simha/DOWNSCALING_PROCESS/4_S2/RES_F'\n",
    "\n",
    "assetfolder_SOL_C_U  ='users/ccrs12fy2022simha/DOWNSCALING_PROCESS/5_ALR/SOL_C_U'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# -----------------------------------------------------\n",
    "# set parameters based on user-defined parameters above\n",
    "# -----------------------------------------------------\n",
    "outputParams = {\n",
    "    'fAPAR': {\n",
    "        'outputScale': 1000,\n",
    "        'outputOffset': 0,\n",
    "        'outputMax': 1\n",
    "    },\n",
    "    'fCOVER': {\n",
    "        'outputScale': 1000,\n",
    "        'outputOffset': 0,\n",
    "        'outputMax': 1\n",
    "    },\n",
    "    'LAI': {\n",
    "        'outputScale': 1000,\n",
    "        'outputOffset': 0,\n",
    "        'outputMax': 8\n",
    "    }\n",
    "}\n",
    "\n",
    "outputScale = outputParams[outputName]['outputScale']\n",
    "outputOffset = outputParams[outputName]['outputOffset']\n",
    "outputMax = outputParams[outputName]['outputMax']\n",
    "responseBand = 'estimate'+outputName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "siteParams = {\n",
    "    # # Geraldton, ON\n",
    "    # 'Geraldton': {\n",
    "    #     'testImage': ee.Image('COPERNICUS/S2_SR/20200811T164849_20200811T165525_T16UEA'),\n",
    "    #     'mapBounds': ee.Geometry.Polygon( \\\n",
    "    #                     [[[-86, 49.5], \\\n",
    "    #                       [-86, 50], \\\n",
    "    #                       [-85.5, 50], \\\n",
    "    #                       [-85.5, 49.5]]]),\n",
    "    #     'mapCenter': [-85.75, 49.75]\n",
    "    # },\n",
    "    # # Fox Creek, AB\n",
    "    # 'FoxCreek': {\n",
    "    #     'testImage': ee.Image('COPERNICUS/S2_SR/20210825T185919_20210825T190431_T11UNA'),\n",
    "    #     'mapBounds': ee.Geometry.Polygon( \\\n",
    "    #                     [[[-117, 54], \\\n",
    "    #                       [-117, 55], \\\n",
    "    #                       [-115, 55], \\\n",
    "    #                       [-115, 54]]]),\n",
    "    #     'mapCenter': [-116.8, 54.4]\n",
    "    # },\n",
    "    # # Kouchibouguac, NB\n",
    "    # 'Kouchibouguac': {\n",
    "    #     'testImage': ee.Image('COPERNICUS/S2_SR/20200905T151701_20200905T151829_T20TLS'),\n",
    "    #     'mapBounds': ee.Geometry.Polygon( \\\n",
    "    #                     [[[-65, 46], \\\n",
    "    #                       [-65, 47], \\\n",
    "    #                       [-64, 47], \\\n",
    "    #                       [-64, 46]]]),\n",
    "    #     'mapCenter': [-64.5, 46.5]\n",
    "    # },\n",
    "    # # Ottawa, ON\n",
    "    # 'Ottawa': {\n",
    "    #     'testImage': ee.Image('COPERNICUS/S2_SR/20200801T155911_20200801T160644_T18TVQ'),\n",
    "    #     'mapBounds': ee.Geometry.Polygon( \\\n",
    "    #                     [[[-75, 45], \\\n",
    "    #                       [-75, 46], \\\n",
    "    #                       [-74, 46], \\\n",
    "    #                       [-74, 45]]]),\n",
    "    #     'mapCenter': [-74.5, 45.5]\n",
    "    # },\n",
    "    # # Wabush, NL\n",
    "    # 'Wabush': {\n",
    "    #     'testImage': ee.Image('COPERNICUS/S2_SR/20200815T153911_20200815T154107_T19UFU'),\n",
    "    #     'mapBounds': ee.Geometry.Polygon( \\\n",
    "    #                     [[[-67.5, 52.3], \\\n",
    "    #                       [-67.5, 53.2], \\\n",
    "    #                       [-66.3, 53.2], \\\n",
    "    #                       [-66.3, 52.3]]]),\n",
    "    #     'mapCenter': [-67, 52.8]\n",
    "    # },\n",
    "    # # Queen Charlotte Island, BC\n",
    "    # 'QueenCharlotte': {\n",
    "    #     'testImage': ee.Image('COPERNICUS/S2_SR/20200909T194951_20200909T195633_T08UPE'),\n",
    "    #     'mapBounds': ee.Geometry.Polygon( \\\n",
    "    #                     [[[-133, 53.2], \\\n",
    "    #                       [-133, 54], \\\n",
    "    #                       [-132, 54], \\\n",
    "    #                       [-132, 53.2]]]),\n",
    "    #     'mapCenter': [-132.4, 53.6]\n",
    "    # },\n",
    "    # # Attawapiskat, ON\n",
    "    # 'Attawapiskat': {\n",
    "    #     'testImage': ee.Image('COPERNICUS/S2_SR/20200815T162839_20200815T163731_T17ULU'),\n",
    "    #     'mapBounds': ee.Geometry.Polygon( \\\n",
    "    #                     [[[-83, 52.3], \\\n",
    "    #                       [-83, 53.2], \\\n",
    "    #                       [-82.4, 53.2], \\\n",
    "    #                       [-82.4, 52.3]]]),\n",
    "    #     'mapCenter': [-82.7, 52.7]\n",
    "    # },\n",
    "    # # Eastmain, QC\n",
    "    # 'Eastmain': {\n",
    "    #     'testImage': ee.Image('COPERNICUS/S2_SR/20200723T161829_20200723T162656_T17UPT'),\n",
    "    #     'mapBounds': ee.Geometry.Polygon( \\\n",
    "    #                     [[[-79.5, 51.4], \\\n",
    "    #                       [-79.5, 52.3], \\\n",
    "    #                       [-78, 52.3], \\\n",
    "    #                       [-78, 51.4]]]),\n",
    "    #     'mapCenter': [-78.7, 51.8]\n",
    "    # },\n",
    "    # # Charlottetown, PEI\n",
    "    # 'Charlottetown': {\n",
    "    #     'testImage': ee.Image('COPERNICUS/S2_SR/20200622T151659_20200622T151653_T20TMS'),\n",
    "    #     'mapBounds': ee.Geometry.Polygon( \\\n",
    "    #                     [[[-63.3, 46.1], \\\n",
    "    #                       [-63.3, 46.5], \\\n",
    "    #                       [-62.9, 46.5], \\\n",
    "    #                       [-62.9, 46.1]]]),\n",
    "    #     'mapCenter': [-63.1, 46.3]\n",
    "    # },\n",
    "    # # Red Bay, NL\n",
    "    # 'RedBay': {\n",
    "    #     'testImage': ee.Image('COPERNICUS/S2_SR/20200716T145729_20200716T145730_T21UWT'),\n",
    "    #     'mapBounds': ee.Geometry.Polygon( \\\n",
    "    #                     [[[-56.6, 51.6], \\\n",
    "    #                       [-56.6, 52.3], \\\n",
    "    #                       [-55.6, 52.3], \\\n",
    "    #                       [-56.6, 51.6]]]),\n",
    "    #     'mapCenter': [-56, 52]\n",
    "    # },\n",
    "    # # Eagle Plain, YT\n",
    "    # 'EaglePlain': {\n",
    "    #     'testImage': ee.Image('COPERNICUS/S2_SR/20200731T204019_20200731T204021_T08WMU'),\n",
    "    #     'mapBounds': ee.Geometry.Polygon( \\\n",
    "    #                     [[[-137, 65.75], \\\n",
    "    #                       [-137, 66.5], \\\n",
    "    #                       [-135, 66.5], \\\n",
    "    #                       [-135, 65.75]]]),\n",
    "    #     'mapCenter': [-136.3, 66.5]\n",
    "    # },\n",
    "    # # Kitchener, ON\n",
    "    # 'Kitchener': {\n",
    "    #     'testImage': ee.Image('COPERNICUS/S2_SR/20200615T160911_20200615T161838_T17TNJ'),\n",
    "    #     'mapBounds': ee.Geometry.Polygon( \\\n",
    "    #                     [[[-81, 43.3], \\\n",
    "    #                       [-81, 44], \\\n",
    "    #                       [-79.8, 44], \\\n",
    "    #                       [-79.8, 43.3]]]),\n",
    "    #     'mapCenter': [-80.5, 43.7]\n",
    "    # },\n",
    "    # ABBY\n",
    "    'ABBY': {\n",
    "        'testImage': ee.Image(\"users/GangHong2/NEON_D16_ABBY_DP1_20210719_191207_reflectance_10m\"),\n",
    "        'mapBounds': ee.Image(\"users/GangHong2/NEON_D16_ABBY_DP1_20210719_191207_reflectance_10m\").geometry()\n",
    "        # 'mapCenter': [-80.5, 43.7]\n",
    "     },\n",
    "    'HOPB': {\n",
    "        'testImage': ee.Image(\"users/GangHong2/NEON_D01_HOPB_DP1_20190826_172857_reflectance_10m\"),\n",
    "        'mapBounds': ee.Image(\"users/GangHong2/NEON_D01_HOPB_DP1_20190826_172857_reflectance_10m\").geometry()\n",
    "        # 'mapCenter': [-80.5, 43.7]\n",
    "    },\n",
    "    'SERC': {\n",
    "        'testImage': ee.Image(\"users/GangHong2/NEON_D02_SERC_DP1_20210811_142655_reflectance_10m\"),\n",
    "        'mapBounds': ee.Image(\"users/GangHong2/NEON_D02_SERC_DP1_20210811_142655_reflectance_10m\").geometry()\n",
    "        # 'mapCenter': [-80.5, 43.7]\n",
    "    },\n",
    "    'STEI': {\n",
    "        'testImage': ee.Image(\"users/GangHong2/NEON_D05_STEI_DP1_20190608_194643_reflectance_10m\"),\n",
    "        'mapBounds': ee.Image(\"users/GangHong2/NEON_D05_STEI_DP1_20190608_194643_reflectance_10m\").geometry()\n",
    "        # 'mapCenter': [-80.5, 43.7]\n",
    "    },\n",
    "    'UNDE': {\n",
    "        'testImage': ee.Image(\"users/GangHong2/NEON_D05_UNDE_DP1_20190606_184411_reflectance_10m\"),\n",
    "        'mapBounds': ee.Image(\"users/GangHong2/NEON_D05_UNDE_DP1_20190606_184411_reflectance_10m\").geometry()\n",
    "        # 'mapCenter': [-80.5, 43.7]\n",
    "    },\n",
    "    'MCDI': {\n",
    "        'testImage': ee.Image(\"users/GangHong2/NEON_D06_MCDI_DP1_20200713_192937_reflectance_10m\"),\n",
    "        'mapBounds': ee.Image(\"users/GangHong2/NEON_D06_MCDI_DP1_20200713_192937_reflectance_10m\").geometry()\n",
    "        # 'mapCenter': [-80.5, 43.7]\n",
    "    },\n",
    "    'LENO': {\n",
    "        'testImage': ee.Image(\"users/GangHong2/NEON_D08_LENO_DP1_20210422_172136_reflectance_10m\"),\n",
    "        'mapBounds': ee.Image(\"users/GangHong2/NEON_D08_LENO_DP1_20210422_172136_reflectance_10m\").geometry()\n",
    "        # 'mapCenter': [-80.5, 43.7]\n",
    "    },  \\\n",
    "    'NOGP': {\n",
    "        'testImage': ee.Image(\"users/GangHong2/NEON_D09_NOGP_DP1_20200626_152700_reflectance_10m\"),\n",
    "        'mapBounds': ee.Image(\"users/GangHong2/NEON_D09_NOGP_DP1_20200626_152700_reflectance_10m\").geometry()\n",
    "        # 'mapCenter': [-80.5, 43.7]\n",
    "    },\n",
    "    'JORN': {\n",
    "        'testImage': ee.Image(\"users/GangHong2/NEON_D14_JORN_DP1_20190825_165611_reflectance_10m\"),\n",
    "        'mapBounds': ee.Image(\"users/GangHong2/NEON_D14_JORN_DP1_20190825_165611_reflectance_10m\").geometry()\n",
    "        # 'mapCenter': [-80.5, 43.7]\n",
    "    },\n",
    "    'WREF': {\n",
    "        'testImage': ee.Image(\"users/GangHong2/NEON_D16_WREF_DP1_20190712_173947_reflectance_10m\"),\n",
    "        'mapBounds': ee.Image(\"users/GangHong2/NEON_D16_WREF_DP1_20190712_173947_reflectance_10m\").geometry()\n",
    "        # 'mapCenter': [-80.5, 43.7]\n",
    "    },\n",
    "    'SJER': {\n",
    "        'testImage': ee.Image(\"users/GangHong2/NEON_D17_SJER_DP1_20210331_200812_reflectance_10m\"),\n",
    "        'mapBounds': ee.Image(\"users/GangHong2/NEON_D17_SJER_DP1_20210331_200812_reflectance_10m\").geometry()\n",
    "        # 'mapCenter': [-80.5, 43.7]\n",
    "    }\n",
    "}\n",
    "# all other sites, just follow the site 'ABBY' to add new sites\n",
    "# users/GangHong2/NEON_D01_HOPB_DP1_20190826_172857_reflectance_10m\n",
    "# users/GangHong2/NEON_D02_SERC_DP1_20210811_142655_reflectance_10m\n",
    "# users/GangHong2/NEON_D05_STEI_DP1_20190608_194643_reflectance_10m\n",
    "# users/GangHong2/NEON_D05_UNDE_DP1_20190606_184411_reflectance_10m\n",
    "# users/GangHong2/NEON_D06_MCDI_DP1_20200713_192937_reflectance_10m\n",
    "# users/GangHong2/NEON_D08_LENO_DP1_20210422_172136_reflectance_10m\n",
    "# users/GangHong2/NEON_D09_NOGP_DP1_20190722_170025_reflectance_10m\n",
    "# users/GangHong2/NEON_D14_JORN_DP1_20190825_165611_reflectance_10m\n",
    "# users/GangHong2/NEON_D16_WREF_DP1_20190712_173947_reflectance_10m\n",
    "# users/GangHong2/NEON_D17_SJER_DP1_20210331_200812_reflectance_10m\n",
    "\n",
    "\n",
    "mapBounds = siteParams[siteSelect]['mapBounds']\n",
    "# mapCenter = siteParams[siteSelect]['mapCenter']\n",
    "testImage = siteParams[siteSelect]['testImage']\n",
    "\n",
    "# other filters\n",
    "# maxCloudcover = 10\n",
    "\n",
    "# export parameters\n",
    "exportFolder = siteSelect+'_'+outputName\n",
    "exportDataType = 'int'\n",
    "exportScale = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "COLLECTION_OPTIONS = {\n",
    "    # Sentinel 2 using 20 m bands:\n",
    "    'COPERNICUS/S2_SR': {\n",
    "      \"name\": 'COPERNICUS/S2_SR',\n",
    "      \"description\": 'Sentinel 2A',\n",
    "      \"Cloudcover\": 'CLOUDY_PIXEL_PERCENTAGE',\n",
    "      \"Watercover\": 'WATER_PERCENTAGE',\n",
    "      \"sza\": 'MEAN_SOLAR_ZENITH_ANGLE',\n",
    "      \"vza\": 'MEAN_INCIDENCE_ZENITH_ANGLE_B8A',\n",
    "      \"saa\": 'MEAN_SOLAR_AZIMUTH_ANGLE', \n",
    "      \"vaa\": 'MEAN_INCIDENCE_AZIMUTH_ANGLE_B8A',\n",
    "      \"VIS_OPTIONS\": 'VIS_OPTIONS',\n",
    "      \"Collection_SL2P\": ee.FeatureCollection(fc.s2_createFeatureCollection_estimates()),\n",
    "      \"Collection_SL2Perrors\": ee.FeatureCollection(fc.s2_createFeatureCollection_errors()),  \n",
    "      \"sl2pDomain\": ee.FeatureCollection(fc.s2_createFeatureCollection_domains()),\n",
    "      \"Network_Ind\": ee.FeatureCollection(fc.s2_createFeatureCollection_Network_Ind()),\n",
    "      \"partition\": ee.ImageCollection(fc.s2_createImageCollection_partition()),\n",
    "      \"legend\": ee.FeatureCollection(fc.s2_createFeatureCollection_legend()),\n",
    "      \"numVariables\": 7\n",
    "    },\n",
    "    # Sentinel 2 using 10 m bands:\n",
    "    'COPERNICUS/S2_SR_10m': {\n",
    "      \"name\": 'COPERNICUS/S2_SR',\n",
    "      \"description\": 'Sentinel 2A',\n",
    "      \"Cloudcover\": 'CLOUDY_PIXEL_PERCENTAGE',\n",
    "      \"Watercover\": 'WATER_PERCENTAGE',\n",
    "      \"sza\": 'MEAN_SOLAR_ZENITH_ANGLE',\n",
    "      \"vza\": 'MEAN_INCIDENCE_ZENITH_ANGLE_B8A',\n",
    "      \"saa\": 'MEAN_SOLAR_AZIMUTH_ANGLE', \n",
    "      \"vaa\": 'MEAN_INCIDENCE_AZIMUTH_ANGLE_B8A',\n",
    "      \"VIS_OPTIONS\": 'VIS_OPTIONS',\n",
    "      \"Collection_SL2P\": ee.FeatureCollection(fc.s2_10m_createFeatureCollection_estimates()),\n",
    "      \"Collection_SL2Perrors\": ee.FeatureCollection(fc.s2_10m_createFeatureCollection_errors()),  \n",
    "      \"sl2pDomain\": ee.FeatureCollection(fc.s2_10m_createFeatureCollection_domains()),\n",
    "      \"Network_Ind\": ee.FeatureCollection(fc.s2_createFeatureCollection_Network_Ind()),\n",
    "      \"partition\": ee.ImageCollection(fc.s2_createImageCollection_partition()),\n",
    "      \"legend\": ee.FeatureCollection(fc.s2_createFeatureCollection_legend()),\n",
    "      \"numVariables\": 7\n",
    "    },\n",
    "    # Sentinel 2 using 10 m bands:\n",
    "    'NEON_Sim_10m': {\n",
    "      \"name\": 'NEON_Sim_10m',\n",
    "      \"description\": 'NEON Simulated',\n",
    "      # \"Cloudcover\": 'CLOUDY_PIXEL_PERCENTAGE',\n",
    "      # \"Watercover\": 'WATER_PERCENTAGE',\n",
    "      # \"sza\": 'MEAN_SOLAR_ZENITH_ANGLE',\n",
    "      # \"vza\": 'MEAN_INCIDENCE_ZENITH_ANGLE_B8A',\n",
    "      # \"saa\": 'MEAN_SOLAR_AZIMUTH_ANGLE', \n",
    "      # \"vaa\": 'MEAN_INCIDENCE_AZIMUTH_ANGLE_B8A',\n",
    "      \"VIS_OPTIONS\": 'VIS_OPTIONS',\n",
    "      \"Collection_SL2P\": ee.FeatureCollection(fc.s2_10m_createFeatureCollection_estimates()),\n",
    "      \"Collection_SL2Perrors\": ee.FeatureCollection(fc.s2_10m_createFeatureCollection_errors()),  \n",
    "      \"sl2pDomain\": ee.FeatureCollection(fc.s2_10m_createFeatureCollection_domains()),\n",
    "      \"Network_Ind\": ee.FeatureCollection(fc.s2_createFeatureCollection_Network_Ind()),\n",
    "      \"partition\": ee.ImageCollection(fc.s2_createImageCollection_partition()),\n",
    "      \"legend\": ee.FeatureCollection(fc.s2_createFeatureCollection_legend()),\n",
    "      \"numVariables\": 7\n",
    "    },\n",
    "     'NEON_Sim': {\n",
    "      \"name\": 'COPERNICUS/S2_SR',\n",
    "      \"description\": 'Sentinel 2A',\n",
    "      # \"Cloudcover\": 'CLOUDY_PIXEL_PERCENTAGE',\n",
    "      # \"Watercover\": 'WATER_PERCENTAGE',\n",
    "      # \"sza\": 'MEAN_SOLAR_ZENITH_ANGLE',\n",
    "      # \"vza\": 'MEAN_INCIDENCE_ZENITH_ANGLE_B8A',\n",
    "      # \"saa\": 'MEAN_SOLAR_AZIMUTH_ANGLE', \n",
    "      # \"vaa\": 'MEAN_INCIDENCE_AZIMUTH_ANGLE_B8A',\n",
    "      \"VIS_OPTIONS\": 'VIS_OPTIONS',\n",
    "      \"Collection_SL2P\": ee.FeatureCollection(fc.s2_createFeatureCollection_estimates()),\n",
    "      \"Collection_SL2Perrors\": ee.FeatureCollection(fc.s2_createFeatureCollection_errors()),  \n",
    "      \"sl2pDomain\": ee.FeatureCollection(fc.s2_createFeatureCollection_domains()),\n",
    "      \"Network_Ind\": ee.FeatureCollection(fc.s2_createFeatureCollection_Network_Ind()),\n",
    "      \"partition\": ee.ImageCollection(fc.s2_createImageCollection_partition()),\n",
    "      \"legend\": ee.FeatureCollection(fc.s2_createFeatureCollection_legend()),\n",
    "      \"numVariables\": 7\n",
    "    },\n",
    "}\n",
    "\n",
    "VIS_OPTIONS = {\n",
    "    'fAPAR': {\n",
    "        \"COPERNICUS/S2_SR\": {\n",
    "            \"Name\": 'fAPAR',\n",
    "            \"errorName\": 'errorfAPAR',\n",
    "            \"maskName\": 'maskfAPAR',\n",
    "            \"description\": 'Fraction of absorbed photosynthetically active radiation',\n",
    "            \"variable\": 2,\n",
    "            \"inputBands\":      ['cosVZA', 'cosSZA', 'cosRAA', 'B3', 'B4', 'B5', 'B6', 'B7', 'B8A', 'B11', 'B12'],\n",
    "            \"inputScaling\":    [0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001],\n",
    "            \"outmin\": (ee.Image(ee.Array([[0]]))),\n",
    "            \"outmax\": (ee.Image(ee.Array([[1]])))\n",
    "        },\n",
    "        \"COPERNICUS/S2_SR_10m\": {\n",
    "            \"Name\": 'fAPAR',\n",
    "            \"errorName\": 'errorfAPAR',\n",
    "            \"maskName\": 'maskfAPAR',\n",
    "            \"description\": 'Fraction of absorbed photosynthetically active radiation',\n",
    "            \"variable\": 2,\n",
    "            \"inputBands\":      ['cosVZA', 'cosSZA', 'cosRAA', 'B2', 'B3', 'B4', 'B8'],\n",
    "            \"inputScaling\":    [0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001],\n",
    "            \"outmin\": (ee.Image(ee.Array([[0]]))),\n",
    "            \"outmax\": (ee.Image(ee.Array([[1]])))\n",
    "        },\n",
    "         \"NEON_Sim_10m\": {\n",
    "            \"Name\": 'fAPAR',\n",
    "            \"errorName\": 'errorfAPAR',\n",
    "            \"maskName\": 'maskfAPAR',\n",
    "            \"description\": 'Fraction of absorbed photosynthetically active radiation',\n",
    "            \"variable\": 2,\n",
    "            \"inputBands\":      ['cosVZA', 'cosSZA', 'cosRAA', 'B2', 'B3', 'B4', 'B8'],\n",
    "            \"inputScaling\":    [1, 1, 1, 1, 1, 1, 1],\n",
    "            \"outmin\": (ee.Image(ee.Array([[0]]))),\n",
    "            \"outmax\": (ee.Image(ee.Array([[1]])))\n",
    "        },\n",
    "         \"NEON_Sim\": {\n",
    "            \"Name\": 'fAPAR',\n",
    "            \"errorName\": 'errorfAPAR',\n",
    "            \"maskName\": 'maskfAPAR',\n",
    "            \"description\": 'Fraction of absorbed photosynthetically active radiation',\n",
    "            \"variable\": 2,\n",
    "            \"inputBands\":      ['cosVZA', 'cosSZA', 'cosRAA', 'B3', 'B4', 'B5', 'B6', 'B7', 'B8A', 'B11', 'B12'],\n",
    "            \"inputScaling\":    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
    "            \"outmin\": (ee.Image(ee.Array([[0]]))),\n",
    "            \"outmax\": (ee.Image(ee.Array([[1]])))\n",
    "        },\n",
    "    },\n",
    "    'fCOVER': {\n",
    "        \"COPERNICUS/S2_SR\": {\n",
    "            \"Name\": 'fCOVER',\n",
    "            \"errorName\": 'errorfCOVER',\n",
    "            \"maskName\": 'maskfCOVER',\n",
    "            \"description\": 'Fraction of canopy cover',\n",
    "            \"variable\": 3,\n",
    "            \"inputBands\":      ['cosVZA', 'cosSZA', 'cosRAA', 'B3', 'B4', 'B5', 'B6', 'B7', 'B8A', 'B11', 'B12'],\n",
    "            \"inputScaling\":    [0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001],\n",
    "            \"outmin\": (ee.Image(ee.Array([[0]]))),\n",
    "            \"outmax\": (ee.Image(ee.Array([[1]]))) \n",
    "        },\n",
    "        \"COPERNICUS/S2_SR_10m\": {\n",
    "            \"Name\": 'fCOVER',\n",
    "            \"errorName\": 'errorfCOVER',\n",
    "            \"maskName\": 'maskfCOVER',\n",
    "            \"description\": 'Fraction of canopy cover',\n",
    "            \"variable\": 3,\n",
    "            \"inputBands\":      ['cosVZA', 'cosSZA', 'cosRAA', 'B2', 'B3', 'B4', 'B8'],\n",
    "            \"inputScaling\":    [0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001],\n",
    "            \"outmin\": (ee.Image(ee.Array([[0]]))),\n",
    "            \"outmax\": (ee.Image(ee.Array([[1]]))) \n",
    "        },\n",
    "         \"NEON_Sim_10m\": {\n",
    "            \"Name\": 'fCOVER',\n",
    "            \"errorName\": 'errorfCOVER',\n",
    "            \"maskName\": 'maskfCOVER',\n",
    "            \"description\": 'Fraction of canopy cover',\n",
    "            \"variable\": 3,\n",
    "            \"inputBands\":      ['cosVZA', 'cosSZA', 'cosRAA', 'B2', 'B3', 'B4', 'B8'],\n",
    "            \"inputScaling\":    [1, 1, 1, 1, 1, 1, 1],\n",
    "            \"outmin\": (ee.Image(ee.Array([[0]]))),\n",
    "            \"outmax\": (ee.Image(ee.Array([[1]]))) \n",
    "        },\n",
    "         \"NEON_Sim\": {\n",
    "            \"Name\": 'fCOVER',\n",
    "            \"errorName\": 'errorfCOVER',\n",
    "            \"maskName\": 'maskfCOVER',\n",
    "            \"description\": 'Fraction of canopy cover',\n",
    "            \"variable\": 3,\n",
    "            \"inputBands\":      ['cosVZA', 'cosSZA', 'cosRAA', 'B3', 'B4', 'B5', 'B6', 'B7', 'B8A', 'B11', 'B12'],\n",
    "            \"inputScaling\":    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
    "            \"outmin\": (ee.Image(ee.Array([[0]]))),\n",
    "            \"outmax\": (ee.Image(ee.Array([[1]]))) \n",
    "        }\n",
    "    },\n",
    "    'LAI': {\n",
    "        \"COPERNICUS/S2_SR\": {\n",
    "            \"Name\": 'LAI',\n",
    "            \"errorName\": 'errorLAI',\n",
    "            \"maskName\": 'maskLAI',\n",
    "            \"description\": 'Leaf area index',\n",
    "            \"variable\": 1,\n",
    "            \"inputBands\":      ['cosVZA', 'cosSZA', 'cosRAA', 'B3', 'B4', 'B5', 'B6', 'B7', 'B8A', 'B11', 'B12'],\n",
    "            \"inputScaling\":    [0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001],\n",
    "            \"outmin\": (ee.Image(ee.Array([[0]]))),\n",
    "            \"outmax\": (ee.Image(ee.Array([[1]])))\n",
    "        },\n",
    "        \"COPERNICUS/S2_SR_10m\": {\n",
    "            \"Name\": 'LAI',\n",
    "            \"errorName\": 'errorLAI',\n",
    "            \"maskName\": 'maskLAI',\n",
    "            \"description\": 'Leaf area index',\n",
    "            \"variable\": 1,\n",
    "            \"inputBands\":      ['cosVZA', 'cosSZA', 'cosRAA', 'B2', 'B3', 'B4', 'B8'],\n",
    "            \"inputScaling\":    [0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001],\n",
    "            \"outmin\": (ee.Image(ee.Array([[0]]))),\n",
    "            \"outmax\": (ee.Image(ee.Array([[1]])))\n",
    "        },\n",
    "          \"NEON_Sim_10m\": {\n",
    "            \"Name\": 'LAI',\n",
    "            \"errorName\": 'errorLAI',\n",
    "            \"maskName\": 'maskLAI',\n",
    "            \"description\": 'Leaf area index',\n",
    "            \"variable\": 1,\n",
    "            \"inputBands\":      ['cosVZA', 'cosSZA', 'cosRAA', 'B2', 'B3', 'B4', 'B8'],\n",
    "            \"inputScaling\":    [1, 1, 1, 1, 1, 1, 1],\n",
    "            \"outmin\": (ee.Image(ee.Array([[0]]))),\n",
    "            \"outmax\": (ee.Image(ee.Array([[1]])))\n",
    "        },\n",
    "        \"NEON_Sim\": {\n",
    "            \"Name\": 'LAI',\n",
    "            \"errorName\": 'errorLAI',\n",
    "            \"maskName\": 'maskLAI',\n",
    "            \"description\": 'Leaf area index',\n",
    "            \"variable\": 1,\n",
    "            \"inputBands\":      ['cosVZA', 'cosSZA', 'cosRAA', 'B3', 'B4', 'B5', 'B6', 'B7', 'B8A', 'B11', 'B12'],\n",
    "            \"inputScaling\":    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
    "            \"outmin\": (ee.Image(ee.Array([[0]]))),\n",
    "            \"outmax\": (ee.Image(ee.Array([[1]])))\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### for NEON bands\n",
    "def  renameBands(image):\n",
    "    bands = ['b1', 'b2', 'b3', 'b4', 'b5', 'b6', 'b7','b8','b9','b10','b11','b12','b13','b14','b15','b16']\n",
    "    new_bands = ['B1', 'B2', 'B3', 'B4', 'B5', 'B6', 'B7','B8', 'B8A', 'B9', 'B10', 'B11', 'B12', 'cosVZA','cosSZA','cosRAA']\n",
    "    return image.select(bands).rename(new_bands)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Part B: Creation of  solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 1 - SL2P/SL2P10 - Processing NEON Simulated - Independent step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### REFERENCE (REF) - SL2P (input bands 10m, output band 10m, use 20m neural network coefficents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# parse the networks\n",
    "colName = 'NEON_Sim'\n",
    "colOptions = COLLECTION_OPTIONS[colName]\n",
    "netOptions = VIS_OPTIONS[outputName][colName]\n",
    "numNets = ee.Number(ee.Feature((COLLECTION_OPTIONS[colName][\"Network_Ind\"]).first()).propertyNames().remove('Feature Index').remove('system:index').remove('lon').size())\n",
    "SL2P = ee.List.sequence(1,ee.Number(COLLECTION_OPTIONS[colName][\"numVariables\"]),1).map(lambda netNum: wn.makeNetVars(COLLECTION_OPTIONS[colName][\"Collection_SL2P\"],numNets,netNum));\n",
    "errorsSL2P = ee.List.sequence(1,ee.Number(COLLECTION_OPTIONS[colName][\"numVariables\"]),1).map(lambda netNum: wn.makeNetVars(COLLECTION_OPTIONS[colName][\"Collection_SL2Perrors\"],numNets,netNum));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# filter collection and add ancillary bands\n",
    "\n",
    "# input_collection = ee.ImageCollection(testImage) \\\n",
    "#                      .map(lambda image: ib.addDate(image)) \\\n",
    "#                      .map(lambda image: image.clip(mapBounds)) \\\n",
    "#                      .map(lambda image: ib.s2MaskClear(image)) \\\n",
    "#                      .map(lambda image: ib.s2MaskLand(image)) \\\n",
    "#                      .map(lambda image: ib.addS2Geometry(colOptions, image))\n",
    "input_collection = ee.ImageCollection(testImage).map(renameBands)\n",
    "# get partition used to select network\n",
    "partition = (COLLECTION_OPTIONS[colName][\"partition\"]).filterBounds(mapBounds).mosaic().clip(mapBounds).rename('partition')\n",
    "\n",
    "# pre process input imagery and flag invalid inputs\n",
    "scaled_input_collection = input_collection.map(lambda image: ib.scaleBands(netOptions[\"inputBands\"],netOptions[\"inputScaling\"],image)) \\\n",
    "                                          .map(lambda image: ib.invalidInput(COLLECTION_OPTIONS[colName][\"sl2pDomain\"],netOptions[\"inputBands\"],image))\n",
    "\n",
    "# apply networks to produce mapped parameters\n",
    "estimateSL2P = scaled_input_collection.map(lambda image: wn.wrapperNNets(SL2P, partition, netOptions, COLLECTION_OPTIONS[colName], \"estimate\", image, outputName))\n",
    "uncertaintySL2P = scaled_input_collection.map(lambda image: wn.wrapperNNets(errorsSL2P, partition, netOptions, COLLECTION_OPTIONS[colName], \"error\", image, outputName))\n",
    "\n",
    "# scale and offset mapped parameter bands\n",
    "estimateSL2P = estimateSL2P.map(lambda image: image.addBands(image.select(\"estimate\"+outputName).multiply(ee.Image.constant(outputScale)).add(ee.Image.constant(outputOffset)), overwrite=True))\n",
    "uncertaintySL2P = uncertaintySL2P.map(lambda image: image.addBands(image.select(\"error\"+outputName).multiply(ee.Image.constant(outputScale)).add(ee.Image.constant(outputOffset)), overwrite=True))\n",
    "\n",
    "# produce final export collection\n",
    "export_collection = input_collection.combine(estimateSL2P).combine(uncertaintySL2P)\n",
    "    \n",
    "# image_output_names = ([name +\"_\"+siteSelect +\"_\"+outputName for name in export_collection.toList(export_collection.size()).map(lambda image: ee.Image(image).id()).getInfo()])\n",
    "image_output_names = ([name[16:]+\"_\"+outputName+\"_\"+\"20m_net\" for name in export_collection.toList(export_collection.size()).map(lambda image: ee.Image(image).get('system:id')).getInfo()]) ##[name[16:], 16 here means the lengh of users/GangHong2/ \n",
    "\n",
    "ee_func.displayImage(export_collection.mosaic().select('estimate'+outputName),0+outputOffset,10*outputScale+outputOffset, mapBounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# export tasks to Earth Engine\n",
    "export_task = ee_func.export_collection_to_gee(collection=export_collection,\n",
    "                                               num_images=1,\n",
    "                                               # image_names=[siteSelect+'_'+outputName+'_SL2P'],\n",
    "                                               image_names = image_output_names,\n",
    "                                               scale=10,\n",
    "                                               # asset_folder='users/kateharvey/SL2P_images',\n",
    "                                               asset_folder=assetfolder_REF,\n",
    "                                               data_type='float',\n",
    "                                               max_pixels=1e13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### SOLUTION B (SOL_B) -  SL2P10 (input bands 10m, output 10m,  10m neural network coefficients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# parse the networks\n",
    "colName ='NEON_Sim_10m'\n",
    "colOptions = COLLECTION_OPTIONS[colName]\n",
    "netOptions = VIS_OPTIONS[outputName][colName]\n",
    "numNets = ee.Number(ee.Feature((COLLECTION_OPTIONS[colName][\"Network_Ind\"]).first()).propertyNames().remove('Feature Index').remove('system:index').remove('lon').size())\n",
    "SL2P = ee.List.sequence(1,ee.Number(COLLECTION_OPTIONS[colName][\"numVariables\"]),1).map(lambda netNum: wn.makeNetVars(COLLECTION_OPTIONS[colName][\"Collection_SL2P\"],numNets,netNum));\n",
    "errorsSL2P = ee.List.sequence(1,ee.Number(COLLECTION_OPTIONS[colName][\"numVariables\"]),1).map(lambda netNum: wn.makeNetVars(COLLECTION_OPTIONS[colName][\"Collection_SL2Perrors\"],numNets,netNum));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_collection_10m = ee.ImageCollection(testImage).map(renameBands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "partition = (COLLECTION_OPTIONS[colName][\"partition\"]).filterBounds(mapBounds).mosaic().clip(mapBounds).rename('partition')\n",
    "\n",
    "# pre process input imagery and flag invalid inputs\n",
    "scaled_input_collection_10m = input_collection_10m.map(lambda image: ib.scaleBands(netOptions[\"inputBands\"],netOptions[\"inputScaling\"],image)) \\\n",
    "                                                  .map(lambda image: ib.invalidInput(COLLECTION_OPTIONS[colName][\"sl2pDomain\"],netOptions[\"inputBands\"],image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print (scaled_input_collection_10m.first().getInfo())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# performs same procedure as above, using SL2P10 network\n",
    "# applies algorithm to 10 m bands ; generates a 10 m map\n",
    "\n",
    "# filter collection and add ancillary bands\n",
    "# input_collection_10m = ee.ImageCollection(testImage) \\\n",
    "#                      .map(lambda image: ib.addDate(image)) \\\n",
    "#                      .map(lambda image: image.clip(mapBounds)) \\\n",
    "#                      .map(lambda image: ib.s2MaskClear(image)) \\\n",
    "#                      .map(lambda image: ib.s2MaskLand(image)) \\\n",
    "#                      .map(lambda image: ib.addS2Geometry(colOptions, image))\n",
    "# input_collection_10m = ee.ImageCollection(testImage)\n",
    "\n",
    "# get partition used to select network\n",
    "# partition = (COLLECTION_OPTIONS[colName][\"partition\"]).filterBounds(mapBounds).mosaic().clip(mapBounds).rename('partition')\n",
    "# partition = (COLLECTION_OPTIONS[colName][\"partition\"]).rename('partition')\n",
    "\n",
    "# # pre process input imagery and flag invalid inputs\n",
    "# scaled_input_collection_10m = input_collection_10m.map(lambda image: ib.scaleBands(netOptions[\"inputBands\"],netOptions[\"inputScaling\"],image)) \\\n",
    "#                                                   .map(lambda image: ib.invalidInput(COLLECTION_OPTIONS[colName][\"sl2pDomain\"],netOptions[\"inputBands\"],image))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# apply networks to produce mapped parameters\n",
    "estimateSL2P_10m = scaled_input_collection_10m.map(lambda image: wn.wrapperNNets(SL2P, partition, netOptions, COLLECTION_OPTIONS[colName], \"estimate\", image, outputName))\n",
    "uncertaintySL2P_10m = scaled_input_collection_10m.map(lambda image: wn.wrapperNNets(errorsSL2P, partition, netOptions, COLLECTION_OPTIONS[colName], \"error\", image, outputName))\n",
    "\n",
    "# scale and offset mapped parameter bands\n",
    "estimateSL2P_10m = estimateSL2P_10m.map(lambda image: image.addBands(image.select(\"estimate\"+outputName) \\\n",
    "                                                             .multiply(ee.Image.constant(outputScale)) \\\n",
    "                                                             .add(ee.Image.constant(outputOffset)), overwrite=True))\n",
    "uncertaintySL2P_10m = uncertaintySL2P_10m.map(lambda image: image.addBands(image.select(\"error\"+outputName) \\\n",
    "                                                                   .multiply(ee.Image.constant(outputScale)) \\\n",
    "                                                                   .add(ee.Image.constant(outputOffset)), overwrite=True))\n",
    "\n",
    "\n",
    "# produce final export collection\n",
    "export_collection_10m = input_collection_10m.combine(estimateSL2P_10m).combine(uncertaintySL2P_10m)\n",
    "\n",
    "# image_output_names_10m = ([name+\"_\"+siteSelect+\"_\"+outputName+\"_10m\" for name in export_collection_10m.toList(export_collection_10m.size()).map(lambda image: ee.Image(image).id()).getInfo()])\n",
    "image_output_names_10m = ([name[16:]+\"_\"+outputName for name in export_collection_10m.toList(export_collection_10m.size()).map(lambda image: ee.Image(image).get('system:id')).getInfo()])\n",
    "\n",
    "ee_func.displayImage(export_collection_10m.mosaic().select('estimate'+outputName),0+outputOffset,10*outputScale+outputOffset, mapBounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export tasks to Earth Engine\n",
    "export_task_10m = ee_func.export_collection_to_gee(collection=export_collection_10m,\n",
    "                                                   num_images=1,\n",
    "                                                   # image_names=[siteSelect+'_'+outputName+'_SL2P10'],\n",
    "                                                   image_names = image_output_names_10m,\n",
    "                                                   scale=10,\n",
    "                                                   # asset_folder='users/kateharvey/SL2P10_images',\n",
    "                                                   asset_folder=assetfolder_SOL_B,\n",
    "                                                   # data_type=exportDataType,\n",
    "                                                   data_type='float',\n",
    "                                                   max_pixels=1e13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 2 - SL2P - Processing 20m NEON - Independent step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### SETUP: resample 10m NEON to 20m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputcollection_10m = ee.ImageCollection(testImage).map(renameBands) ## rename testImage bands based on the bands name for input SL2P\n",
    "proj_10m=inputcollection_10m.first().select('B1').projection().getInfo()  ## get the projection of one band\n",
    "inputImage_20m = inputcollection_10m.first().resample('bilinear').reproject(crs=proj_10m['crs'], scale=20) ## resample the image to 20m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### NULL HYPOTHESIS (NULL) -  (input band 20m, ouput band 20m, 20m net) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse the networks\n",
    "colName = 'NEON_Sim'\n",
    "colOptions = COLLECTION_OPTIONS[colName]\n",
    "netOptions = VIS_OPTIONS[outputName][colName]\n",
    "numNets = ee.Number(ee.Feature((COLLECTION_OPTIONS[colName][\"Network_Ind\"]).first()).propertyNames().remove('Feature Index').remove('system:index').remove('lon').size())\n",
    "SL2P = ee.List.sequence(1,ee.Number(COLLECTION_OPTIONS[colName][\"numVariables\"]),1).map(lambda netNum: wn.makeNetVars(COLLECTION_OPTIONS[colName][\"Collection_SL2P\"],numNets,netNum));\n",
    "errorsSL2P = ee.List.sequence(1,ee.Number(COLLECTION_OPTIONS[colName][\"numVariables\"]),1).map(lambda netNum: wn.makeNetVars(COLLECTION_OPTIONS[colName][\"Collection_SL2Perrors\"],numNets,netNum));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"width:100%;\"><div style=\"position:relative;width:100%;height:0;padding-bottom:60%;\"><span style=\"color:#565656\">Make this Notebook Trusted to load map: File -> Trust Notebook</span><iframe srcdoc=\"&lt;!DOCTYPE html&gt;\n",
       "&lt;html&gt;\n",
       "&lt;head&gt;\n",
       "    \n",
       "    &lt;meta http-equiv=&quot;content-type&quot; content=&quot;text/html; charset=UTF-8&quot; /&gt;\n",
       "    \n",
       "        &lt;script&gt;\n",
       "            L_NO_TOUCH = false;\n",
       "            L_DISABLE_3D = false;\n",
       "        &lt;/script&gt;\n",
       "    \n",
       "    &lt;style&gt;html, body {width: 100%;height: 100%;margin: 0;padding: 0;}&lt;/style&gt;\n",
       "    &lt;style&gt;#map {position:absolute;top:0;bottom:0;right:0;left:0;}&lt;/style&gt;\n",
       "    &lt;script src=&quot;https://cdn.jsdelivr.net/npm/leaflet@1.9.3/dist/leaflet.js&quot;&gt;&lt;/script&gt;\n",
       "    &lt;script src=&quot;https://code.jquery.com/jquery-1.12.4.min.js&quot;&gt;&lt;/script&gt;\n",
       "    &lt;script src=&quot;https://cdn.jsdelivr.net/npm/bootstrap@5.2.2/dist/js/bootstrap.bundle.min.js&quot;&gt;&lt;/script&gt;\n",
       "    &lt;script src=&quot;https://cdnjs.cloudflare.com/ajax/libs/Leaflet.awesome-markers/2.0.2/leaflet.awesome-markers.js&quot;&gt;&lt;/script&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/leaflet@1.9.3/dist/leaflet.css&quot;/&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/bootstrap@5.2.2/dist/css/bootstrap.min.css&quot;/&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://netdna.bootstrapcdn.com/bootstrap/3.0.0/css/bootstrap.min.css&quot;/&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.2.0/css/all.min.css&quot;/&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdnjs.cloudflare.com/ajax/libs/Leaflet.awesome-markers/2.0.2/leaflet.awesome-markers.css&quot;/&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/gh/python-visualization/folium/folium/templates/leaflet.awesome.rotate.min.css&quot;/&gt;\n",
       "    \n",
       "            &lt;meta name=&quot;viewport&quot; content=&quot;width=device-width,\n",
       "                initial-scale=1.0, maximum-scale=1.0, user-scalable=no&quot; /&gt;\n",
       "            &lt;style&gt;\n",
       "                #map_f2bc717ac9a40639b067e2a438b50607 {\n",
       "                    position: relative;\n",
       "                    width: 100.0%;\n",
       "                    height: 500.0px;\n",
       "                    left: 0.0%;\n",
       "                    top: 0.0%;\n",
       "                }\n",
       "                .leaflet-container { font-size: 1rem; }\n",
       "            &lt;/style&gt;\n",
       "        \n",
       "    &lt;script src=&quot;https://cdnjs.cloudflare.com/ajax/libs/leaflet.fullscreen/1.4.2/Control.FullScreen.min.js&quot;&gt;&lt;/script&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdnjs.cloudflare.com/ajax/libs/leaflet.fullscreen/1.4.2/Control.FullScreen.min.css&quot;/&gt;\n",
       "&lt;/head&gt;\n",
       "&lt;body&gt;\n",
       "    \n",
       "    \n",
       "            &lt;div class=&quot;folium-map&quot; id=&quot;map_f2bc717ac9a40639b067e2a438b50607&quot; &gt;&lt;/div&gt;\n",
       "        \n",
       "&lt;/body&gt;\n",
       "&lt;script&gt;\n",
       "    \n",
       "    \n",
       "            var map_f2bc717ac9a40639b067e2a438b50607 = L.map(\n",
       "                &quot;map_f2bc717ac9a40639b067e2a438b50607&quot;,\n",
       "                {\n",
       "                    center: [37.03640665253355, -119.7386779864812],\n",
       "                    crs: L.CRS.EPSG3857,\n",
       "                    zoom: 8,\n",
       "                    zoomControl: true,\n",
       "                    preferCanvas: false,\n",
       "                }\n",
       "            );\n",
       "\n",
       "            \n",
       "\n",
       "        \n",
       "    \n",
       "            var tile_layer_7a62690711fbdaffb560de72ee1ae2f2 = L.tileLayer(\n",
       "                &quot;https://{s}.tile.openstreetmap.org/{z}/{x}/{y}.png&quot;,\n",
       "                {&quot;attribution&quot;: &quot;Data by \\u0026copy; \\u003ca target=\\&quot;_blank\\&quot; href=\\&quot;http://openstreetmap.org\\&quot;\\u003eOpenStreetMap\\u003c/a\\u003e, under \\u003ca target=\\&quot;_blank\\&quot; href=\\&quot;http://www.openstreetmap.org/copyright\\&quot;\\u003eODbL\\u003c/a\\u003e.&quot;, &quot;detectRetina&quot;: false, &quot;maxNativeZoom&quot;: 18, &quot;maxZoom&quot;: 18, &quot;minZoom&quot;: 0, &quot;noWrap&quot;: false, &quot;opacity&quot;: 1, &quot;subdomains&quot;: &quot;abc&quot;, &quot;tms&quot;: false}\n",
       "            ).addTo(map_f2bc717ac9a40639b067e2a438b50607);\n",
       "        \n",
       "    \n",
       "            var tile_layer_4245024d9e82ad3a8156263a1e1c7576 = L.tileLayer(\n",
       "                &quot;https://earthengine.googleapis.com/v1alpha/projects/earthengine-legacy/maps/2f945ac8b13227cff169abac9135c1e7-413cbb637db20d5fde43fcae07b099dc/tiles/{z}/{x}/{y}&quot;,\n",
       "                {&quot;attribution&quot;: &quot;Google Earth Engine&quot;, &quot;detectRetina&quot;: false, &quot;maxNativeZoom&quot;: 18, &quot;maxZoom&quot;: 18, &quot;minZoom&quot;: 0, &quot;noWrap&quot;: false, &quot;opacity&quot;: 1, &quot;subdomains&quot;: &quot;abc&quot;, &quot;tms&quot;: false}\n",
       "            ).addTo(map_f2bc717ac9a40639b067e2a438b50607);\n",
       "        \n",
       "    \n",
       "            var layer_control_e6fac80919a9457431cbd3193e45b502 = {\n",
       "                base_layers : {\n",
       "                    &quot;openstreetmap&quot; : tile_layer_7a62690711fbdaffb560de72ee1ae2f2,\n",
       "                },\n",
       "                overlays :  {\n",
       "                    &quot;Image&quot; : tile_layer_4245024d9e82ad3a8156263a1e1c7576,\n",
       "                },\n",
       "            };\n",
       "            L.control.layers(\n",
       "                layer_control_e6fac80919a9457431cbd3193e45b502.base_layers,\n",
       "                layer_control_e6fac80919a9457431cbd3193e45b502.overlays,\n",
       "                {&quot;autoZIndex&quot;: true, &quot;collapsed&quot;: true, &quot;position&quot;: &quot;topright&quot;}\n",
       "            ).addTo(map_f2bc717ac9a40639b067e2a438b50607);\n",
       "        \n",
       "    \n",
       "            L.control.fullscreen(\n",
       "                {&quot;forceSeparateButton&quot;: false, &quot;position&quot;: &quot;topleft&quot;, &quot;title&quot;: &quot;Full Screen&quot;, &quot;titleCancel&quot;: &quot;Exit Full Screen&quot;}\n",
       "            ).addTo(map_f2bc717ac9a40639b067e2a438b50607);\n",
       "        \n",
       "&lt;/script&gt;\n",
       "&lt;/html&gt;\" style=\"position:absolute;width:100%;height:100%;left:0;top:0;border:none !important;\" allowfullscreen webkitallowfullscreen mozallowfullscreen></iframe></div></div>"
      ],
      "text/plain": [
       "<folium.folium.Map at 0x1eb43a15930>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# filter collection and add ancillary bands\n",
    "input_collection = ee.ImageCollection(inputImage_20m)##.map(renameBands)\n",
    "# get partition used to select network\n",
    "partition = (COLLECTION_OPTIONS[colName][\"partition\"]).filterBounds(mapBounds).mosaic().clip(mapBounds).rename('partition')\n",
    "\n",
    "# pre process input imagery and flag invalid inputs\n",
    "scaled_input_collection = input_collection.map(lambda image: ib.scaleBands(netOptions[\"inputBands\"],netOptions[\"inputScaling\"],image)) \\\n",
    "                                          .map(lambda image: ib.invalidInput(COLLECTION_OPTIONS[colName][\"sl2pDomain\"],netOptions[\"inputBands\"],image))\n",
    "\n",
    "# apply networks to produce mapped parameters\n",
    "estimateSL2P = scaled_input_collection.map(lambda image: wn.wrapperNNets(SL2P, partition, netOptions, COLLECTION_OPTIONS[colName], \"estimate\", image, outputName))\n",
    "uncertaintySL2P = scaled_input_collection.map(lambda image: wn.wrapperNNets(errorsSL2P, partition, netOptions, COLLECTION_OPTIONS[colName], \"error\", image, outputName))\n",
    "\n",
    "# scale and offset mapped parameter bands\n",
    "estimateSL2P = estimateSL2P.map(lambda image: image.addBands(image.select(\"estimate\"+outputName).multiply(ee.Image.constant(outputScale)).add(ee.Image.constant(outputOffset)), overwrite=True))\n",
    "uncertaintySL2P = uncertaintySL2P.map(lambda image: image.addBands(image.select(\"error\"+outputName).multiply(ee.Image.constant(outputScale)).add(ee.Image.constant(outputOffset)), overwrite=True))\n",
    "\n",
    "# produce final export collection\n",
    "export_collection = input_collection.combine(estimateSL2P).combine(uncertaintySL2P)\n",
    "    \n",
    "# image_output_names = ([name +\"_\"+siteSelect +\"_\"+outputName for name in export_collection.toList(export_collection.size()).map(lambda image: ee.Image(image).id()).getInfo()])\n",
    "image_output_names = ([name[16:61]+\"_20m_\"+outputName+\"_\"+\"20m_net\" for name in export_collection.toList(export_collection.size()).map(lambda image: ee.Image(image).get('system:id')).getInfo()]) ##[name[16:], 16 here means the lengh of users/GangHong2/ \n",
    "\n",
    "ee_func.displayImage(export_collection.mosaic().select('estimate'+outputName),0+outputOffset,10*outputScale+outputOffset, mapBounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export tasks to Earth Engine\n",
    "export_task_20m = ee_func.export_collection_to_gee(collection=export_collection,\n",
    "                                                   num_images=1,                                                   \n",
    "                                                   image_names = image_output_names,\n",
    "                                                   scale=10,   ## inputband 20m, the acutal output is 20m, but here 10m for comparison with others                                            \n",
    "                                                   asset_folder=assetfolder_NULL,                                                   \n",
    "                                                   data_type='float',\n",
    "                                                   max_pixels=1e13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 3 - SL2P/SL2P10- Processing DSen2 - Independent step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### SETUP 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### make an imagecollection from DSen2 imageries- 10 totally\n",
    "img1=ee.ImageCollection(ee.Image('users/GangHong2/DSen2/S2B_MSIL2A_20190822T173909_N0213_R098_T13SCS_20190822T220238'))\n",
    "img2=ee.ImageCollection(ee.Image('users/GangHong2/DSen2/S2B_MSIL2A_20190826T153819_N0213_R011_T18TYN_20190826T195901'))\n",
    "img3=ee.ImageCollection(ee.Image('users/GangHong2/DSen2/S2B_MSIL2A_20210422T162829_N0300_R083_T16SCA_20210422T204151'))\n",
    "img4=ee.ImageCollection(ee.Image('users/GangHong2/DSen2/S2B_MSIL2A_20210719T190919_N0301_R056_T10TER_20210719T215339'))\n",
    "img5=ee.ImageCollection(ee.Image('users/GangHong2/DSen2/S2B_MSIL2A_20190608T164849_N0212_R026_T15TYL_20190608T212115'))\n",
    "img6=ee.ImageCollection(ee.Image('users/GangHong2/DSen2/S2B_MSIL2A_20210401T183919_N0300_R070_T11SKB_20210401T224235'))\n",
    "img7=ee.ImageCollection(ee.Image('users/GangHong2/DSen2/S2B_MSIL2A_20200627T173909_N0214_R098_T14TLS_20200627T213600'))\n",
    "img8=ee.ImageCollection(ee.Image('users/GangHong2/DSen2/S2B_MSIL2A_20210808T154809_N0301_R054_T18SUJ_20210808T201351'))\n",
    "img9=ee.ImageCollection(ee.Image('users/GangHong2/DSen2/S2A_MSIL2A_20200713T170901_N0214_R112_T14SQJ_20200713T213310'))\n",
    "img10=ee.ImageCollection(ee.Image('users/GangHong2/DSen2/S2A_MSIL2A_20190606T165901_N0212_R069_T16TCS_20190606T212006'))\n",
    "\n",
    "## an image collection\n",
    "DSen2_Col=img1.merge(img2).merge(img3).merge(img4).merge(img5).merge(img6).merge(img7).merge(img8).merge(img9).merge(img10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### SETUP 2: preparing image for runing SL2P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### get the asset ID, like 'users/GangHong2/NEON_D16_ABBY_DP1_20210719_191207_reflectance_10m'\n",
    "neon_id=testImage.get(\"system:id\").getInfo()\n",
    "neon_name=neon_id[16:]   ## slice the neon_id to get the name, like 'NEON_D16_ABBY_DP1_20210719_191207_reflectance_10m'\n",
    "## based on the property name 'NEON' to find DSen2\n",
    "DSen2=DSen2_Col.filter(ee.Filter.eq('NEON', neon_name))\n",
    "## get the DSen2 name, like 'S2B_MSIL2A_20210719T190919_N0301_R056_T10TER_20210719T215339'\n",
    "DSen2_Name=DSen2.first().get(\"system:id\").getInfo()[22:]\n",
    "## find S2 from GEE from DSen2 file name\n",
    "S2img = ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED').filterBounds(DSen2.geometry()).filter(ee.Filter.eq('PRODUCT_ID', DSen2_Name))\n",
    "### select S2 based on DSen2 image geometry and keep band 'SCL' for masking Land\n",
    "S2_selected=S2img.first().clip(DSen2.geometry()).select('SCL')\n",
    "## merge S2 SCL band and DSen2 bands\n",
    "newS2=S2_selected.addBands(DSen2.first())\n",
    "## rename bands \n",
    "inputImage_bands = ee.List(['SCL','B4', 'B3', 'B2', 'B8','B5', 'B6', 'B7', 'B8A', 'B11', 'B12'])\n",
    "inputImage = newS2.rename(inputImage_bands)\n",
    "# print(inputImage.bandNames().getInfo())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### SOLUTION A (SOL_A) - SL2P (input band 10m, output band 10m, 20m net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse the networks\n",
    "colName = 'COPERNICUS/S2_SR'\n",
    "colOptions = COLLECTION_OPTIONS[colName]\n",
    "netOptions = VIS_OPTIONS[outputName][colName]\n",
    "numNets = ee.Number(ee.Feature((COLLECTION_OPTIONS[colName][\"Network_Ind\"]).first()).propertyNames().remove('Feature Index').remove('system:index').remove('lon').size())\n",
    "SL2P = ee.List.sequence(1,ee.Number(COLLECTION_OPTIONS[colName][\"numVariables\"]),1).map(lambda netNum: wn.makeNetVars(COLLECTION_OPTIONS[colName][\"Collection_SL2P\"],numNets,netNum));\n",
    "errorsSL2P = ee.List.sequence(1,ee.Number(COLLECTION_OPTIONS[colName][\"numVariables\"]),1).map(lambda netNum: wn.makeNetVars(COLLECTION_OPTIONS[colName][\"Collection_SL2Perrors\"],numNets,netNum));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"width:100%;\"><div style=\"position:relative;width:100%;height:0;padding-bottom:60%;\"><span style=\"color:#565656\">Make this Notebook Trusted to load map: File -> Trust Notebook</span><iframe srcdoc=\"&lt;!DOCTYPE html&gt;\n",
       "&lt;html&gt;\n",
       "&lt;head&gt;\n",
       "    \n",
       "    &lt;meta http-equiv=&quot;content-type&quot; content=&quot;text/html; charset=UTF-8&quot; /&gt;\n",
       "    \n",
       "        &lt;script&gt;\n",
       "            L_NO_TOUCH = false;\n",
       "            L_DISABLE_3D = false;\n",
       "        &lt;/script&gt;\n",
       "    \n",
       "    &lt;style&gt;html, body {width: 100%;height: 100%;margin: 0;padding: 0;}&lt;/style&gt;\n",
       "    &lt;style&gt;#map {position:absolute;top:0;bottom:0;right:0;left:0;}&lt;/style&gt;\n",
       "    &lt;script src=&quot;https://cdn.jsdelivr.net/npm/leaflet@1.9.3/dist/leaflet.js&quot;&gt;&lt;/script&gt;\n",
       "    &lt;script src=&quot;https://code.jquery.com/jquery-1.12.4.min.js&quot;&gt;&lt;/script&gt;\n",
       "    &lt;script src=&quot;https://cdn.jsdelivr.net/npm/bootstrap@5.2.2/dist/js/bootstrap.bundle.min.js&quot;&gt;&lt;/script&gt;\n",
       "    &lt;script src=&quot;https://cdnjs.cloudflare.com/ajax/libs/Leaflet.awesome-markers/2.0.2/leaflet.awesome-markers.js&quot;&gt;&lt;/script&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/leaflet@1.9.3/dist/leaflet.css&quot;/&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/bootstrap@5.2.2/dist/css/bootstrap.min.css&quot;/&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://netdna.bootstrapcdn.com/bootstrap/3.0.0/css/bootstrap.min.css&quot;/&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.2.0/css/all.min.css&quot;/&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdnjs.cloudflare.com/ajax/libs/Leaflet.awesome-markers/2.0.2/leaflet.awesome-markers.css&quot;/&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/gh/python-visualization/folium/folium/templates/leaflet.awesome.rotate.min.css&quot;/&gt;\n",
       "    \n",
       "            &lt;meta name=&quot;viewport&quot; content=&quot;width=device-width,\n",
       "                initial-scale=1.0, maximum-scale=1.0, user-scalable=no&quot; /&gt;\n",
       "            &lt;style&gt;\n",
       "                #map_a7696e881d29ff966160461394bd5b89 {\n",
       "                    position: relative;\n",
       "                    width: 100.0%;\n",
       "                    height: 500.0px;\n",
       "                    left: 0.0%;\n",
       "                    top: 0.0%;\n",
       "                }\n",
       "                .leaflet-container { font-size: 1rem; }\n",
       "            &lt;/style&gt;\n",
       "        \n",
       "    &lt;script src=&quot;https://cdnjs.cloudflare.com/ajax/libs/leaflet.fullscreen/1.4.2/Control.FullScreen.min.js&quot;&gt;&lt;/script&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdnjs.cloudflare.com/ajax/libs/leaflet.fullscreen/1.4.2/Control.FullScreen.min.css&quot;/&gt;\n",
       "&lt;/head&gt;\n",
       "&lt;body&gt;\n",
       "    \n",
       "    \n",
       "            &lt;div class=&quot;folium-map&quot; id=&quot;map_a7696e881d29ff966160461394bd5b89&quot; &gt;&lt;/div&gt;\n",
       "        \n",
       "&lt;/body&gt;\n",
       "&lt;script&gt;\n",
       "    \n",
       "    \n",
       "            var map_a7696e881d29ff966160461394bd5b89 = L.map(\n",
       "                &quot;map_a7696e881d29ff966160461394bd5b89&quot;,\n",
       "                {\n",
       "                    center: [42.45658376615197, -72.32260025238313],\n",
       "                    crs: L.CRS.EPSG3857,\n",
       "                    zoom: 8,\n",
       "                    zoomControl: true,\n",
       "                    preferCanvas: false,\n",
       "                }\n",
       "            );\n",
       "\n",
       "            \n",
       "\n",
       "        \n",
       "    \n",
       "            var tile_layer_7d0cb1a02d5ff64de64804a5bd21f0aa = L.tileLayer(\n",
       "                &quot;https://{s}.tile.openstreetmap.org/{z}/{x}/{y}.png&quot;,\n",
       "                {&quot;attribution&quot;: &quot;Data by \\u0026copy; \\u003ca target=\\&quot;_blank\\&quot; href=\\&quot;http://openstreetmap.org\\&quot;\\u003eOpenStreetMap\\u003c/a\\u003e, under \\u003ca target=\\&quot;_blank\\&quot; href=\\&quot;http://www.openstreetmap.org/copyright\\&quot;\\u003eODbL\\u003c/a\\u003e.&quot;, &quot;detectRetina&quot;: false, &quot;maxNativeZoom&quot;: 18, &quot;maxZoom&quot;: 18, &quot;minZoom&quot;: 0, &quot;noWrap&quot;: false, &quot;opacity&quot;: 1, &quot;subdomains&quot;: &quot;abc&quot;, &quot;tms&quot;: false}\n",
       "            ).addTo(map_a7696e881d29ff966160461394bd5b89);\n",
       "        \n",
       "    \n",
       "            var tile_layer_20578e8bf88a266a63223c4f0f32ef60 = L.tileLayer(\n",
       "                &quot;https://earthengine.googleapis.com/v1alpha/projects/earthengine-legacy/maps/513083b0c7643098eafc8d9be06968c5-4d9a51dde4a886f171032ffbc5a29f8b/tiles/{z}/{x}/{y}&quot;,\n",
       "                {&quot;attribution&quot;: &quot;Google Earth Engine&quot;, &quot;detectRetina&quot;: false, &quot;maxNativeZoom&quot;: 18, &quot;maxZoom&quot;: 18, &quot;minZoom&quot;: 0, &quot;noWrap&quot;: false, &quot;opacity&quot;: 1, &quot;subdomains&quot;: &quot;abc&quot;, &quot;tms&quot;: false}\n",
       "            ).addTo(map_a7696e881d29ff966160461394bd5b89);\n",
       "        \n",
       "    \n",
       "            var layer_control_18de5d6cd4dd530609932751830a02e3 = {\n",
       "                base_layers : {\n",
       "                    &quot;openstreetmap&quot; : tile_layer_7d0cb1a02d5ff64de64804a5bd21f0aa,\n",
       "                },\n",
       "                overlays :  {\n",
       "                    &quot;Image&quot; : tile_layer_20578e8bf88a266a63223c4f0f32ef60,\n",
       "                },\n",
       "            };\n",
       "            L.control.layers(\n",
       "                layer_control_18de5d6cd4dd530609932751830a02e3.base_layers,\n",
       "                layer_control_18de5d6cd4dd530609932751830a02e3.overlays,\n",
       "                {&quot;autoZIndex&quot;: true, &quot;collapsed&quot;: true, &quot;position&quot;: &quot;topright&quot;}\n",
       "            ).addTo(map_a7696e881d29ff966160461394bd5b89);\n",
       "        \n",
       "    \n",
       "            L.control.fullscreen(\n",
       "                {&quot;forceSeparateButton&quot;: false, &quot;position&quot;: &quot;topleft&quot;, &quot;title&quot;: &quot;Full Screen&quot;, &quot;titleCancel&quot;: &quot;Exit Full Screen&quot;}\n",
       "            ).addTo(map_a7696e881d29ff966160461394bd5b89);\n",
       "        \n",
       "&lt;/script&gt;\n",
       "&lt;/html&gt;\" style=\"position:absolute;width:100%;height:100%;left:0;top:0;border:none !important;\" allowfullscreen webkitallowfullscreen mozallowfullscreen></iframe></div></div>"
      ],
      "text/plain": [
       "<folium.folium.Map at 0x1b536535390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# filter collection and add ancillary bands\n",
    "input_collection = ee.ImageCollection(inputImage).map(lambda image: ib.s2MaskLand(image)).map(lambda image: ib.addS2Geometry(colOptions, image))\n",
    "\n",
    "# get partition used to select network\n",
    "partition = (COLLECTION_OPTIONS[colName][\"partition\"]).filterBounds(mapBounds).mosaic().clip(mapBounds).rename('partition')\n",
    "\n",
    "# pre process input imagery and flag invalid inputs\n",
    "scaled_input_collection = input_collection.map(lambda image: ib.scaleBands(netOptions[\"inputBands\"],netOptions[\"inputScaling\"],image)) \\\n",
    "                                          .map(lambda image: ib.invalidInput(COLLECTION_OPTIONS[colName][\"sl2pDomain\"],netOptions[\"inputBands\"],image))\n",
    "\n",
    "# apply networks to produce mapped parameters\n",
    "estimateSL2P = scaled_input_collection.map(lambda image: wn.wrapperNNets(SL2P, partition, netOptions, COLLECTION_OPTIONS[colName], \"estimate\", image, outputName))\n",
    "uncertaintySL2P = scaled_input_collection.map(lambda image: wn.wrapperNNets(errorsSL2P, partition, netOptions, COLLECTION_OPTIONS[colName], \"error\", image, outputName))\n",
    "\n",
    "# scale and offset mapped parameter bands\n",
    "estimateSL2P = estimateSL2P.map(lambda image: image.addBands(image.select(\"estimate\"+outputName).multiply(ee.Image.constant(outputScale)).add(ee.Image.constant(outputOffset)), overwrite=True))\n",
    "uncertaintySL2P = uncertaintySL2P.map(lambda image: image.addBands(image.select(\"error\"+outputName).multiply(ee.Image.constant(outputScale)).add(ee.Image.constant(outputOffset)), overwrite=True))\n",
    "\n",
    "# produce final export collection\n",
    "export_collection = input_collection.combine(estimateSL2P).combine(uncertaintySL2P)\n",
    "    \n",
    "# image_output_names = ([name+\"_\"+outputName for name in export_collection.toList(export_collection.size()).map(lambda image: ee.Image(image).id()).getInfo()])\n",
    "image_output_names = ([name+\"_\"+siteSelect+\"_\"+outputName+\"_DSen2_20m_net\" for name in export_collection.toList(export_collection.size()).map(lambda image: ee.Image(image).id()).getInfo()])\n",
    "ee_func.displayImage(export_collection.mosaic().select('estimate'+outputName),0+outputOffset,10*outputScale+outputOffset, mapBounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export tasks to Earth Engine\n",
    "export_task = ee_func.export_collection_to_gee(collection=export_collection,\n",
    "                                               num_images=1,                                             \n",
    "                                               image_names = image_output_names,\n",
    "                                               scale=10,                                          \n",
    "                                               asset_folder=assetfolder_SOL_A,\n",
    "                                               data_type='float',\n",
    "                                               max_pixels=1e13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### RESULT D (RES_D) - SL2P10 (inputband 10m, output band 10m, 10m net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse the networks\n",
    "colName = 'COPERNICUS/S2_SR_10m'\n",
    "colOptions = COLLECTION_OPTIONS[colName]\n",
    "netOptions = VIS_OPTIONS[outputName][colName]\n",
    "numNets = ee.Number(ee.Feature((COLLECTION_OPTIONS[colName][\"Network_Ind\"]).first()).propertyNames().remove('Feature Index').remove('system:index').remove('lon').size())\n",
    "SL2P = ee.List.sequence(1,ee.Number(COLLECTION_OPTIONS[colName][\"numVariables\"]),1).map(lambda netNum: wn.makeNetVars(COLLECTION_OPTIONS[colName][\"Collection_SL2P\"],numNets,netNum));\n",
    "errorsSL2P = ee.List.sequence(1,ee.Number(COLLECTION_OPTIONS[colName][\"numVariables\"]),1).map(lambda netNum: wn.makeNetVars(COLLECTION_OPTIONS[colName][\"Collection_SL2Perrors\"],numNets,netNum));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"width:100%;\"><div style=\"position:relative;width:100%;height:0;padding-bottom:60%;\"><span style=\"color:#565656\">Make this Notebook Trusted to load map: File -> Trust Notebook</span><iframe srcdoc=\"&lt;!DOCTYPE html&gt;\n",
       "&lt;html&gt;\n",
       "&lt;head&gt;\n",
       "    \n",
       "    &lt;meta http-equiv=&quot;content-type&quot; content=&quot;text/html; charset=UTF-8&quot; /&gt;\n",
       "    \n",
       "        &lt;script&gt;\n",
       "            L_NO_TOUCH = false;\n",
       "            L_DISABLE_3D = false;\n",
       "        &lt;/script&gt;\n",
       "    \n",
       "    &lt;style&gt;html, body {width: 100%;height: 100%;margin: 0;padding: 0;}&lt;/style&gt;\n",
       "    &lt;style&gt;#map {position:absolute;top:0;bottom:0;right:0;left:0;}&lt;/style&gt;\n",
       "    &lt;script src=&quot;https://cdn.jsdelivr.net/npm/leaflet@1.9.3/dist/leaflet.js&quot;&gt;&lt;/script&gt;\n",
       "    &lt;script src=&quot;https://code.jquery.com/jquery-1.12.4.min.js&quot;&gt;&lt;/script&gt;\n",
       "    &lt;script src=&quot;https://cdn.jsdelivr.net/npm/bootstrap@5.2.2/dist/js/bootstrap.bundle.min.js&quot;&gt;&lt;/script&gt;\n",
       "    &lt;script src=&quot;https://cdnjs.cloudflare.com/ajax/libs/Leaflet.awesome-markers/2.0.2/leaflet.awesome-markers.js&quot;&gt;&lt;/script&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/leaflet@1.9.3/dist/leaflet.css&quot;/&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/bootstrap@5.2.2/dist/css/bootstrap.min.css&quot;/&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://netdna.bootstrapcdn.com/bootstrap/3.0.0/css/bootstrap.min.css&quot;/&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.2.0/css/all.min.css&quot;/&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdnjs.cloudflare.com/ajax/libs/Leaflet.awesome-markers/2.0.2/leaflet.awesome-markers.css&quot;/&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/gh/python-visualization/folium/folium/templates/leaflet.awesome.rotate.min.css&quot;/&gt;\n",
       "    \n",
       "            &lt;meta name=&quot;viewport&quot; content=&quot;width=device-width,\n",
       "                initial-scale=1.0, maximum-scale=1.0, user-scalable=no&quot; /&gt;\n",
       "            &lt;style&gt;\n",
       "                #map_03d14681d6cb02bb2223a6583c9054df {\n",
       "                    position: relative;\n",
       "                    width: 100.0%;\n",
       "                    height: 500.0px;\n",
       "                    left: 0.0%;\n",
       "                    top: 0.0%;\n",
       "                }\n",
       "                .leaflet-container { font-size: 1rem; }\n",
       "            &lt;/style&gt;\n",
       "        \n",
       "    &lt;script src=&quot;https://cdnjs.cloudflare.com/ajax/libs/leaflet.fullscreen/1.4.2/Control.FullScreen.min.js&quot;&gt;&lt;/script&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdnjs.cloudflare.com/ajax/libs/leaflet.fullscreen/1.4.2/Control.FullScreen.min.css&quot;/&gt;\n",
       "&lt;/head&gt;\n",
       "&lt;body&gt;\n",
       "    \n",
       "    \n",
       "            &lt;div class=&quot;folium-map&quot; id=&quot;map_03d14681d6cb02bb2223a6583c9054df&quot; &gt;&lt;/div&gt;\n",
       "        \n",
       "&lt;/body&gt;\n",
       "&lt;script&gt;\n",
       "    \n",
       "    \n",
       "            var map_03d14681d6cb02bb2223a6583c9054df = L.map(\n",
       "                &quot;map_03d14681d6cb02bb2223a6583c9054df&quot;,\n",
       "                {\n",
       "                    center: [42.45658376615197, -72.32260025238313],\n",
       "                    crs: L.CRS.EPSG3857,\n",
       "                    zoom: 8,\n",
       "                    zoomControl: true,\n",
       "                    preferCanvas: false,\n",
       "                }\n",
       "            );\n",
       "\n",
       "            \n",
       "\n",
       "        \n",
       "    \n",
       "            var tile_layer_5ae3ba6e937cc5860cffd97ff26915f5 = L.tileLayer(\n",
       "                &quot;https://{s}.tile.openstreetmap.org/{z}/{x}/{y}.png&quot;,\n",
       "                {&quot;attribution&quot;: &quot;Data by \\u0026copy; \\u003ca target=\\&quot;_blank\\&quot; href=\\&quot;http://openstreetmap.org\\&quot;\\u003eOpenStreetMap\\u003c/a\\u003e, under \\u003ca target=\\&quot;_blank\\&quot; href=\\&quot;http://www.openstreetmap.org/copyright\\&quot;\\u003eODbL\\u003c/a\\u003e.&quot;, &quot;detectRetina&quot;: false, &quot;maxNativeZoom&quot;: 18, &quot;maxZoom&quot;: 18, &quot;minZoom&quot;: 0, &quot;noWrap&quot;: false, &quot;opacity&quot;: 1, &quot;subdomains&quot;: &quot;abc&quot;, &quot;tms&quot;: false}\n",
       "            ).addTo(map_03d14681d6cb02bb2223a6583c9054df);\n",
       "        \n",
       "    \n",
       "            var tile_layer_0a6a0cf2bbd3c95d3089963608c2a044 = L.tileLayer(\n",
       "                &quot;https://earthengine.googleapis.com/v1alpha/projects/earthengine-legacy/maps/9947f89ff457bd167f341c960b4cae2f-0985ef852a7feb22b6e81fcd53a34af4/tiles/{z}/{x}/{y}&quot;,\n",
       "                {&quot;attribution&quot;: &quot;Google Earth Engine&quot;, &quot;detectRetina&quot;: false, &quot;maxNativeZoom&quot;: 18, &quot;maxZoom&quot;: 18, &quot;minZoom&quot;: 0, &quot;noWrap&quot;: false, &quot;opacity&quot;: 1, &quot;subdomains&quot;: &quot;abc&quot;, &quot;tms&quot;: false}\n",
       "            ).addTo(map_03d14681d6cb02bb2223a6583c9054df);\n",
       "        \n",
       "    \n",
       "            var layer_control_9be31ec69e55e0ec37516bafd9b75fd2 = {\n",
       "                base_layers : {\n",
       "                    &quot;openstreetmap&quot; : tile_layer_5ae3ba6e937cc5860cffd97ff26915f5,\n",
       "                },\n",
       "                overlays :  {\n",
       "                    &quot;Image&quot; : tile_layer_0a6a0cf2bbd3c95d3089963608c2a044,\n",
       "                },\n",
       "            };\n",
       "            L.control.layers(\n",
       "                layer_control_9be31ec69e55e0ec37516bafd9b75fd2.base_layers,\n",
       "                layer_control_9be31ec69e55e0ec37516bafd9b75fd2.overlays,\n",
       "                {&quot;autoZIndex&quot;: true, &quot;collapsed&quot;: true, &quot;position&quot;: &quot;topright&quot;}\n",
       "            ).addTo(map_03d14681d6cb02bb2223a6583c9054df);\n",
       "        \n",
       "    \n",
       "            L.control.fullscreen(\n",
       "                {&quot;forceSeparateButton&quot;: false, &quot;position&quot;: &quot;topleft&quot;, &quot;title&quot;: &quot;Full Screen&quot;, &quot;titleCancel&quot;: &quot;Exit Full Screen&quot;}\n",
       "            ).addTo(map_03d14681d6cb02bb2223a6583c9054df);\n",
       "        \n",
       "&lt;/script&gt;\n",
       "&lt;/html&gt;\" style=\"position:absolute;width:100%;height:100%;left:0;top:0;border:none !important;\" allowfullscreen webkitallowfullscreen mozallowfullscreen></iframe></div></div>"
      ],
      "text/plain": [
       "<folium.folium.Map at 0x1b536563c40>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# performs same procedure as above, using SL2P10 network\n",
    "# applies algorithm to 10 m bands ; generates a 10 m map\n",
    "\n",
    "# filter collection and add ancillary bands\n",
    "input_collection_10m = ee.ImageCollection(inputImage).map(lambda image: ib.s2MaskLand(image)).map(lambda image: ib.addS2Geometry(colOptions, image))\n",
    "\n",
    "# get partition used to select network\n",
    "partition = (COLLECTION_OPTIONS[colName][\"partition\"]).filterBounds(mapBounds).mosaic().clip(mapBounds).rename('partition')\n",
    "\n",
    "# pre process input imagery and flag invalid inputs\n",
    "scaled_input_collection_10m = input_collection_10m.map(lambda image: ib.s2MaskLand(image)) \\\n",
    "                                                  .map(lambda image: ib.scaleBands(netOptions[\"inputBands\"],netOptions[\"inputScaling\"],image)) \\\n",
    "                                                  .map(lambda image: ib.invalidInput(COLLECTION_OPTIONS[colName][\"sl2pDomain\"],netOptions[\"inputBands\"],image))\n",
    "\n",
    "# apply networks to produce mapped parameters\n",
    "estimateSL2P_10m = scaled_input_collection_10m.map(lambda image: wn.wrapperNNets(SL2P, partition, netOptions, COLLECTION_OPTIONS[colName], \"estimate\", image, outputName))\n",
    "uncertaintySL2P_10m = scaled_input_collection_10m.map(lambda image: wn.wrapperNNets(errorsSL2P, partition, netOptions, COLLECTION_OPTIONS[colName], \"error\", image, outputName))\n",
    "\n",
    "# scale and offset mapped parameter bands\n",
    "estimateSL2P_10m = estimateSL2P_10m.map(lambda image: image.addBands(image.select(\"estimate\"+outputName) \\\n",
    "                                                             .multiply(ee.Image.constant(outputScale)) \\\n",
    "                                                             .add(ee.Image.constant(outputOffset)), overwrite=True))\n",
    "uncertaintySL2P_10m = uncertaintySL2P_10m.map(lambda image: image.addBands(image.select(\"error\"+outputName) \\\n",
    "                                                                   .multiply(ee.Image.constant(outputScale)) \\\n",
    "                                                                   .add(ee.Image.constant(outputOffset)), overwrite=True))\n",
    "\n",
    "\n",
    "# produce final export collection\n",
    "export_collection_10m = input_collection_10m.combine(estimateSL2P_10m).combine(uncertaintySL2P_10m)\n",
    "\n",
    "# image_output_names_10m = ([name+\"_\"+outputName+\"_10m\" for name in export_collection_10m.toList(export_collection_10m.size()).map(lambda image: ee.Image(image).id()).getInfo()])\n",
    "image_output_names_10m = ([name+\"_\"+siteSelect+\"_\"+outputName+\"_DSen2_10m_net\" for name in export_collection_10m.toList(export_collection_10m.size()).map(lambda image: ee.Image(image).id()).getInfo()])\n",
    "ee_func.displayImage(export_collection_10m.mosaic().select('estimate'+outputName),0+outputOffset,10*outputScale+outputOffset, mapBounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export tasks to Earth Engine\n",
    "export_task_10m = ee_func.export_collection_to_gee(collection=export_collection_10m,\n",
    "                                                   num_images=1,                                                  \n",
    "                                                   image_names = image_output_names_10m,\n",
    "                                                   scale=10,                                                  \n",
    "                                                   asset_folder=assetfolder_RES_D,                                                \n",
    "                                                   data_type='float',\n",
    "                                                   max_pixels=1e13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 4 - SL2P/SL2P10 - Processing S2 - Independent step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "### make an imagecollection from DSen2 imageries\n",
    "img1=ee.ImageCollection(ee.Image('users/GangHong2/DSen2/S2B_MSIL2A_20190822T173909_N0213_R098_T13SCS_20190822T220238'))\n",
    "img2=ee.ImageCollection(ee.Image('users/GangHong2/DSen2/S2B_MSIL2A_20190826T153819_N0213_R011_T18TYN_20190826T195901'))\n",
    "img3=ee.ImageCollection(ee.Image('users/GangHong2/DSen2/S2B_MSIL2A_20210422T162829_N0300_R083_T16SCA_20210422T204151'))\n",
    "img4=ee.ImageCollection(ee.Image('users/GangHong2/DSen2/S2B_MSIL2A_20210719T190919_N0301_R056_T10TER_20210719T215339'))\n",
    "img5=ee.ImageCollection(ee.Image('users/GangHong2/DSen2/S2B_MSIL2A_20190608T164849_N0212_R026_T15TYL_20190608T212115'))\n",
    "img6=ee.ImageCollection(ee.Image('users/GangHong2/DSen2/S2B_MSIL2A_20210401T183919_N0300_R070_T11SKB_20210401T224235'))\n",
    "img7=ee.ImageCollection(ee.Image('users/GangHong2/DSen2/S2B_MSIL2A_20200627T173909_N0214_R098_T14TLS_20200627T213600'))\n",
    "img8=ee.ImageCollection(ee.Image('users/GangHong2/DSen2/S2B_MSIL2A_20210808T154809_N0301_R054_T18SUJ_20210808T201351'))\n",
    "img9=ee.ImageCollection(ee.Image('users/GangHong2/DSen2/S2A_MSIL2A_20200713T170901_N0214_R112_T14SQJ_20200713T213310'))\n",
    "img10=ee.ImageCollection(ee.Image('users/GangHong2/DSen2/S2A_MSIL2A_20190606T165901_N0212_R069_T16TCS_20190606T212006'))\n",
    "\n",
    "## an image collection\n",
    "DSen2_Col=img1.merge(img2).merge(img3).merge(img4).merge(img5).merge(img6).merge(img7).merge(img8).merge(img9).merge(img10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "### get the asset ID, like 'users/GangHong2/NEON_D16_ABBY_DP1_20210719_191207_reflectance_10m'\n",
    "neon_id=testImage.get(\"system:id\").getInfo()\n",
    "neon_name=neon_id[16:]   ## slice the neon_id to get the name, like 'NEON_D16_ABBY_DP1_20210719_191207_reflectance_10m'\n",
    "## based on the property name 'NEON' to find DSen2\n",
    "DSen2=DSen2_Col.filter(ee.Filter.eq('NEON', neon_name))\n",
    "## get the DSen2 name, like 'S2B_MSIL2A_20210719T190919_N0301_R056_T10TER_20210719T215339'\n",
    "DSen2_Name=DSen2.first().get(\"system:id\").getInfo()[22:]\n",
    "## find S2 from GEE from DSen2 file name\n",
    "S2img = ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED').filterBounds(DSen2.geometry()).filter(ee.Filter.eq('PRODUCT_ID', DSen2_Name))\n",
    "### select S2 based on DSen2 image geometry and keep band 'SCL' for masking Land\n",
    "S2_selected=S2img.first().clip(DSen2.geometry()).select(['B2', 'B3', 'B4', 'B5','B6', 'B7', 'B8', 'B8A', 'B11', 'B12','SCL'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### RESULT E (RES_E) - SL2P (input bands 20m, output 20m,  20m net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse the networks\n",
    "colName = 'COPERNICUS/S2_SR'\n",
    "colOptions = COLLECTION_OPTIONS[colName]\n",
    "netOptions = VIS_OPTIONS[outputName][colName]\n",
    "numNets = ee.Number(ee.Feature((COLLECTION_OPTIONS[colName][\"Network_Ind\"]).first()).propertyNames().remove('Feature Index').remove('system:index').remove('lon').size())\n",
    "SL2P = ee.List.sequence(1,ee.Number(COLLECTION_OPTIONS[colName][\"numVariables\"]),1).map(lambda netNum: wn.makeNetVars(COLLECTION_OPTIONS[colName][\"Collection_SL2P\"],numNets,netNum));\n",
    "errorsSL2P = ee.List.sequence(1,ee.Number(COLLECTION_OPTIONS[colName][\"numVariables\"]),1).map(lambda netNum: wn.makeNetVars(COLLECTION_OPTIONS[colName][\"Collection_SL2Perrors\"],numNets,netNum));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"width:100%;\"><div style=\"position:relative;width:100%;height:0;padding-bottom:60%;\"><span style=\"color:#565656\">Make this Notebook Trusted to load map: File -> Trust Notebook</span><iframe srcdoc=\"&lt;!DOCTYPE html&gt;\n",
       "&lt;html&gt;\n",
       "&lt;head&gt;\n",
       "    \n",
       "    &lt;meta http-equiv=&quot;content-type&quot; content=&quot;text/html; charset=UTF-8&quot; /&gt;\n",
       "    \n",
       "        &lt;script&gt;\n",
       "            L_NO_TOUCH = false;\n",
       "            L_DISABLE_3D = false;\n",
       "        &lt;/script&gt;\n",
       "    \n",
       "    &lt;style&gt;html, body {width: 100%;height: 100%;margin: 0;padding: 0;}&lt;/style&gt;\n",
       "    &lt;style&gt;#map {position:absolute;top:0;bottom:0;right:0;left:0;}&lt;/style&gt;\n",
       "    &lt;script src=&quot;https://cdn.jsdelivr.net/npm/leaflet@1.9.3/dist/leaflet.js&quot;&gt;&lt;/script&gt;\n",
       "    &lt;script src=&quot;https://code.jquery.com/jquery-1.12.4.min.js&quot;&gt;&lt;/script&gt;\n",
       "    &lt;script src=&quot;https://cdn.jsdelivr.net/npm/bootstrap@5.2.2/dist/js/bootstrap.bundle.min.js&quot;&gt;&lt;/script&gt;\n",
       "    &lt;script src=&quot;https://cdnjs.cloudflare.com/ajax/libs/Leaflet.awesome-markers/2.0.2/leaflet.awesome-markers.js&quot;&gt;&lt;/script&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/leaflet@1.9.3/dist/leaflet.css&quot;/&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/bootstrap@5.2.2/dist/css/bootstrap.min.css&quot;/&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://netdna.bootstrapcdn.com/bootstrap/3.0.0/css/bootstrap.min.css&quot;/&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.2.0/css/all.min.css&quot;/&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdnjs.cloudflare.com/ajax/libs/Leaflet.awesome-markers/2.0.2/leaflet.awesome-markers.css&quot;/&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/gh/python-visualization/folium/folium/templates/leaflet.awesome.rotate.min.css&quot;/&gt;\n",
       "    \n",
       "            &lt;meta name=&quot;viewport&quot; content=&quot;width=device-width,\n",
       "                initial-scale=1.0, maximum-scale=1.0, user-scalable=no&quot; /&gt;\n",
       "            &lt;style&gt;\n",
       "                #map_af7d71a9c9acfe4dc2b8c21ca182e397 {\n",
       "                    position: relative;\n",
       "                    width: 100.0%;\n",
       "                    height: 500.0px;\n",
       "                    left: 0.0%;\n",
       "                    top: 0.0%;\n",
       "                }\n",
       "                .leaflet-container { font-size: 1rem; }\n",
       "            &lt;/style&gt;\n",
       "        \n",
       "    &lt;script src=&quot;https://cdnjs.cloudflare.com/ajax/libs/leaflet.fullscreen/1.4.2/Control.FullScreen.min.js&quot;&gt;&lt;/script&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdnjs.cloudflare.com/ajax/libs/leaflet.fullscreen/1.4.2/Control.FullScreen.min.css&quot;/&gt;\n",
       "&lt;/head&gt;\n",
       "&lt;body&gt;\n",
       "    \n",
       "    \n",
       "            &lt;div class=&quot;folium-map&quot; id=&quot;map_af7d71a9c9acfe4dc2b8c21ca182e397&quot; &gt;&lt;/div&gt;\n",
       "        \n",
       "&lt;/body&gt;\n",
       "&lt;script&gt;\n",
       "    \n",
       "    \n",
       "            var map_af7d71a9c9acfe4dc2b8c21ca182e397 = L.map(\n",
       "                &quot;map_af7d71a9c9acfe4dc2b8c21ca182e397&quot;,\n",
       "                {\n",
       "                    center: [42.45658376615197, -72.32260025238313],\n",
       "                    crs: L.CRS.EPSG3857,\n",
       "                    zoom: 8,\n",
       "                    zoomControl: true,\n",
       "                    preferCanvas: false,\n",
       "                }\n",
       "            );\n",
       "\n",
       "            \n",
       "\n",
       "        \n",
       "    \n",
       "            var tile_layer_9bbe9b78b48863000fb186694944682a = L.tileLayer(\n",
       "                &quot;https://{s}.tile.openstreetmap.org/{z}/{x}/{y}.png&quot;,\n",
       "                {&quot;attribution&quot;: &quot;Data by \\u0026copy; \\u003ca target=\\&quot;_blank\\&quot; href=\\&quot;http://openstreetmap.org\\&quot;\\u003eOpenStreetMap\\u003c/a\\u003e, under \\u003ca target=\\&quot;_blank\\&quot; href=\\&quot;http://www.openstreetmap.org/copyright\\&quot;\\u003eODbL\\u003c/a\\u003e.&quot;, &quot;detectRetina&quot;: false, &quot;maxNativeZoom&quot;: 18, &quot;maxZoom&quot;: 18, &quot;minZoom&quot;: 0, &quot;noWrap&quot;: false, &quot;opacity&quot;: 1, &quot;subdomains&quot;: &quot;abc&quot;, &quot;tms&quot;: false}\n",
       "            ).addTo(map_af7d71a9c9acfe4dc2b8c21ca182e397);\n",
       "        \n",
       "    \n",
       "            var tile_layer_16c9f095a71548f0d250aa825e8f4832 = L.tileLayer(\n",
       "                &quot;https://earthengine.googleapis.com/v1alpha/projects/earthengine-legacy/maps/de9637b2995d463fbd7f5d66c85c7a66-cf51435e59122445e0c83225fc66040f/tiles/{z}/{x}/{y}&quot;,\n",
       "                {&quot;attribution&quot;: &quot;Google Earth Engine&quot;, &quot;detectRetina&quot;: false, &quot;maxNativeZoom&quot;: 18, &quot;maxZoom&quot;: 18, &quot;minZoom&quot;: 0, &quot;noWrap&quot;: false, &quot;opacity&quot;: 1, &quot;subdomains&quot;: &quot;abc&quot;, &quot;tms&quot;: false}\n",
       "            ).addTo(map_af7d71a9c9acfe4dc2b8c21ca182e397);\n",
       "        \n",
       "    \n",
       "            var layer_control_6d07a1b6f59aaf427f1f951d3b83417e = {\n",
       "                base_layers : {\n",
       "                    &quot;openstreetmap&quot; : tile_layer_9bbe9b78b48863000fb186694944682a,\n",
       "                },\n",
       "                overlays :  {\n",
       "                    &quot;Image&quot; : tile_layer_16c9f095a71548f0d250aa825e8f4832,\n",
       "                },\n",
       "            };\n",
       "            L.control.layers(\n",
       "                layer_control_6d07a1b6f59aaf427f1f951d3b83417e.base_layers,\n",
       "                layer_control_6d07a1b6f59aaf427f1f951d3b83417e.overlays,\n",
       "                {&quot;autoZIndex&quot;: true, &quot;collapsed&quot;: true, &quot;position&quot;: &quot;topright&quot;}\n",
       "            ).addTo(map_af7d71a9c9acfe4dc2b8c21ca182e397);\n",
       "        \n",
       "    \n",
       "            L.control.fullscreen(\n",
       "                {&quot;forceSeparateButton&quot;: false, &quot;position&quot;: &quot;topleft&quot;, &quot;title&quot;: &quot;Full Screen&quot;, &quot;titleCancel&quot;: &quot;Exit Full Screen&quot;}\n",
       "            ).addTo(map_af7d71a9c9acfe4dc2b8c21ca182e397);\n",
       "        \n",
       "&lt;/script&gt;\n",
       "&lt;/html&gt;\" style=\"position:absolute;width:100%;height:100%;left:0;top:0;border:none !important;\" allowfullscreen webkitallowfullscreen mozallowfullscreen></iframe></div></div>"
      ],
      "text/plain": [
       "<folium.folium.Map at 0x1b536546500>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# filter collection and add ancillary bands\n",
    "input_collection = ee.ImageCollection(S2_selected).map(lambda image: ib.s2MaskLand(image)).map(lambda image: ib.addS2Geometry(colOptions, image))\n",
    "\n",
    "# get partition used to select network\n",
    "partition = (COLLECTION_OPTIONS[colName][\"partition\"]).filterBounds(mapBounds).mosaic().clip(mapBounds).rename('partition')\n",
    "\n",
    "# pre process input imagery and flag invalid inputs\n",
    "scaled_input_collection = input_collection.map(lambda image: ib.scaleBands(netOptions[\"inputBands\"],netOptions[\"inputScaling\"],image)) \\\n",
    "                                          .map(lambda image: ib.invalidInput(COLLECTION_OPTIONS[colName][\"sl2pDomain\"],netOptions[\"inputBands\"],image))\n",
    "\n",
    "# apply networks to produce mapped parameters\n",
    "estimateSL2P = scaled_input_collection.map(lambda image: wn.wrapperNNets(SL2P, partition, netOptions, COLLECTION_OPTIONS[colName], \"estimate\", image, outputName))\n",
    "uncertaintySL2P = scaled_input_collection.map(lambda image: wn.wrapperNNets(errorsSL2P, partition, netOptions, COLLECTION_OPTIONS[colName], \"error\", image, outputName))\n",
    "\n",
    "# scale and offset mapped parameter bands\n",
    "estimateSL2P = estimateSL2P.map(lambda image: image.addBands(image.select(\"estimate\"+outputName).multiply(ee.Image.constant(outputScale)).add(ee.Image.constant(outputOffset)), overwrite=True))\n",
    "uncertaintySL2P = uncertaintySL2P.map(lambda image: image.addBands(image.select(\"error\"+outputName).multiply(ee.Image.constant(outputScale)).add(ee.Image.constant(outputOffset)), overwrite=True))\n",
    "\n",
    "# produce final export collection\n",
    "export_collection = input_collection.combine(estimateSL2P).combine(uncertaintySL2P)\n",
    "    \n",
    "# image_output_names = ([name+\"_\"+outputName for name in export_collection.toList(export_collection.size()).map(lambda image: ee.Image(image).id()).getInfo()])\n",
    "image_output_names = ([name+\"_\"+siteSelect+\"_\"+outputName+\"_S2_20m_net\" for name in export_collection.toList(export_collection.size()).map(lambda image: ee.Image(image).id()).getInfo()])\n",
    "ee_func.displayImage(export_collection.mosaic().select('estimate'+outputName),0+outputOffset,10*outputScale+outputOffset, mapBounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export tasks to Earth Engine\n",
    "export_task = ee_func.export_collection_to_gee(collection=export_collection,\n",
    "                                               num_images=1,                                             \n",
    "                                               image_names = image_output_names,\n",
    "                                               scale=20,                ## output 20m                \n",
    "                                               asset_folder=assetfolder_RES_E,\n",
    "                                               data_type='float',\n",
    "                                               max_pixels=1e13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "###  RESULT F (RES_F) - SL2P10 (input bands 10m, output 10m, 10m net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse the networks\n",
    "colName = 'COPERNICUS/S2_SR_10m'\n",
    "colOptions = COLLECTION_OPTIONS[colName]\n",
    "netOptions = VIS_OPTIONS[outputName][colName]\n",
    "numNets = ee.Number(ee.Feature((COLLECTION_OPTIONS[colName][\"Network_Ind\"]).first()).propertyNames().remove('Feature Index').remove('system:index').remove('lon').size())\n",
    "SL2P = ee.List.sequence(1,ee.Number(COLLECTION_OPTIONS[colName][\"numVariables\"]),1).map(lambda netNum: wn.makeNetVars(COLLECTION_OPTIONS[colName][\"Collection_SL2P\"],numNets,netNum));\n",
    "errorsSL2P = ee.List.sequence(1,ee.Number(COLLECTION_OPTIONS[colName][\"numVariables\"]),1).map(lambda netNum: wn.makeNetVars(COLLECTION_OPTIONS[colName][\"Collection_SL2Perrors\"],numNets,netNum));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"width:100%;\"><div style=\"position:relative;width:100%;height:0;padding-bottom:60%;\"><span style=\"color:#565656\">Make this Notebook Trusted to load map: File -> Trust Notebook</span><iframe srcdoc=\"&lt;!DOCTYPE html&gt;\n",
       "&lt;html&gt;\n",
       "&lt;head&gt;\n",
       "    \n",
       "    &lt;meta http-equiv=&quot;content-type&quot; content=&quot;text/html; charset=UTF-8&quot; /&gt;\n",
       "    \n",
       "        &lt;script&gt;\n",
       "            L_NO_TOUCH = false;\n",
       "            L_DISABLE_3D = false;\n",
       "        &lt;/script&gt;\n",
       "    \n",
       "    &lt;style&gt;html, body {width: 100%;height: 100%;margin: 0;padding: 0;}&lt;/style&gt;\n",
       "    &lt;style&gt;#map {position:absolute;top:0;bottom:0;right:0;left:0;}&lt;/style&gt;\n",
       "    &lt;script src=&quot;https://cdn.jsdelivr.net/npm/leaflet@1.9.3/dist/leaflet.js&quot;&gt;&lt;/script&gt;\n",
       "    &lt;script src=&quot;https://code.jquery.com/jquery-1.12.4.min.js&quot;&gt;&lt;/script&gt;\n",
       "    &lt;script src=&quot;https://cdn.jsdelivr.net/npm/bootstrap@5.2.2/dist/js/bootstrap.bundle.min.js&quot;&gt;&lt;/script&gt;\n",
       "    &lt;script src=&quot;https://cdnjs.cloudflare.com/ajax/libs/Leaflet.awesome-markers/2.0.2/leaflet.awesome-markers.js&quot;&gt;&lt;/script&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/leaflet@1.9.3/dist/leaflet.css&quot;/&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/bootstrap@5.2.2/dist/css/bootstrap.min.css&quot;/&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://netdna.bootstrapcdn.com/bootstrap/3.0.0/css/bootstrap.min.css&quot;/&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.2.0/css/all.min.css&quot;/&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdnjs.cloudflare.com/ajax/libs/Leaflet.awesome-markers/2.0.2/leaflet.awesome-markers.css&quot;/&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/gh/python-visualization/folium/folium/templates/leaflet.awesome.rotate.min.css&quot;/&gt;\n",
       "    \n",
       "            &lt;meta name=&quot;viewport&quot; content=&quot;width=device-width,\n",
       "                initial-scale=1.0, maximum-scale=1.0, user-scalable=no&quot; /&gt;\n",
       "            &lt;style&gt;\n",
       "                #map_06afd7e65b545261171b96d27f5a9178 {\n",
       "                    position: relative;\n",
       "                    width: 100.0%;\n",
       "                    height: 500.0px;\n",
       "                    left: 0.0%;\n",
       "                    top: 0.0%;\n",
       "                }\n",
       "                .leaflet-container { font-size: 1rem; }\n",
       "            &lt;/style&gt;\n",
       "        \n",
       "    &lt;script src=&quot;https://cdnjs.cloudflare.com/ajax/libs/leaflet.fullscreen/1.4.2/Control.FullScreen.min.js&quot;&gt;&lt;/script&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdnjs.cloudflare.com/ajax/libs/leaflet.fullscreen/1.4.2/Control.FullScreen.min.css&quot;/&gt;\n",
       "&lt;/head&gt;\n",
       "&lt;body&gt;\n",
       "    \n",
       "    \n",
       "            &lt;div class=&quot;folium-map&quot; id=&quot;map_06afd7e65b545261171b96d27f5a9178&quot; &gt;&lt;/div&gt;\n",
       "        \n",
       "&lt;/body&gt;\n",
       "&lt;script&gt;\n",
       "    \n",
       "    \n",
       "            var map_06afd7e65b545261171b96d27f5a9178 = L.map(\n",
       "                &quot;map_06afd7e65b545261171b96d27f5a9178&quot;,\n",
       "                {\n",
       "                    center: [42.45658376615197, -72.32260025238313],\n",
       "                    crs: L.CRS.EPSG3857,\n",
       "                    zoom: 8,\n",
       "                    zoomControl: true,\n",
       "                    preferCanvas: false,\n",
       "                }\n",
       "            );\n",
       "\n",
       "            \n",
       "\n",
       "        \n",
       "    \n",
       "            var tile_layer_74ba4518cc9baecd4f51ef88fc2f4ccf = L.tileLayer(\n",
       "                &quot;https://{s}.tile.openstreetmap.org/{z}/{x}/{y}.png&quot;,\n",
       "                {&quot;attribution&quot;: &quot;Data by \\u0026copy; \\u003ca target=\\&quot;_blank\\&quot; href=\\&quot;http://openstreetmap.org\\&quot;\\u003eOpenStreetMap\\u003c/a\\u003e, under \\u003ca target=\\&quot;_blank\\&quot; href=\\&quot;http://www.openstreetmap.org/copyright\\&quot;\\u003eODbL\\u003c/a\\u003e.&quot;, &quot;detectRetina&quot;: false, &quot;maxNativeZoom&quot;: 18, &quot;maxZoom&quot;: 18, &quot;minZoom&quot;: 0, &quot;noWrap&quot;: false, &quot;opacity&quot;: 1, &quot;subdomains&quot;: &quot;abc&quot;, &quot;tms&quot;: false}\n",
       "            ).addTo(map_06afd7e65b545261171b96d27f5a9178);\n",
       "        \n",
       "    \n",
       "            var tile_layer_ef44a13a62bb586cd9fe13b7235be83f = L.tileLayer(\n",
       "                &quot;https://earthengine.googleapis.com/v1alpha/projects/earthengine-legacy/maps/a48c3506b8197bd584a5f9649c52ae58-c766ff69c757b93446d9679e5770b827/tiles/{z}/{x}/{y}&quot;,\n",
       "                {&quot;attribution&quot;: &quot;Google Earth Engine&quot;, &quot;detectRetina&quot;: false, &quot;maxNativeZoom&quot;: 18, &quot;maxZoom&quot;: 18, &quot;minZoom&quot;: 0, &quot;noWrap&quot;: false, &quot;opacity&quot;: 1, &quot;subdomains&quot;: &quot;abc&quot;, &quot;tms&quot;: false}\n",
       "            ).addTo(map_06afd7e65b545261171b96d27f5a9178);\n",
       "        \n",
       "    \n",
       "            var layer_control_da9a931b67513ee7e34188694f3db046 = {\n",
       "                base_layers : {\n",
       "                    &quot;openstreetmap&quot; : tile_layer_74ba4518cc9baecd4f51ef88fc2f4ccf,\n",
       "                },\n",
       "                overlays :  {\n",
       "                    &quot;Image&quot; : tile_layer_ef44a13a62bb586cd9fe13b7235be83f,\n",
       "                },\n",
       "            };\n",
       "            L.control.layers(\n",
       "                layer_control_da9a931b67513ee7e34188694f3db046.base_layers,\n",
       "                layer_control_da9a931b67513ee7e34188694f3db046.overlays,\n",
       "                {&quot;autoZIndex&quot;: true, &quot;collapsed&quot;: true, &quot;position&quot;: &quot;topright&quot;}\n",
       "            ).addTo(map_06afd7e65b545261171b96d27f5a9178);\n",
       "        \n",
       "    \n",
       "            L.control.fullscreen(\n",
       "                {&quot;forceSeparateButton&quot;: false, &quot;position&quot;: &quot;topleft&quot;, &quot;title&quot;: &quot;Full Screen&quot;, &quot;titleCancel&quot;: &quot;Exit Full Screen&quot;}\n",
       "            ).addTo(map_06afd7e65b545261171b96d27f5a9178);\n",
       "        \n",
       "&lt;/script&gt;\n",
       "&lt;/html&gt;\" style=\"position:absolute;width:100%;height:100%;left:0;top:0;border:none !important;\" allowfullscreen webkitallowfullscreen mozallowfullscreen></iframe></div></div>"
      ],
      "text/plain": [
       "<folium.folium.Map at 0x1b536546f20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# performs same procedure as above, using SL2P10 network\n",
    "# applies algorithm to 10 m bands ; generates a 10 m map\n",
    "\n",
    "# filter collection and add ancillary bands\n",
    "input_collection_10m = ee.ImageCollection(S2_selected).map(lambda image: ib.s2MaskLand(image)).map(lambda image: ib.addS2Geometry(colOptions, image))\n",
    "\n",
    "# get partition used to select network\n",
    "partition = (COLLECTION_OPTIONS[colName][\"partition\"]).filterBounds(mapBounds).mosaic().clip(mapBounds).rename('partition')\n",
    "\n",
    "# pre process input imagery and flag invalid inputs\n",
    "scaled_input_collection_10m = input_collection_10m.map(lambda image: ib.s2MaskLand(image)) \\\n",
    "                                                  .map(lambda image: ib.scaleBands(netOptions[\"inputBands\"],netOptions[\"inputScaling\"],image)) \\\n",
    "                                                  .map(lambda image: ib.invalidInput(COLLECTION_OPTIONS[colName][\"sl2pDomain\"],netOptions[\"inputBands\"],image))\n",
    "\n",
    "# apply networks to produce mapped parameters\n",
    "estimateSL2P_10m = scaled_input_collection_10m.map(lambda image: wn.wrapperNNets(SL2P, partition, netOptions, COLLECTION_OPTIONS[colName], \"estimate\", image, outputName))\n",
    "uncertaintySL2P_10m = scaled_input_collection_10m.map(lambda image: wn.wrapperNNets(errorsSL2P, partition, netOptions, COLLECTION_OPTIONS[colName], \"error\", image, outputName))\n",
    "\n",
    "# scale and offset mapped parameter bands\n",
    "estimateSL2P_10m = estimateSL2P_10m.map(lambda image: image.addBands(image.select(\"estimate\"+outputName) \\\n",
    "                                                             .multiply(ee.Image.constant(outputScale)) \\\n",
    "                                                             .add(ee.Image.constant(outputOffset)), overwrite=True))\n",
    "uncertaintySL2P_10m = uncertaintySL2P_10m.map(lambda image: image.addBands(image.select(\"error\"+outputName) \\\n",
    "                                                                   .multiply(ee.Image.constant(outputScale)) \\\n",
    "                                                                   .add(ee.Image.constant(outputOffset)), overwrite=True))\n",
    "\n",
    "\n",
    "# produce final export collection\n",
    "export_collection_10m = input_collection_10m.combine(estimateSL2P_10m).combine(uncertaintySL2P_10m)\n",
    "\n",
    "# image_output_names_10m = ([name+\"_\"+outputName+\"_10m\" for name in export_collection_10m.toList(export_collection_10m.size()).map(lambda image: ee.Image(image).id()).getInfo()])\n",
    "image_output_names_10m = ([name+\"_\"+siteSelect+\"_\"+outputName+\"_S2_10m_net\" for name in export_collection_10m.toList(export_collection_10m.size()).map(lambda image: ee.Image(image).id()).getInfo()])\n",
    "ee_func.displayImage(export_collection_10m.mosaic().select('estimate'+outputName),0+outputOffset,10*outputScale+outputOffset, mapBounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export tasks to Earth Engine\n",
    "export_task_10m = ee_func.export_collection_to_gee(collection=export_collection_10m,\n",
    "                                                   num_images=1,                                                  \n",
    "                                                   image_names = image_output_names_10m,\n",
    "                                                   scale=10,                                                  \n",
    "                                                   asset_folder=assetfolder_RES_F,                                                \n",
    "                                                   data_type='float',\n",
    "                                                   max_pixels=1e13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 5 -  ALR estimate - Processing through random forest - Independent step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### SOLUTION C (SOL_C) - (input 10m band, output 10m, no neural network net but random forest used in this procedure) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ALR function for estimation,after feature selection, a simple random forest estiamte applied\n",
    "def func_ALR(temp_image, responsedBand, outputName, mapBounds):\n",
    "   \n",
    "    # inputImage = ee.Image(temp_image).select(1,2,3,7,22,23,27,28,29,30,31,32)\n",
    "    # inputImage = ee.Image(temp_image).select(1,2,3,7,16,17,18,19,20,21)\n",
    "    # inputImage_bands = ee.List(['B2', 'B3', 'B4', 'B8', 'QA60', 'date', 'estimate'+outputName, 'partition', 'networkID', 'error'+outputName, 'partition_1', 'networkID_1'])\n",
    "    inputImage_bands = ee.List(['B2', 'B3', 'B4', 'B8', 'estimate'+outputName, 'partition', 'networkID', 'error'+outputName, 'partition_1', 'networkID_1'])\n",
    "    # inputImage = inputImage.rename(inputImage_bands)\n",
    "    inputImage = ee.Image(temp_image).select(inputImage_bands)\n",
    "    input_VI_definition = ee.List([\n",
    "                                   \"GI      = b('B3')/b('B4')\",                               \n",
    "                                   \"SGI     = b('B8')/b('B4')\",                                \n",
    "                                   \"GVI     = (b('B8')/b('B3'))-1\",                             \n",
    "                                   \"NDVI3   = ((b('B8')-b('B4'))/(b('B8')))+b('B4')\",                                \n",
    "                                   \"NDVI    = (b('B8')-b('B4'))/(b('B8')+b('B4'))\",\n",
    "                                   \"GNDVI   = (b('B8')-b('B3'))/(b('B8')+b('B3'))\",                                \n",
    "                                   \"NDGI    = (b('B3')-b('B4'))/(b('B3')+b('B4'))\",                                 \n",
    "                                   \"EVI     = 2.5*((b('B8')-b('B4'))/(b('B8')+6*b('B4')-7.5*b('B3')+1))\",\n",
    "                                   \"EVI2    = 2.5*((b('B8')-b('B4'))/(b('B8')+2.4*b('B4')+1))\",\n",
    "                                   \"RDVI    = (b('B8')-b('B4'))/((b('B8')+b('B4'))**0.5)\",\n",
    "                                   \"MSR     = ((b('B8')/b('B4'))-1)/((b('B8')/b('B4'))**0.5+1)\",                            \n",
    "                                   \"MSAVI2  = 0.5*(2*b('B8')+1-((2*b('B8')+1)**2-8*(b('B8')-b('B4')))**0.5)\",                                \n",
    "                                   \"NLI     = ((b('B8')**2)-b('B4'))/((b('B8')**2)+b('B4'))\"])\n",
    "\n",
    "    # names of bands to pass to ALR method (excluding metadata and other non-spectral bands)\n",
    "    input_bandNames = ['B2', 'B3', 'B4', 'B8', 'GI', 'SGI', 'GVI', 'NDVI3', 'NDVI', 'GNDVI', 'NDGI', 'EVI', 'EVI2', 'RDVI', 'MSR', 'MSAVI2', 'NLI']\n",
    "    \n",
    "    def format_image(image, image_bands, response_band, VI_definition):\n",
    "        image = ee.Image(image)\n",
    "        image_bands = ee.List(image_bands)\n",
    "        response_band = ee.String(response_band)\n",
    "        VI_definition = ee.List(VI_definition)\n",
    "        \n",
    "        # image_bands specifices a list of the names of the bands used in defining the expressions for VIs in VI_definition\n",
    "        image = image.rename(image_bands).toDouble()\n",
    "        \n",
    "        # Generate an ImageCollection from a list of expressions defining a set of VIs using the bands available in the image\n",
    "        VIimageCollection = ee.ImageCollection(VI_definition.map(lambda expr: image.expression(expr)))\n",
    "        VIimage = VIimageCollection.toBands().regexpRename(\"[0-9]+_\", \"\")\n",
    "        \n",
    "        # Reorder the bands in the image so the response band is the first band in the image\n",
    "        feature_bands = image_bands.remove(response_band)\n",
    "        \n",
    "        return ee.Image(image.select(response_band).addBands(VIimage).addBands(image.select(feature_bands)))\n",
    "\n",
    "    \n",
    "    inputImage = format_image(inputImage, inputImage_bands, responseBand, input_VI_definition)\n",
    "    \n",
    "    def scale_image(image, response_band):\n",
    "        image = ee.Image(image)\n",
    "        response_band = ee.String(response_band)\n",
    "        \n",
    "        def get_num_pixels(image):\n",
    "    \n",
    "            # get image height\n",
    "            def get_height(image):\n",
    "                height = image.getInfo()[\"bands\"][0][\"dimensions\"][0]\n",
    "                return height\n",
    "\n",
    "            # get image width\n",
    "            def get_width(image):\n",
    "                width = image.getInfo()[\"bands\"][0][\"dimensions\"][1]\n",
    "                return width\n",
    "\n",
    "            image_height = get_height(image)\n",
    "            image_width = get_width(image)\n",
    "            image_pixels = image_height*image_width\n",
    "\n",
    "            return image_pixels\n",
    "        \n",
    "        image_pixels = ee.Number(get_num_pixels(image))\n",
    "        \n",
    "        # Set up lists containing the input/feature bands in the image\n",
    "        bandList = image.bandNames()\n",
    "        featureList = bandList.remove(response_band)\n",
    "        num_bands = bandList.length()\n",
    "        num_features = featureList.length()\n",
    "        \n",
    "        # We will be using the reduceRegion() function on images from Earth Engine, \n",
    "        # which will process up to a specified number of pixels from the image to generate the outputs of the reducer\n",
    "        max_pixels = image_pixels.min(10000000)\n",
    "        # best_effort = ee.Algorithms.If(image_pixels.gt(max_pixels), True, False)\n",
    "        \n",
    "        # Set default projection and scale using the response band\n",
    "        defaultScale = image.select(response_band).projection().nominalScale()\n",
    "        defaultCrs = image.select(response_band).projection().crs()\n",
    "        image = image.setDefaultProjection(crs=defaultCrs, scale=defaultScale)\n",
    "        \n",
    "        # Center all of the bands in the image for LARs\n",
    "        # We will centre the sampled data later as well as reduceRegion() is not precise enough\n",
    "        meanImage = image.subtract(image.reduceRegion(reducer=ee.Reducer.mean(), \\\n",
    "                                    scale=defaultScale, bestEffort=True, maxPixels=max_pixels).toImage(bandList))\n",
    "        \n",
    "        # Separate the image into features (X) and response (y) as we need to standardize the input features\n",
    "        X = meanImage.select(featureList)\n",
    "        y = meanImage.select(response_band)\n",
    "        \n",
    "        # Standardize the input features\n",
    "        X = X.divide(X.reduceRegion(reducer=ee.Reducer.stdDev(), bestEffort=True, maxPixels=max_pixels).toImage(featureList))\n",
    "        \n",
    "        return X.addBands(y)\n",
    "\n",
    "    \n",
    "    scaledImage = scale_image(inputImage, responseBand)\n",
    "    \n",
    "    \n",
    "    def ee_LARS(input_image, input_bandNames, response_bandName, num_nonzero_coefficients, num_samples):\n",
    "        image = ee.Image(input_image)\n",
    "        feature_list = ee.List(input_bandNames)\n",
    "        response_band = ee.String(response_bandName)\n",
    "        full_band_list = ee.List(feature_list).add(response_band)\n",
    "        num_nonzero_coefficients = ee.Number(num_nonzero_coefficients)\n",
    "        num_samples = ee.Number(num_samples)\n",
    "        def get_num_pixels(image):\n",
    "    \n",
    "            # get image height\n",
    "            def get_height(image):\n",
    "                height = image.getInfo()[\"bands\"][0][\"dimensions\"][0]\n",
    "                return height\n",
    "\n",
    "            # get image width\n",
    "            def get_width(image):\n",
    "                width = image.getInfo()[\"bands\"][0][\"dimensions\"][1]\n",
    "                return width\n",
    "\n",
    "            image_height = get_height(image)\n",
    "            image_width = get_width(image)\n",
    "            image_pixels = image_height*image_width\n",
    "\n",
    "            return image_pixels\n",
    "        image_pixels = ee.Number(get_num_pixels(image))\n",
    "        \n",
    "        # Randomly sample pixels in the image at native resolution into a FeatureCollection\n",
    "        input_collection = image.sample(numPixels=num_samples.min(image_pixels))\n",
    "        n = input_collection.size()\n",
    "        m = feature_list.length()\n",
    "        \n",
    "        # Use an aggregate array function over the FeatureCollection and map the function over each feature in the band list\n",
    "        # to generate a dictionary of all of the samples retrieved\n",
    "        inputs = ee.Dictionary.fromLists(full_band_list, full_band_list.map(lambda feature: input_collection.aggregate_array(feature)))\n",
    "        \n",
    "        # Although we may call our scale_image function on the input image, the reduceRegion() function used to determine the mean\n",
    "        # and standard deviation of each band in the image over the entire region is not precise enough over a large image\n",
    "        # so we must recenter all of the bands in the image and now we can also normalize (L2 norm) each input feature as required\n",
    "        # by the LARs algorithm\n",
    "        \n",
    "        # Use an aggregate_mean function over the feature collection to get the mean of each band\n",
    "        input_means = ee.Dictionary.fromLists(full_band_list, full_band_list.map(lambda feature: input_collection.aggregate_mean(feature)))\n",
    "\n",
    "        def centre_inputs(key, value):\n",
    "            key_mean = input_means.getNumber(key)\n",
    "            return ee.List(value).map(lambda sample: ee.Number(sample).subtract(key_mean))\n",
    "        \n",
    "        \n",
    "        # Center bands by mapping over the list of features and then a subtracting over the list of samples for each band\n",
    "        inputs = inputs.map(centre_inputs)\n",
    "\n",
    "        # Separate the response variable samples into its own vector\n",
    "        y = inputs.toArray([response_band]).reshape([-1,1])\n",
    "\n",
    "        # Remove response band from the feature collection by selecting only bands in the feature list\n",
    "        inputs = inputs.select(feature_list)\n",
    "        \n",
    "        # Generate a dictionary of all of the L2 norms of the input features using a custom mapped function\n",
    "        input_norms = inputs.map(lambda key, value: ee.Number(ee.List(value).map(lambda sample: ee.Number(sample).pow(2)).reduce(ee.Reducer.sum())).pow(0.5))\n",
    "\n",
    "        def norm_inputs(key, value):\n",
    "            key_norm = input_norms.getNumber(key)\n",
    "            return ee.List(value).map(lambda sample: ee.Number(sample).divide(key_norm))\n",
    "        \n",
    "        # Normalize all of the features by mapping a function over the list of features\n",
    "        # and then map a division over the list of all of the samples of the feature\n",
    "        inputs = inputs.map(norm_inputs)\n",
    "        \n",
    "        # Generate the array of samples using the dictionary\n",
    "        X = inputs.toArray(feature_list).transpose()\n",
    "\n",
    "        # Find the first best predictor of the response to initialize the main LARs loop\n",
    "        initial_prediction = ee.Array(ee.List.repeat([0], n))\n",
    "        c = X.transpose().matrixMultiply(y.subtract(initial_prediction))\n",
    "        c_abs = c.abs()\n",
    "        C_maxLoc = c_abs.project([0]).argmax()\n",
    "        add_feature = C_maxLoc.getNumber(0)\n",
    "        A = ee.List([add_feature])\n",
    "        \n",
    "        # Create a dicitionary of initial inputs to pass into the main LARs iterative loop\n",
    "        # The iterate function in Earth Engine processes each iteration as a tree of iterations with no access to any variables\n",
    "        # from previous iterations (only those that are passed to the next iteration)\n",
    "        # so we must pass both the current prediction and the active set of features (with non-zero coefficients), A\n",
    "        initial_inputs = ee.Dictionary({'prediction': initial_prediction, 'A': A})\n",
    "\n",
    "        def LARs_regression(iteration, inputs):\n",
    "            inputs = ee.Dictionary(inputs)\n",
    "\n",
    "            # Find the active set of features, A (predictors with non-zero coefficients)\n",
    "            A = ee.List(inputs.get('A'))\n",
    "            # A_list is an array used to mask the full array of input samples and the correlation vector\n",
    "            A_list = ee.Array(ee.List.sequence(0, m.subtract(1))\\\n",
    "                              .map(lambda index: A.contains(index)).replaceAll(False, 0).replaceAll(True, 1)).reshape([-1,1])\n",
    "\n",
    "            # The following matrix algebra determines the next most correlated variable, or the next best predictor considering the\n",
    "            # current features in the active set, A, as well as the magnitude to adjust the prediction vector to ensure all of the\n",
    "            # features in the active set are equally correlated to response vector\n",
    "            prediction = inputs.getArray('prediction')\n",
    "            c = X.transpose().matrixMultiply(y.subtract(prediction))\n",
    "            c_abs = c.abs()\n",
    "            C_max = c_abs.get(c_abs.argmax())\n",
    "            s_A = c.divide(c_abs).mask(A_list)\n",
    "            X_A = X.mask(A_list.transpose())\n",
    "            G_Ai = X_A.transpose().matrixMultiply(X_A).matrixInverse()\n",
    "            G1 = G_Ai.matrixMultiply(s_A)\n",
    "            A_A = s_A.project([0]).dotProduct(G1.project([0])).pow(-0.5)\n",
    "            w_A = G1.multiply(A_A)\n",
    "            u_A = X_A.matrixMultiply(w_A)\n",
    "            a = X.transpose().matrixMultiply(u_A)\n",
    "            a = a.project([0])\n",
    "            c = c.project([0])\n",
    "\n",
    "            def compute_gammaArray(index_j):\n",
    "                minus_j = C_max.subtract(c.get([index_j])).divide(A_A.subtract(a.get([index_j])))\n",
    "                plus_j = C_max.add(c.get([index_j])).divide(A_A.add(a.get([index_j])))\n",
    "                return ee.List([minus_j, plus_j]).filter(ee.Filter.gte('item', 0)).reduce(ee.Reducer.min())\n",
    "\n",
    "            A_c = ee.List.sequence(0, m.subtract(1)).removeAll(A)\n",
    "            gammaArray = A_c.map(compute_gammaArray)\n",
    "            gamma = gammaArray.reduce(ee.Reducer.min())\n",
    "            min_location = gammaArray.indexOf(gamma)\n",
    "            add_feature = A_c.getNumber(min_location)\n",
    "\n",
    "            # Update active set of variables with next best predictor from non-active set and update prediction vector\n",
    "            A = A.add(add_feature)\n",
    "            prediction = prediction.add(u_A.multiply(gamma))\n",
    "\n",
    "            return ee.Dictionary({'prediction': prediction, 'A': A})\n",
    "\n",
    "\n",
    "        # The final iteration of LARs (if selecting all input variables) requires a different method to determine magnitude for\n",
    "        # adjusting the magnitude of the prediction vector, as the regular LARs iteration relies on variables in non-active set\n",
    "        # In the final iteration there will be no variables in the non-active set, so the method will not work\n",
    "        def LARs_final_iteration(iteration, inputs):\n",
    "            inputs = ee.Dictionary(inputs)\n",
    "            A = ee.List(inputs.get('A'))\n",
    "\n",
    "            prediction = inputs.getArray('prediction')\n",
    "            c = X.transpose().matrixMultiply(y.subtract(prediction))\n",
    "            c_abs = c.abs()\n",
    "            C_max = c_abs.get(c_abs.argmax())        \n",
    "\n",
    "            s_A = c.divide(c_abs)\n",
    "            G_Ai = X.transpose().matrixMultiply(X).matrixInverse()\n",
    "            G1 = G_Ai.matrixMultiply(s_A)\n",
    "            A_A = s_A.project([0]).dotProduct(G1.project([0])).pow(-0.5)\n",
    "            w_A = G1.multiply(A_A)\n",
    "            u_A = X.matrixMultiply(w_A)\n",
    "\n",
    "            gamma = C_max.divide(A_A)\n",
    "            prediction = prediction.add(u_A.multiply(gamma))\n",
    "\n",
    "            return ee.Dictionary({'prediction': prediction, 'A': A})\n",
    "\n",
    "        # Actually carrying out the iterations by iterating over a placeholder list (sequence from 1 to the number of non-zero\n",
    "        # variables that the user wishes to select as predictors for the response)\n",
    "        iterations = ee.List.sequence(1, m.subtract(1).min(num_nonzero_coefficients))\n",
    "        penultimate_outputs = iterations.iterate(LARs_regression, initial_inputs)\n",
    "        final_outputs = ee.Dictionary(ee.Algorithms.If(num_nonzero_coefficients.gte(m), \\\n",
    "                                LARs_final_iteration(m, penultimate_outputs), penultimate_outputs))\n",
    "        \n",
    "        final_prediction = final_outputs.getArray('prediction')\n",
    "\n",
    "        A = ee.List(final_outputs.get('A'))\n",
    "\n",
    "        feature_path = A.slice(0, num_nonzero_coefficients).map(lambda index: feature_list.getString(index))        \n",
    "        return feature_path\n",
    "\n",
    "    \n",
    "    select_features = ee_LARS(scaledImage, input_bandNames, responseBand, 5, 50000)\n",
    "    #unclassified = ee.Image(cloud_folder+'/'+siteSelect+'_'+outputName+'_VI')\n",
    "    unclassified = ee.Image(inputImage)\n",
    "    # bands = ee.List([responseBand, 'GI', 'SGI', 'GVI', 'NDVI3', 'NDVI', 'GNDVI', 'NDGI',\n",
    "    #                  'EVI', 'EVI2', 'RDVI', 'MSR', 'MSAVI2', 'NLI', 'B2', 'B3', 'B4', 'B8',\n",
    "    #                  'QA60', 'date', 'partition', 'networkID', 'error'+outputName, 'partition_1', 'networkID_1'])\n",
    "    bands = ee.List([responseBand, 'GI', 'SGI', 'GVI', 'NDVI3', 'NDVI', 'GNDVI', 'NDGI',\n",
    "                     'EVI', 'EVI2', 'RDVI', 'MSR', 'MSAVI2', 'NLI', 'B2', 'B3', 'B4', 'B8',\n",
    "                     'partition', 'networkID', 'error'+outputName, 'partition_1', 'networkID_1'])\n",
    "    unclassified = unclassified.rename(bands)\n",
    "\n",
    "    # prediction bands (equivalent to select_features, with responseBand)\n",
    "    bands = select_features\n",
    "    input_bands = select_features.add(responseBand)\n",
    "    training_data = ee.FeatureCollection(unclassified.sample(numPixels=1000, seed=1).select(input_bands))\n",
    "    # implement regression tree with Random Forest algorithm\n",
    "    # optional parameters for smileRandomForest(): variablesPerSplit, minLeafPopulation, bagFraction, maxNodes, seed\n",
    "    rf_classifier = ee.Classifier.smileRandomForest(100).setOutputMode('REGRESSION').train(features=training_data,\n",
    "                                                                                           classProperty=responseBand,\n",
    "                                                                                           inputProperties=input_bands)\n",
    "    rf_classified = unclassified.select(bands).classify(rf_classifier, 'ALR_'+responseBand).clip(mapBounds)\n",
    "    return temp_image.addBands(rf_classified)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "## use a biophysical parameter result as an input\n",
    "\n",
    "parent_directory = 'users/ccrs12fy2022simha/DOWNSCALING_PROCESS/3_DSEN2_S2/SOL_A/'\n",
    "\n",
    "#use = \n",
    "# assetname='20190826T153819_20190826T154455_T18TYN_HOPB_LAI_DSen2_20m_net'\n",
    "# assetname='20210808T154809_20210808T155521_T18SUJ_SERC_LAI_DSen2_20m_net'\n",
    "# assetname='20190608T164849_20190608T165019_T15TYL_STEI_LAI_DSen2_20m_net'\n",
    "# assetname='20190606T165901_20190606T170333_T16TCS_UNDE_LAI_DSen2_20m_net'\n",
    "# assetname='20200713T170901_20200713T171937_T14SQJ_MCDI_LAI_DSen2_20m_net'\n",
    "# assetname='20210422T162829_20210422T163638_T16SCA_LENO_LAI_DSen2_20m_net'\n",
    "# assetname=20200627T173909_20200627T174744_T14TLS_NOGP_LAI_DSen2_20m_net'\n",
    "# assetname='20190822T173909_20190822T175453_T13SCS_JORN_LAI_DSen2_20m_net'\n",
    "# assetname='20210401T183919_20210401T184709_T11SKB_SJER_LAI_DSen2_20m_net'\n",
    "\n",
    "#ABBY, HOPB, SERC, STEI, UNDE, MCDI,LENO, NOGP,JORN, SJER\n",
    "\n",
    "#example\n",
    "# assetname='users/GangHong2/Dsen/20210719T190919_20210719T191700_T10TER_ABBY_LAI_DSen2_20m_net'\n",
    "\n",
    "len_parent_directory = len(parent_directory)\n",
    "img=ee.Image(parent_directory+assetname)\n",
    "mapBounds=img.geometry()\n",
    "# print(output_Name)\n",
    "output_Name=assetname[len_parent_directory:]+'_ALR' ### index number neeed to be adjusted to get the meaningful file name '20210719T190919_20210719T191700_T10TER_ABBY_LAI_DSen2_20m_net_ALR'20210401T183919_20210401T184709_T11SKB_SJER_LAI_DSen2_20m_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputName = 'LAI'\n",
    "responseBand = 'estimate'+outputName\n",
    "ALR_result=func_ALR(img, responseBand, outputName, mapBounds)\n",
    "# print (ALR_result.bandNames().getInfo())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export formatted image to GEE asset \n",
    "# assetfolder='users/GangHong2/ALR'\n",
    "export = ee.ImageCollection(ALR_result)\n",
    "export_task = ee_func.export_collection_to_gee(collection=export,\n",
    "                                                 num_images=1,                                                                                              \n",
    "                                                 # image_names=[siteSelect+'_'+outputName+'_ALR'],\n",
    "                                                 image_names=[output_Name],\n",
    "                                                 asset_folder=assetfolder_SOL_C,                                                 \n",
    "                                                 scale=10,\n",
    "                                                 data_type='float',\n",
    "                                                 max_pixels=1e13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Part C: Validation of solutions "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "## make a dictionry list for reference image and the image to be compared based on site \n",
    "input_list=[\n",
    "{'site':'ABBY',\n",
    " 'ref':'users/ccrs12fy2022simha/DOWNSCALING_PROCESS/1_NEON10/REF/NEON_D16_ABBY_DP1_20210719_191207_reflectance_10m_LAI_20m_net',\n",
    " 'null':'users/ccrs12fy2022simha/DOWNSCALING_PROCESS/2_NEON20/NULL/NEON_D16_ABBY_DP1_20210719_191207_reflectance_20m_LAI_20m_net',\n",
    " 'sol_a':'users/ccrs12fy2022simha/DOWNSCALING_PROCESS/3_DSEN2_S2/SOL_A/20210719T190919_20210719T191700_T10TER_ABBY_LAI_DSen2_20m_net',\n",
    " 'sol_b':'users/ccrs12fy2022simha/DOWNSCALING_PROCESS/1_NEON10/SOL_B/NEON_D16_ABBY_DP1_20210719_191207_reflectance_10m_LAI_10m_net',\n",
    " 'sol_c':'users/ccrs12fy2022simha/DOWNSCALING_PROCESS/5_ALR/SOL_C/20210719T190919_20210719T191700_T10TER_ABBY_LAI_DSen2_20m_net_ALR',\n",
    " 'res_d':'users/ccrs12fy2022simha/DOWNSCALING_PROCESS/3_DSEN2_S2/RES_D/20210719T190919_20210719T191700_T10TER_ABBY_LAI_DSen2_10m_net',\n",
    " 'res_e':'users/ccrs12fy2022simha/DOWNSCALING_PROCESS/4_S2/RES_E/20210719T190919_20210719T191700_T10TER_ABBY_LAI_S2_20m_net',\n",
    " 'res_f':'users/ccrs12fy2022simha/DOWNSCALING_PROCESS/4_S2/RES_F/20210719T190919_20210719T191700_T10TER_ABBY_LAI_S2_10m_net'},\n",
    "{'site':'SJER',\n",
    " 'ref':'users/ccrs12fy2022simha/DOWNSCALING_PROCESS/1_NEON10/REF/NEON_D17_SJER_DP1_20210331_200812_reflectance_10m_LAI_20m_net',\n",
    " 'null':'users/ccrs12fy2022simha/DOWNSCALING_PROCESS/2_NEON20/NULL/NEON_D17_SJER_DP1_20210331_200812_reflectance_20m_LAI_20m_net',\n",
    " 'sol_a':'users/ccrs12fy2022simha/DOWNSCALING_PROCESS/3_DSEN2_S2/SOL_A/20210401T183919_20210401T184709_T11SKB_SJER_LAI_DSen2_20m_net',\n",
    " 'sol_b':'users/ccrs12fy2022simha/DOWNSCALING_PROCESS/1_NEON10/SOL_B/NEON_D17_SJER_DP1_20210331_200812_reflectance_10m_LAI_10m_net',\n",
    " 'sol_c':'users/ccrs12fy2022simha/DOWNSCALING_PROCESS/5_ALR/SOL_C/20210401T183919_20210401T184709_T11SKB_SJER_LAI_DSen2_20m_net_ALR',\n",
    " 'res_d':'users/ccrs12fy2022simha/DOWNSCALING_PROCESS/3_DSEN2_S2/RES_D/20210401T183919_20210401T184709_T11SKB_SJER_LAI_DSen2_10m_net',\n",
    " 'res_e':'users/ccrs12fy2022simha/DOWNSCALING_PROCESS/4_S2/RES_E/20210401T183919_20210401T184709_T11SKB_SJER_LAI_S2_20m_net',\n",
    " 'res_f':'users/ccrs12fy2022simha/DOWNSCALING_PROCESS/4_S2/RES_F/20210401T183919_20210401T184709_T11SKB_SJER_LAI_S2_10m_net'},\n",
    "{'site':'JORN',\n",
    " 'ref':'users/ccrs12fy2022simha/DOWNSCALING_PROCESS/1_NEON10/REF/NEON_D14_JORN_DP1_20190825_165611_reflectance_10m_LAI_20m_net',\n",
    "  'null':'users/ccrs12fy2022simha/DOWNSCALING_PROCESS/2_NEON20/NULL/NEON_D14_JORN_DP1_20190825_165611_reflectance_20m_LAI_20m_net',\n",
    " 'sol_a':'users/ccrs12fy2022simha/DOWNSCALING_PROCESS/3_DSEN2_S2/SOL_A/20190822T173909_20190822T175453_T13SCS_JORN_LAI_DSen2_20m_net',\n",
    " 'sol_b':'users/ccrs12fy2022simha/DOWNSCALING_PROCESS/1_NEON10/SOL_B/NEON_D14_JORN_DP1_20190825_165611_reflectance_10m_LAI_10m_net',\n",
    " 'sol_c':'users/ccrs12fy2022simha/DOWNSCALING_PROCESS/5_ALR/SOL_C/20190822T173909_20190822T175453_T13SCS_JORN_LAI_DSen2_20m_net_ALR',\n",
    " 'res_d':'users/ccrs12fy2022simha/DOWNSCALING_PROCESS/3_DSEN2_S2/RES_D/20190822T173909_20190822T175453_T13SCS_JORN_LAI_DSen2_10m_net',\n",
    " 'res_e':'users/ccrs12fy2022simha/DOWNSCALING_PROCESS/4_S2/RES_E/20190822T173909_20190822T175453_T13SCS_JORN_LAI_S2_20m_net',\n",
    " 'res_f':'users/ccrs12fy2022simha/DOWNSCALING_PROCESS/4_S2/RES_F/20190822T173909_20190822T175453_T13SCS_JORN_LAI_S2_10m_net'},\n",
    "{'site':'NOGP',\n",
    " 'ref':'users/ccrs12fy2022simha/DOWNSCALING_PROCESS/1_NEON10/REF/NEON_D09_NOGP_DP1_20200626_152700_reflectance_10m_LAI_20m_net',\n",
    " 'null':'users/ccrs12fy2022simha/DOWNSCALING_PROCESS/2_NEON20/NULL/NEON_D09_NOGP_DP1_20200626_152700_reflectance_20m_LAI_20m_net',\n",
    " 'sol_a':'users/ccrs12fy2022simha/DOWNSCALING_PROCESS/3_DSEN2_S2/SOL_A/20200627T173909_20200627T174744_T14TLS_NOGP_LAI_DSen2_20m_net',\n",
    " 'sol_b':'users/ccrs12fy2022simha/DOWNSCALING_PROCESS/1_NEON10/SOL_B/NEON_D09_NOGP_DP1_20200626_152700_reflectance_10m_LAI_10m_net',\n",
    " 'sol_c':'users/ccrs12fy2022simha/DOWNSCALING_PROCESS/5_ALR/SOL_C/20200627T173909_20200627T174744_T14TLS_NOGP_LAI_DSen2_20m_net_ALR',\n",
    " 'res_d':'users/ccrs12fy2022simha/DOWNSCALING_PROCESS/3_DSEN2_S2/RES_D/20200627T173909_20200627T174744_T14TLS_NOGP_LAI_DSen2_10m_net',\n",
    " 'res_e':'users/ccrs12fy2022simha/DOWNSCALING_PROCESS/4_S2/RES_E/20200627T173909_20200627T174744_T14TLS_NOGP_LAI_S2_20m_net',\n",
    " 'res_f':'users/ccrs12fy2022simha/DOWNSCALING_PROCESS/4_S2/RES_F/20200627T173909_20200627T174744_T14TLS_NOGP_LAI_S2_10m_net'},\n",
    "{'site':'LENO',\n",
    " 'ref':'users/ccrs12fy2022simha/DOWNSCALING_PROCESS/1_NEON10/REF/NEON_D08_LENO_DP1_20210422_172136_reflectance_10m_LAI_20m_net',\n",
    " 'null':'users/ccrs12fy2022simha/DOWNSCALING_PROCESS/2_NEON20/NULL/NEON_D08_LENO_DP1_20210422_172136_reflectance_20m_LAI_20m_net',\n",
    " 'sol_a':'users/ccrs12fy2022simha/DOWNSCALING_PROCESS/3_DSEN2_S2/SOL_A/20210422T162829_20210422T163638_T16SCA_LENO_LAI_DSen2_20m_net',\n",
    " 'sol_b':'users/ccrs12fy2022simha/DOWNSCALING_PROCESS/1_NEON10/SOL_B/NEON_D08_LENO_DP1_20210422_172136_reflectance_10m_LAI_10m_net',\n",
    " 'sol_c':'users/ccrs12fy2022simha/DOWNSCALING_PROCESS/5_ALR/SOL_C/20210422T162829_20210422T163638_T16SCA_LENO_LAI_DSen2_20m_net_ALR',\n",
    " 'res_d':'users/ccrs12fy2022simha/DOWNSCALING_PROCESS/3_DSEN2_S2/RES_D/20210422T162829_20210422T163638_T16SCA_LENO_LAI_DSen2_10m_net',\n",
    " 'res_e':'users/ccrs12fy2022simha/DOWNSCALING_PROCESS/4_S2/RES_E/20210422T162829_20210422T163638_T16SCA_LENO_LAI_S2_20m_net',\n",
    " 'res_f':'users/ccrs12fy2022simha/DOWNSCALING_PROCESS/4_S2/RES_F/20210422T162829_20210422T163638_T16SCA_LENO_LAI_S2_10m_net'},\n",
    "{'site':'MCDI',\n",
    " 'ref':'users/ccrs12fy2022simha/DOWNSCALING_PROCESS/1_NEON10/REF/NEON_D06_MCDI_DP1_20200713_192937_reflectance_10m_LAI_20m_net',\n",
    " 'null':'users/ccrs12fy2022simha/DOWNSCALING_PROCESS/2_NEON20/NULL/NEON_D06_MCDI_DP1_20200713_192937_reflectance_20m_LAI_20m_net',\n",
    " 'sol_a':'users/ccrs12fy2022simha/DOWNSCALING_PROCESS/3_DSEN2_S2/SOL_A/20200713T170901_20200713T171937_T14SQJ_MCDI_LAI_DSen2_20m_net',\n",
    " 'sol_b':'users/ccrs12fy2022simha/DOWNSCALING_PROCESS/1_NEON10/SOL_B/NEON_D06_MCDI_DP1_20200713_192937_reflectance_10m_LAI_10m_net',\n",
    " 'sol_c':'users/ccrs12fy2022simha/DOWNSCALING_PROCESS/5_ALR/SOL_C/20200713T170901_20200713T171937_T14SQJ_MCDI_LAI_DSen2_20m_net_ALR',\n",
    " 'res_d':'users/ccrs12fy2022simha/DOWNSCALING_PROCESS/3_DSEN2_S2/RES_D/20200713T170901_20200713T171937_T14SQJ_MCDI_LAI_DSen2_10m_net',\n",
    " 'res_e':'users/ccrs12fy2022simha/DOWNSCALING_PROCESS/4_S2/RES_E/20200713T170901_20200713T171937_T14SQJ_MCDI_LAI_S2_20m_net',\n",
    " 'res_f':'users/ccrs12fy2022simha/DOWNSCALING_PROCESS/4_S2/RES_F/20200713T170901_20200713T171937_T14SQJ_MCDI_LAI_S2_10m_net'},\n",
    "{'site':'UNDE',\n",
    " 'ref':'users/ccrs12fy2022simha/DOWNSCALING_PROCESS/1_NEON10/REF/NEON_D05_UNDE_DP1_20190606_184411_reflectance_10m_LAI_20m_net',\n",
    " 'null':'users/ccrs12fy2022simha/DOWNSCALING_PROCESS/2_NEON20/NULL/NEON_D05_UNDE_DP1_20190606_184411_reflectance_20m_LAI_20m_net',\n",
    " 'sol_a':'users/ccrs12fy2022simha/DOWNSCALING_PROCESS/3_DSEN2_S2/SOL_A/20190606T165901_20190606T170333_T16TCS_UNDE_LAI_DSen2_20m_net',\n",
    " 'sol_b':'users/ccrs12fy2022simha/DOWNSCALING_PROCESS/1_NEON10/SOL_B/NEON_D05_UNDE_DP1_20190606_184411_reflectance_10m_LAI_10m_net',\n",
    " 'sol_c':'users/ccrs12fy2022simha/DOWNSCALING_PROCESS/5_ALR/SOL_C/20190606T165901_20190606T170333_T16TCS_UNDE_LAI_DSen2_20m_net_ALR',\n",
    " 'res_d':'users/ccrs12fy2022simha/DOWNSCALING_PROCESS/3_DSEN2_S2/RES_D/20190606T165901_20190606T170333_T16TCS_UNDE_LAI_DSen2_10m_net',\n",
    " 'res_e':'users/ccrs12fy2022simha/DOWNSCALING_PROCESS/4_S2/RES_E/20190606T165901_20190606T170333_T16TCS_UNDE_LAI_S2_20m_net',\n",
    " 'res_f':'users/ccrs12fy2022simha/DOWNSCALING_PROCESS/4_S2/RES_F/20190606T165901_20190606T170333_T16TCS_UNDE_LAI_S2_10m_net'},  \n",
    "{'site':'STEI',\n",
    " 'ref':'users/ccrs12fy2022simha/DOWNSCALING_PROCESS/1_NEON10/REF/NEON_D05_STEI_DP1_20190608_194643_reflectance_10m_LAI_20m_net',\n",
    " 'null':'users/ccrs12fy2022simha/DOWNSCALING_PROCESS/2_NEON20/NULL/NEON_D05_STEI_DP1_20190608_194643_reflectance_20m_LAI_20m_net',\n",
    " 'sol_a':'users/ccrs12fy2022simha/DOWNSCALING_PROCESS/3_DSEN2_S2/SOL_A/20190608T164849_20190608T165019_T15TYL_STEI_LAI_DSen2_20m_net',\n",
    " 'sol_b':'users/ccrs12fy2022simha/DOWNSCALING_PROCESS/1_NEON10/SOL_B/NEON_D05_STEI_DP1_20190608_194643_reflectance_10m_LAI_10m_net',\n",
    " 'sol_c':'users/ccrs12fy2022simha/DOWNSCALING_PROCESS/5_ALR/SOL_C/20190608T164849_20190608T165019_T15TYL_STEI_LAI_DSen2_20m_net_ALR',\n",
    " 'res_d':'users/ccrs12fy2022simha/DOWNSCALING_PROCESS/3_DSEN2_S2/RES_D/20190608T164849_20190608T165019_T15TYL_STEI_LAI_DSen2_10m_net',\n",
    " 'res_e':'users/ccrs12fy2022simha/DOWNSCALING_PROCESS/4_S2/RES_E/20190608T164849_20190608T165019_T15TYL_STEI_LAI_S2_20m_net',\n",
    " 'res_f':'users/ccrs12fy2022simha/DOWNSCALING_PROCESS/4_S2/RES_F/20190608T164849_20190608T165019_T15TYL_STEI_LAI_S2_10m_net'},\n",
    "{'site':'SERC',\n",
    " 'ref':'users/ccrs12fy2022simha/DOWNSCALING_PROCESS/1_NEON10/REF/NEON_D02_SERC_DP1_20210811_142655_reflectance_10m_LAI_20m_net',\n",
    " 'null':'users/ccrs12fy2022simha/DOWNSCALING_PROCESS/2_NEON20/NULL/NEON_D02_SERC_DP1_20210811_142655_reflectance_20m_LAI_20m_net',\n",
    " 'sol_a':'users/ccrs12fy2022simha/DOWNSCALING_PROCESS/3_DSEN2_S2/SOL_A/20210808T154809_20210808T155521_T18SUJ_SERC_LAI_DSen2_20m_net',\n",
    " 'sol_b':'users/ccrs12fy2022simha/DOWNSCALING_PROCESS/1_NEON10/SOL_B/NEON_D02_SERC_DP1_20210811_142655_reflectance_10m_LAI_10m_net',\n",
    " 'sol_c':'users/ccrs12fy2022simha/DOWNSCALING_PROCESS/5_ALR/SOL_C/20210808T154809_20210808T155521_T18SUJ_SERC_LAI_DSen2_20m_net_ALR',\n",
    " 'res_d':'users/ccrs12fy2022simha/DOWNSCALING_PROCESS/3_DSEN2_S2/RES_D/20210808T154809_20210808T155521_T18SUJ_SERC_LAI_DSen2_10m_net',\n",
    " 'res_e':'users/ccrs12fy2022simha/DOWNSCALING_PROCESS/4_S2/RES_E/20210808T154809_20210808T155521_T18SUJ_SERC_LAI_S2_20m_net',\n",
    " 'res_f':'users/ccrs12fy2022simha/DOWNSCALING_PROCESS/4_S2/RES_F/20210808T154809_20210808T155521_T18SUJ_SERC_LAI_S2_10m_net'},\n",
    "{'site':'HOPB',\n",
    " 'ref':'users/ccrs12fy2022simha/DOWNSCALING_PROCESS/1_NEON10/REF/NEON_D01_HOPB_DP1_20190826_172857_reflectance_10m_LAI_20m_net',\n",
    " 'null':'users/ccrs12fy2022simha/DOWNSCALING_PROCESS/2_NEON20/NULL/NEON_D01_HOPB_DP1_20190826_172857_reflectance_20m_LAI_20m_net',\n",
    " 'sol_a':'users/ccrs12fy2022simha/DOWNSCALING_PROCESS/3_DSEN2_S2/SOL_A/20190826T153819_20190826T154455_T18TYN_HOPB_LAI_DSen2_20m_net',\n",
    " 'sol_b':'users/ccrs12fy2022simha/DOWNSCALING_PROCESS/1_NEON10/SOL_B/NEON_D01_HOPB_DP1_20190826_172857_reflectance_10m_LAI_10m_net',\n",
    " 'sol_c':'users/ccrs12fy2022simha/DOWNSCALING_PROCESS/5_ALR/SOL_C/20190826T153819_20190826T154455_T18TYN_HOPB_LAI_DSen2_20m_net_ALR',\n",
    " 'res_d':'users/ccrs12fy2022simha/DOWNSCALING_PROCESS/3_DSEN2_S2/RES_D/20190826T153819_20190826T154455_T18TYN_HOPB_LAI_DSen2_10m_net',\n",
    " 'res_e':'users/ccrs12fy2022simha/DOWNSCALING_PROCESS/4_S2/RES_E/20190826T153819_20190826T154455_T18TYN_HOPB_LAI_S2_20m_net',\n",
    " 'res_f':'users/ccrs12fy2022simha/DOWNSCALING_PROCESS/4_S2/RES_F/20190826T153819_20190826T154455_T18TYN_HOPB_LAI_S2_10m_net'}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1 - Evaluation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation_function(scale_x, scale_y,image1_name, image2_name,output_file):\n",
    "    ## create a empty data frame\n",
    "    df_scale = pd.DataFrame()#    df_scale = pd.DataFrame(columns=['site','RMSE','SSIM','R2'])\n",
    "\n",
    "    ## a loop for each site\n",
    "    arr = []\n",
    "    for input in input_list:\n",
    "        site=input.get('site')\n",
    "        ## get the orignal 10m data from reference image and arregate to scale\n",
    "        ref_img=ee.Image(input.get(image1_name))\n",
    "        proj_scale_ref= ref_img.projection().scale(scale_x, scale_y) \n",
    "        # print (proj_30m_ref.getInfo())\n",
    "        ref_img_scale=ref_img.select('estimateLAI').reduceResolution(\n",
    "            **{\n",
    "              'reducer': ee.Reducer.mean(),\n",
    "              'maxPixels': 1112\n",
    "            }) \\\n",
    "            .reproject(\n",
    "                **{\n",
    "              'crs': proj_scale_ref\n",
    "            }).rename('first_scale_LAI')\n",
    "         ## get the orignal 10m data from the image to be compared and arregate to scale\n",
    "        comp_img=ee.Image(input.get(image2_name))  \n",
    "        proj_scale_comp=comp_img.projection().scale(scale_x, scale_y) \n",
    "        comp_img_scale=comp_img.select('estimateLAI').reduceResolution(\n",
    "            **{\n",
    "              'reducer': ee.Reducer.mean(),\n",
    "              'maxPixels': 1112\n",
    "            }) \\\n",
    "            .reproject(\n",
    "                **{\n",
    "              'crs': proj_scale_comp\n",
    "            }).rename('second_scale_LAI')\n",
    "       ## genreate a new image to combine scale reference image and the image to be compared\n",
    "        input_img_scale=ref_img_scale.select('first_scale_LAI').addBands(comp_img_scale.select('second_scale_LAI'))\n",
    "        ## generate samples\n",
    "        samples_feat_scale = ee.FeatureCollection(input_img_scale.sample(numPixels=1000, seed=1))\n",
    "        ## get the property name of sample features\n",
    "        samples_col_scale=samples_feat_scale.first().propertyNames().getInfo()##.remove('system:index')\n",
    "        ## remove the property 'system:index'\n",
    "        samples_col_scale.remove('system:index')\n",
    "        # print (samples_colscale)\n",
    "        ## convert the data from ee.feature to data frame\n",
    "        sample_list_scale = samples_feat_scale.reduceColumns(ee.Reducer.toList(len(samples_col_scale)), samples_col_scale).values().get(0)\n",
    "        df2=pd.DataFrame(sample_list_scale.getInfo(), columns=samples_col_scale) \n",
    "        # print (df2.isnull().sum().sum()) ## check the sum of null in dataframe\n",
    "        # print (df2.head(10))\n",
    "        ## get the value for each column\n",
    "        ref_Vals = df2[samples_col_scale[0]]/1000\n",
    "        predict_Vals = df2[samples_col_scale[1]]/1000\n",
    "        ## RMSE\n",
    "        RMSE = mean_squared_error(ref_Vals, predict_Vals) \n",
    "        ## ssim\n",
    "        SSIM = ssim(ref_Vals, predict_Vals, data_range=(predict_Vals.max() - predict_Vals.min())) \n",
    "        ## R2\n",
    "        R2 = r2_score(ref_Vals, predict_Vals)\n",
    "        df_temp={'Site':site, 'RMSE': RMSE, 'SSIM':SSIM,'R2': R2}   \n",
    "        new_df = pd.DataFrame([df_temp])\n",
    "        ## append the result of the site to the data frame\n",
    "        df_scale = pd.concat([df_scale, new_df], axis=0, ignore_index=True)\n",
    "    # print(df_scale)\n",
    "    df_scale.to_csv(output_file,index=False)\n",
    "    return df_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation_function(1,1,\"ref\",\"sol_a\",'C:/Users/nkalimip/Downloads/NEON-main/NEON-main/evaluation/first.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2 - Final Evaluation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "# site_arr = [\"ABBY\", \"HOPB\", \"SERC\",\" STEI\", \"UNDE\",\" MCDI\",\"LENO\", \"NOGP\",\"JORN\",\"SJER\"]\n",
    "# evaluation_function(1,1,\"ref\",\"sol_a\",'C:/Users/nkalimip/Downloads/NEON-main/NEON-main/evaluation/first.csv')\n",
    "\n",
    "def final_evaluation():\n",
    "    solution_arr = ['null','ref','sol_a','sol_b','sol_c','res_d','res_e','res_f']\n",
    "    solution_arr.remove('ref')\n",
    "    # print(solution_arr_without_ref)\n",
    "    for counter in range (0,len(solution_arr)):\n",
    "        evaluation_function(1,1,\"ref\",solution_arr[counter],'C:/Users/nkalimip/Downloads/NEON-main/NEON-main/evaluation/unaggregated/ref_and_'+ solution_arr[counter]+'.csv')\n",
    "        evaluation_function(3,3,\"ref\",solution_arr[counter],'C:/Users/nkalimip/Downloads/NEON-main/NEON-main/evaluation/aggregated_30m/ref_and_'+ solution_arr[counter]+'.csv')   \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_evaluation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Part D: Estimate uncertainty of predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1 - Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 1.1 - Uncertanity of Random forest function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #// A Sentinel-2 surface reflectance image, reflectance bands selected,\n",
    "# # // serves as the source for training and prediction in this contrived example.\n",
    "# img = (ee.Image('COPERNICUS/S2_SR/20210109T185751_20210109T185931_T10SEG').select('B.*'))\n",
    "\n",
    "# #// ESA WorldCover land cover map, used as label source in classifier training.\n",
    "# lc = ee.Image('ESA/WorldCover/v100/2020')\n",
    "\n",
    "# #// Remap the land cover class values to a 0-based sequential series.\n",
    "# classValues = [10, 20, 30, 40, 50, 60, 70, 80, 90, 95, 100]\n",
    "# remapValues = ee.List.sequence(0, 10)\n",
    "# label = 'lc'\n",
    "# lc = (lc.remap(classValues, remapValues).rename(label).toByte())\n",
    "\n",
    "# # // Add land cover as a band of the reflectance image and sample 100 pixels at\n",
    "# # // 10 m scale from each land cover class within a region of interest.\n",
    "# roi = ee.Geometry.Rectangle(-122.347, 37.743, -122.024, 37.838)\n",
    "# sample = img.addBands(lc).stratifiedSample(\n",
    "#   numPoints= ee.Number(100),\n",
    "#   classBand= label,\n",
    "#   region= roi,\n",
    "#   scale= ee.Number(10),\n",
    "#   geometries= True\n",
    "# )\n",
    "\n",
    "# # // Add a random value field to the sample and use it to approximately split 80%\n",
    "# # // of the features into a training set and 20% into a validation set.\n",
    "# sample = sample.randomColumn()\n",
    "# trainingSample = sample.filter('random <= 0.8')\n",
    "# validationSample = sample.filter('random > 0.8')\n",
    "\n",
    "# # // Train a 10-tree random forest classifier from the training sample.\n",
    "# # //////////////////////////////////////////////////////////////////////////\n",
    "# # // The map() operation takes a function that works on each element independently\n",
    "# # // and returns a value. You define a function that can be applied to the input.\n",
    "\n",
    "# # // Constants\n",
    "# n_trees = 10\n",
    "# regressors = ['B4','B5','B6','B7']\n",
    "# response = 'B2'\n",
    "\n",
    "# defVis = {\n",
    "#   min: -100,\n",
    "# }\n",
    "\n",
    "\n",
    "def smileRandomForestU(img, trainingSample, band, n_trees,regressors,response,defVis):\n",
    "  trainedClassifier = ee.Classifier.smileRandomForest(n_trees).train(\n",
    "        features= trainingSample,\n",
    "        classProperty= response,\n",
    "        inputProperties= regressors,\n",
    "        subsampling= 0.5,\n",
    "        subsamplingSeed=0\n",
    "        ).setOutputMode(\"regression\") \n",
    "        \n",
    "  #print(trainedClassifier)     \n",
    "\n",
    "   #image_classified = img.classify(trainedClassifier)\n",
    "  image_classified  = img.select(band).classify(trainedClassifier, 'ALR_'+response)\n",
    "\n",
    "\n",
    "\n",
    "    # //////////////////////////////////////////////////////////////////////////////\n",
    "  # // trainedClassifier1  and classifiersmileRandomForest function\n",
    "  def trainedClassifier1(seed_no):\n",
    "    trainedClassifier = ee.Classifier.smileRandomForest(1).train(\n",
    "      features= trainingSample,\n",
    "      classProperty= response,\n",
    "      inputProperties= regressors,\n",
    "      subsampling= 0.5,\n",
    "      subsamplingSeed=seed_no\n",
    "      ).setOutputMode(\"regression\")  \n",
    "    return trainedClassifier\n",
    "\n",
    "\n",
    "  # ////////////////////////////////////////////////////////\n",
    "  # // Helper function to map a list of classifiers over an image\n",
    "  def classifyImg(img,classifier):\n",
    "    return img.select(band).classify(classifier)\n",
    "\n",
    "\n",
    "  # // This returns the requested reducer over each classifier\n",
    "  def classifyStats(reducer,trainedClassifier1,n_trees,img):\n",
    "\n",
    "      return (ee.ImageCollection(ee.List.sequence(0, n_trees-1)\n",
    "                                      .map(trainedClassifier1)\n",
    "                                      .map(lambda classifier: classifyImg(img,classifier)))\n",
    "                              .reduce(reducer))\n",
    "\n",
    "  # SL2P = ee.List.sequence(1,ee.Number(collectionOptions.get(\"numVariables\")),1).map(lambda netNum: wn.makeNetVars(collectionOptions.get(\"Collection_SL2P\"),numNets,netNum))\n",
    "  # // RF - my current solution but this should all accept all of the args for \n",
    "  # // .classify and .train so trainedClassifier1 is flexible\n",
    "\n",
    "  # // Get SEP value\n",
    "  SEP = classifyStats(ee.Reducer.sampleStdDev(),trainedClassifier1,10,img)\n",
    "  #print(\"SEP\",SEP)\n",
    "\n",
    "  # /// add the layer\n",
    "  # Map.addLayer(SEP,defVis, \"SEP\")\n",
    "\n",
    "  # ////////////////////////////////////////////\n",
    "  # // Richard SDN\n",
    "  # // Make RF classifier\n",
    "\n",
    "  # // This generates a list of numbers from 1 to n_trees.\n",
    "  myList = ee.List.sequence(0, n_trees-1)\n",
    "\n",
    "  def getSDNfunc(seed_no): \n",
    "      # //print(\"seed_no\",seed_no) \n",
    "      # //  seed_no =0\n",
    "    # // use existing trainedclasifier function\n",
    "      trainedClassifier = ee.Classifier.smileRandomForest(1).train(\n",
    "        features= trainingSample,\n",
    "        classProperty=response,\n",
    "        inputProperties= regressors,\n",
    "        subsampling= 0.5,\n",
    "        subsamplingSeed=seed_no\n",
    "        ).setOutputMode(\"regression\")  \n",
    "    \n",
    "    # //print(\"trainingSample\",trainingSample) \n",
    "    # //print(\"trainingSample response\",trainingSample.aggregate_array(response)) \n",
    "    # //print(\"trainingClassifier\",trainedClassifier.explain()) \n",
    "    \n",
    "    # // Apply the classifier to an image corresponding to the training sample\n",
    "      estimates = trainingSample.select(band).classify(trainedClassifier)\n",
    "    # //print(\"estimates\",estimates)\n",
    "    \n",
    "    # // Get unique output values\n",
    "      uniqueEstimates = estimates.aggregate_array('classification').distinct()\n",
    "    # //print(\"uniqueEstimates\",uniqueEstimates)\n",
    "    \n",
    "    # // // computes SDN of training samples that match unique estimate\n",
    "      def getSDN(trainingSample,response,estimate):\n",
    "        samples = (trainingSample.filter(ee.Filter.eq(\"classification\",estimate)).aggregate_array(response))\n",
    "      \n",
    "        return (ee.Number(samples.cat(samples).reduce(ee.Reducer.sampleStdDev())))\n",
    "    \n",
    "    \n",
    "    # // print(\"check\", estimates.filter(ee.Filter.eq(\"classification\",189)))\n",
    "    # // Get the trainingSample values for each unique estimate\n",
    "      sdnUniqueEstimates = uniqueEstimates.map(lambda uniqueEstimate: getSDN(estimates,response,uniqueEstimate))\n",
    "                                          # // .removeAll(ee.List([None]))\n",
    "    # //print(\"sdnUniqueEstimates\",sdnUniqueEstimates)\n",
    "    \n",
    "    # // Apply the classifer to image\n",
    "      imgEstimate = img.select(band).classify(trainedClassifier)\n",
    "    # //print(sdnUniqueEstimates)\n",
    "      imgSDNEstimate = imgEstimate.remap(uniqueEstimates,sdnUniqueEstimates,0)\n",
    "    # // Map.addLayer(imgEstimate)\n",
    "    # // Map.addLayer(imgSDNEstimate)\n",
    "    # // print(\"SDN\",imgSDNEstimate)\n",
    "    # // Map.addLayer(SDN,defVis,\"imgSDNEstimate\")\n",
    "      return imgSDNEstimate\n",
    "\n",
    "  # // Apply your function to each item in the list by using the map() function.\n",
    "  squares = myList.map(getSDNfunc)\n",
    "  #print(squares.get(0).getInfo()) \n",
    "\n",
    "  # # //apply function to firsttree\n",
    "  #  square1 = getSDNfunc2(myList.get(0))\n",
    "  # print(square1) \n",
    "\n",
    "  # # // Turn list to image collection\n",
    "  #  colPred1 = ee.ImageCollection(square1)\n",
    "  # //print(\"colPred\",colPred)\n",
    "  #  SDN1 = colPred1.reduce(ee.Reducer.mean())\n",
    "  # print(\"SDN1\",SDN1)\n",
    "  # Map.addLayer(SDN1,defVis,\"SDN1\")\n",
    "\n",
    "  # // Turn list to image collection\n",
    "  colPred = ee.ImageCollection(squares).toBands()\n",
    "  #print(\"colPred\",colPred)\n",
    "  # Map.addLayer(colPred,defVis,\"colpred\")\n",
    "  SDN = colPred.reduce(ee.Reducer.mean())\n",
    "\n",
    "  # print(\"SDN\",SDN)\n",
    "  # Map.addLayer(SDN,defVis,\"SDN\")\n",
    "\n",
    "  # //////////////////////////////////////////////////////////\n",
    "  SEP_2 = ee.Image(SEP).multiply(ee.Image(SEP))\n",
    "  # // Map.addLayer(SEP_2,defVis,\"SEP_2\")\n",
    "\n",
    "  SDN_2 = ee.Image(SDN).multiply(ee.Image(SDN))\n",
    "  # // Map.addLayer(SDN_2, defVis,\"SDN_2\" )\n",
    "\n",
    "  U = ee.Image(SEP_2).add(ee.Image(SDN_2))\n",
    "  # Map.addLayer(U,defVis,\"U\")\n",
    "  #print(\"U\", U)\n",
    "\n",
    "  # //////////////////////////////////////////////////////////\n",
    "  keys = ['SEP', 'SDN', 'U']\n",
    "  values = [SEP, SDN, U]\n",
    "\n",
    "  dict_of_pops = ee.Dictionary.fromLists(keys, values)\n",
    "  #print(dict_of_pops)\n",
    "  return image_classified.set(dict_of_pops)\n",
    "  #print(image_classified)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 1.2 - ALR Function with new code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ALR function for estimation,after feature selection, a simple random forest estiamte applied\n",
    "def func_ALR(temp_image, responsedBand, outputName, mapBounds):\n",
    "   \n",
    "    # inputImage = ee.Image(temp_image).select(1,2,3,7,22,23,27,28,29,30,31,32)\n",
    "    # inputImage = ee.Image(temp_image).select(1,2,3,7,16,17,18,19,20,21)\n",
    "    # inputImage_bands = ee.List(['B2', 'B3', 'B4', 'B8', 'QA60', 'date', 'estimate'+outputName, 'partition', 'networkID', 'error'+outputName, 'partition_1', 'networkID_1'])\n",
    "    inputImage_bands = ee.List(['B2', 'B3', 'B4', 'B8', 'estimate'+outputName, 'partition', 'networkID', 'error'+outputName, 'partition_1', 'networkID_1'])\n",
    "    # inputImage = inputImage.rename(inputImage_bands)\n",
    "    inputImage = ee.Image(temp_image).select(inputImage_bands)\n",
    "    input_VI_definition = ee.List([\n",
    "                                   \"GI      = b('B3')/b('B4')\",                               \n",
    "                                   \"SGI     = b('B8')/b('B4')\",                                \n",
    "                                   \"GVI     = (b('B8')/b('B3'))-1\",                             \n",
    "                                   \"NDVI3   = ((b('B8')-b('B4'))/(b('B8')))+b('B4')\",                                \n",
    "                                   \"NDVI    = (b('B8')-b('B4'))/(b('B8')+b('B4'))\",\n",
    "                                   \"GNDVI   = (b('B8')-b('B3'))/(b('B8')+b('B3'))\",                                \n",
    "                                   \"NDGI    = (b('B3')-b('B4'))/(b('B3')+b('B4'))\",                                 \n",
    "                                   \"EVI     = 2.5*((b('B8')-b('B4'))/(b('B8')+6*b('B4')-7.5*b('B3')+1))\",\n",
    "                                   \"EVI2    = 2.5*((b('B8')-b('B4'))/(b('B8')+2.4*b('B4')+1))\",\n",
    "                                   \"RDVI    = (b('B8')-b('B4'))/((b('B8')+b('B4'))**0.5)\",\n",
    "                                   \"MSR     = ((b('B8')/b('B4'))-1)/((b('B8')/b('B4'))**0.5+1)\",                            \n",
    "                                   \"MSAVI2  = 0.5*(2*b('B8')+1-((2*b('B8')+1)**2-8*(b('B8')-b('B4')))**0.5)\",                                \n",
    "                                   \"NLI     = ((b('B8')**2)-b('B4'))/((b('B8')**2)+b('B4'))\"])\n",
    "\n",
    "    # names of bands to pass to ALR method (excluding metadata and other non-spectral bands)\n",
    "    input_bandNames = ['B2', 'B3', 'B4', 'B8', 'GI', 'SGI', 'GVI', 'NDVI3', 'NDVI', 'GNDVI', 'NDGI', 'EVI', 'EVI2', 'RDVI', 'MSR', 'MSAVI2', 'NLI']\n",
    "    \n",
    "    def format_image(image, image_bands, response_band, VI_definition):\n",
    "        image = ee.Image(image)\n",
    "        image_bands = ee.List(image_bands)\n",
    "        response_band = ee.String(response_band)\n",
    "        VI_definition = ee.List(VI_definition)\n",
    "        \n",
    "        # image_bands specifices a list of the names of the bands used in defining the expressions for VIs in VI_definition\n",
    "        image = image.rename(image_bands).toDouble()\n",
    "        \n",
    "        # Generate an ImageCollection from a list of expressions defining a set of VIs using the bands available in the image\n",
    "        VIimageCollection = ee.ImageCollection(VI_definition.map(lambda expr: image.expression(expr)))\n",
    "        VIimage = VIimageCollection.toBands().regexpRename(\"[0-9]+_\", \"\")\n",
    "        \n",
    "        # Reorder the bands in the image so the response band is the first band in the image\n",
    "        feature_bands = image_bands.remove(response_band)\n",
    "        \n",
    "        return ee.Image(image.select(response_band).addBands(VIimage).addBands(image.select(feature_bands)))\n",
    "\n",
    "    \n",
    "    inputImage = format_image(inputImage, inputImage_bands, responseBand, input_VI_definition)\n",
    "    \n",
    "    def scale_image(image, response_band):\n",
    "        image = ee.Image(image)\n",
    "        response_band = ee.String(response_band)\n",
    "        \n",
    "        def get_num_pixels(image):\n",
    "    \n",
    "            # get image height\n",
    "            def get_height(image):\n",
    "                height = image.getInfo()[\"bands\"][0][\"dimensions\"][0]\n",
    "                return height\n",
    "\n",
    "            # get image width\n",
    "            def get_width(image):\n",
    "                width = image.getInfo()[\"bands\"][0][\"dimensions\"][1]\n",
    "                return width\n",
    "\n",
    "            image_height = get_height(image)\n",
    "            image_width = get_width(image)\n",
    "            image_pixels = image_height*image_width\n",
    "\n",
    "            return image_pixels\n",
    "        \n",
    "        image_pixels = ee.Number(get_num_pixels(image))\n",
    "        \n",
    "        # Set up lists containing the input/feature bands in the image\n",
    "        bandList = image.bandNames()\n",
    "        featureList = bandList.remove(response_band)\n",
    "        num_bands = bandList.length()\n",
    "        num_features = featureList.length()\n",
    "        \n",
    "        # We will be using the reduceRegion() function on images from Earth Engine, \n",
    "        # which will process up to a specified number of pixels from the image to generate the outputs of the reducer\n",
    "        max_pixels = image_pixels.min(10000000)\n",
    "        # best_effort = ee.Algorithms.If(image_pixels.gt(max_pixels), True, False)\n",
    "        \n",
    "        # Set default projection and scale using the response band\n",
    "        defaultScale = image.select(response_band).projection().nominalScale()\n",
    "        defaultCrs = image.select(response_band).projection().crs()\n",
    "        image = image.setDefaultProjection(crs=defaultCrs, scale=defaultScale)\n",
    "        \n",
    "        # Center all of the bands in the image for LARs\n",
    "        # We will centre the sampled data later as well as reduceRegion() is not precise enough\n",
    "        meanImage = image.subtract(image.reduceRegion(reducer=ee.Reducer.mean(), \\\n",
    "                                    scale=defaultScale, bestEffort=True, maxPixels=max_pixels).toImage(bandList))\n",
    "        \n",
    "        # Separate the image into features (X) and response (y) as we need to standardize the input features\n",
    "        X = meanImage.select(featureList)\n",
    "        y = meanImage.select(response_band)\n",
    "        \n",
    "        # Standardize the input features\n",
    "        X = X.divide(X.reduceRegion(reducer=ee.Reducer.stdDev(), bestEffort=True, maxPixels=max_pixels).toImage(featureList))\n",
    "        \n",
    "        return X.addBands(y)\n",
    "\n",
    "    \n",
    "    scaledImage = scale_image(inputImage, responseBand)\n",
    "    \n",
    "    \n",
    "    def ee_LARS(input_image, input_bandNames, response_bandName, num_nonzero_coefficients, num_samples):\n",
    "        image = ee.Image(input_image)\n",
    "        feature_list = ee.List(input_bandNames)\n",
    "        response_band = ee.String(response_bandName)\n",
    "        full_band_list = ee.List(feature_list).add(response_band)\n",
    "        num_nonzero_coefficients = ee.Number(num_nonzero_coefficients)\n",
    "        num_samples = ee.Number(num_samples)\n",
    "        def get_num_pixels(image):\n",
    "    \n",
    "            # get image height\n",
    "            def get_height(image):\n",
    "                height = image.getInfo()[\"bands\"][0][\"dimensions\"][0]\n",
    "                return height\n",
    "\n",
    "            # get image width\n",
    "            def get_width(image):\n",
    "                width = image.getInfo()[\"bands\"][0][\"dimensions\"][1]\n",
    "                return width\n",
    "\n",
    "            image_height = get_height(image)\n",
    "            image_width = get_width(image)\n",
    "            image_pixels = image_height*image_width\n",
    "\n",
    "            return image_pixels\n",
    "        image_pixels = ee.Number(get_num_pixels(image))\n",
    "        \n",
    "        # Randomly sample pixels in the image at native resolution into a FeatureCollection\n",
    "        input_collection = image.sample(numPixels=num_samples.min(image_pixels))\n",
    "        n = input_collection.size()\n",
    "        m = feature_list.length()\n",
    "        \n",
    "        # Use an aggregate array function over the FeatureCollection and map the function over each feature in the band list\n",
    "        # to generate a dictionary of all of the samples retrieved\n",
    "        inputs = ee.Dictionary.fromLists(full_band_list, full_band_list.map(lambda feature: input_collection.aggregate_array(feature)))\n",
    "        \n",
    "        # Although we may call our scale_image function on the input image, the reduceRegion() function used to determine the mean\n",
    "        # and standard deviation of each band in the image over the entire region is not precise enough over a large image\n",
    "        # so we must recenter all of the bands in the image and now we can also normalize (L2 norm) each input feature as required\n",
    "        # by the LARs algorithm\n",
    "        \n",
    "        # Use an aggregate_mean function over the feature collection to get the mean of each band\n",
    "        input_means = ee.Dictionary.fromLists(full_band_list, full_band_list.map(lambda feature: input_collection.aggregate_mean(feature)))\n",
    "\n",
    "        def centre_inputs(key, value):\n",
    "            key_mean = input_means.getNumber(key)\n",
    "            return ee.List(value).map(lambda sample: ee.Number(sample).subtract(key_mean))\n",
    "        \n",
    "        \n",
    "        # Center bands by mapping over the list of features and then a subtracting over the list of samples for each band\n",
    "        inputs = inputs.map(centre_inputs)\n",
    "\n",
    "        # Separate the response variable samples into its own vector\n",
    "        y = inputs.toArray([response_band]).reshape([-1,1])\n",
    "\n",
    "        # Remove response band from the feature collection by selecting only bands in the feature list\n",
    "        inputs = inputs.select(feature_list)\n",
    "        \n",
    "        # Generate a dictionary of all of the L2 norms of the input features using a custom mapped function\n",
    "        input_norms = inputs.map(lambda key, value: ee.Number(ee.List(value).map(lambda sample: ee.Number(sample).pow(2)).reduce(ee.Reducer.sum())).pow(0.5))\n",
    "\n",
    "        def norm_inputs(key, value):\n",
    "            key_norm = input_norms.getNumber(key)\n",
    "            return ee.List(value).map(lambda sample: ee.Number(sample).divide(key_norm))\n",
    "        \n",
    "        # Normalize all of the features by mapping a function over the list of features\n",
    "        # and then map a division over the list of all of the samples of the feature\n",
    "        inputs = inputs.map(norm_inputs)\n",
    "        \n",
    "        # Generate the array of samples using the dictionary\n",
    "        X = inputs.toArray(feature_list).transpose()\n",
    "\n",
    "        # Find the first best predictor of the response to initialize the main LARs loop\n",
    "        initial_prediction = ee.Array(ee.List.repeat([0], n))\n",
    "        c = X.transpose().matrixMultiply(y.subtract(initial_prediction))\n",
    "        c_abs = c.abs()\n",
    "        C_maxLoc = c_abs.project([0]).argmax()\n",
    "        add_feature = C_maxLoc.getNumber(0)\n",
    "        A = ee.List([add_feature])\n",
    "        \n",
    "        # Create a dicitionary of initial inputs to pass into the main LARs iterative loop\n",
    "        # The iterate function in Earth Engine processes each iteration as a tree of iterations with no access to any variables\n",
    "        # from previous iterations (only those that are passed to the next iteration)\n",
    "        # so we must pass both the current prediction and the active set of features (with non-zero coefficients), A\n",
    "        initial_inputs = ee.Dictionary({'prediction': initial_prediction, 'A': A})\n",
    "\n",
    "        def LARs_regression(iteration, inputs):\n",
    "            inputs = ee.Dictionary(inputs)\n",
    "\n",
    "            # Find the active set of features, A (predictors with non-zero coefficients)\n",
    "            A = ee.List(inputs.get('A'))\n",
    "            # A_list is an array used to mask the full array of input samples and the correlation vector\n",
    "            A_list = ee.Array(ee.List.sequence(0, m.subtract(1))\\\n",
    "                              .map(lambda index: A.contains(index)).replaceAll(False, 0).replaceAll(True, 1)).reshape([-1,1])\n",
    "\n",
    "            # The following matrix algebra determines the next most correlated variable, or the next best predictor considering the\n",
    "            # current features in the active set, A, as well as the magnitude to adjust the prediction vector to ensure all of the\n",
    "            # features in the active set are equally correlated to response vector\n",
    "            prediction = inputs.getArray('prediction')\n",
    "            c = X.transpose().matrixMultiply(y.subtract(prediction))\n",
    "            c_abs = c.abs()\n",
    "            C_max = c_abs.get(c_abs.argmax())\n",
    "            s_A = c.divide(c_abs).mask(A_list)\n",
    "            X_A = X.mask(A_list.transpose())\n",
    "            G_Ai = X_A.transpose().matrixMultiply(X_A).matrixInverse()\n",
    "            G1 = G_Ai.matrixMultiply(s_A)\n",
    "            A_A = s_A.project([0]).dotProduct(G1.project([0])).pow(-0.5)\n",
    "            w_A = G1.multiply(A_A)\n",
    "            u_A = X_A.matrixMultiply(w_A)\n",
    "            a = X.transpose().matrixMultiply(u_A)\n",
    "            a = a.project([0])\n",
    "            c = c.project([0])\n",
    "\n",
    "            def compute_gammaArray(index_j):\n",
    "                minus_j = C_max.subtract(c.get([index_j])).divide(A_A.subtract(a.get([index_j])))\n",
    "                plus_j = C_max.add(c.get([index_j])).divide(A_A.add(a.get([index_j])))\n",
    "                return ee.List([minus_j, plus_j]).filter(ee.Filter.gte('item', 0)).reduce(ee.Reducer.min())\n",
    "\n",
    "            A_c = ee.List.sequence(0, m.subtract(1)).removeAll(A)\n",
    "            gammaArray = A_c.map(compute_gammaArray)\n",
    "            gamma = gammaArray.reduce(ee.Reducer.min())\n",
    "            min_location = gammaArray.indexOf(gamma)\n",
    "            add_feature = A_c.getNumber(min_location)\n",
    "\n",
    "            # Update active set of variables with next best predictor from non-active set and update prediction vector\n",
    "            A = A.add(add_feature)\n",
    "            prediction = prediction.add(u_A.multiply(gamma))\n",
    "\n",
    "            return ee.Dictionary({'prediction': prediction, 'A': A})\n",
    "\n",
    "\n",
    "        # The final iteration of LARs (if selecting all input variables) requires a different method to determine magnitude for\n",
    "        # adjusting the magnitude of the prediction vector, as the regular LARs iteration relies on variables in non-active set\n",
    "        # In the final iteration there will be no variables in the non-active set, so the method will not work\n",
    "        def LARs_final_iteration(iteration, inputs):\n",
    "            inputs = ee.Dictionary(inputs)\n",
    "            A = ee.List(inputs.get('A'))\n",
    "\n",
    "            prediction = inputs.getArray('prediction')\n",
    "            c = X.transpose().matrixMultiply(y.subtract(prediction))\n",
    "            c_abs = c.abs()\n",
    "            C_max = c_abs.get(c_abs.argmax())        \n",
    "\n",
    "            s_A = c.divide(c_abs)\n",
    "            G_Ai = X.transpose().matrixMultiply(X).matrixInverse()\n",
    "            G1 = G_Ai.matrixMultiply(s_A)\n",
    "            A_A = s_A.project([0]).dotProduct(G1.project([0])).pow(-0.5)\n",
    "            w_A = G1.multiply(A_A)\n",
    "            u_A = X.matrixMultiply(w_A)\n",
    "\n",
    "            gamma = C_max.divide(A_A)\n",
    "            prediction = prediction.add(u_A.multiply(gamma))\n",
    "\n",
    "            return ee.Dictionary({'prediction': prediction, 'A': A})\n",
    "\n",
    "        # Actually carrying out the iterations by iterating over a placeholder list (sequence from 1 to the number of non-zero\n",
    "        # variables that the user wishes to select as predictors for the response)\n",
    "        iterations = ee.List.sequence(1, m.subtract(1).min(num_nonzero_coefficients))\n",
    "        penultimate_outputs = iterations.iterate(LARs_regression, initial_inputs)\n",
    "        final_outputs = ee.Dictionary(ee.Algorithms.If(num_nonzero_coefficients.gte(m), \\\n",
    "                                LARs_final_iteration(m, penultimate_outputs), penultimate_outputs))\n",
    "        \n",
    "        final_prediction = final_outputs.getArray('prediction')\n",
    "\n",
    "        A = ee.List(final_outputs.get('A'))\n",
    "\n",
    "        feature_path = A.slice(0, num_nonzero_coefficients).map(lambda index: feature_list.getString(index))        \n",
    "        return feature_path\n",
    "\n",
    "    \n",
    "    select_features = ee_LARS(scaledImage, input_bandNames, responseBand, 5, 50000)\n",
    "    #unclassified = ee.Image(cloud_folder+'/'+siteSelect+'_'+outputName+'_VI')\n",
    "    unclassified = ee.Image(inputImage)\n",
    "    # bands = ee.List([responseBand, 'GI', 'SGI', 'GVI', 'NDVI3', 'NDVI', 'GNDVI', 'NDGI',\n",
    "    #                  'EVI', 'EVI2', 'RDVI', 'MSR', 'MSAVI2', 'NLI', 'B2', 'B3', 'B4', 'B8',\n",
    "    #                  'QA60', 'date', 'partition', 'networkID', 'error'+outputName, 'partition_1', 'networkID_1'])\n",
    "    bands = ee.List([responseBand, 'GI', 'SGI', 'GVI', 'NDVI3', 'NDVI', 'GNDVI', 'NDGI',\n",
    "                     'EVI', 'EVI2', 'RDVI', 'MSR', 'MSAVI2', 'NLI', 'B2', 'B3', 'B4', 'B8',\n",
    "                     'partition', 'networkID', 'error'+outputName, 'partition_1', 'networkID_1'])\n",
    "    unclassified = unclassified.rename(bands)\n",
    "\n",
    "    # prediction bands (equivalent to select_features, with responseBand)\n",
    "    bands = select_features\n",
    "    input_bands = select_features.add(responseBand)\n",
    "    training_data = ee.FeatureCollection(unclassified.sample(numPixels=1000, seed=1).select(input_bands))\n",
    "    # implement regression tree with Random Forest algorithm\n",
    "    # optional parameters for smileRandomForest(): variablesPerSplit, minLeafPopulation, bagFraction, maxNodes, seed\n",
    "    # rf_classifier = ee.Classifier.smileRandomForest(100).setOutputMode('REGRESSION').train(features=training_data,\n",
    "    #                                                                                        classProperty=responseBand,\n",
    "    #                                                                                        inputProperties=input_bands)\n",
    "    # rf_classified = unclassified.select(bands).classify(rf_classifier, 'ALR_'+responseBand).clip(mapBounds)\n",
    "   \n",
    "    defVis = {\n",
    "      min: -100,\n",
    "    }\n",
    "\n",
    "    rf_classified = smileRandomForestU(unclassified, training_data, bands, 100,input_bands,responseBand,defVis)\n",
    "    rf_classified.clip(mapBounds)\n",
    "    return temp_image.addBands(rf_classified)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "## use a biophysical parameter result as an input\n",
    "\n",
    "parent_directory = 'users/ccrs12fy2022simha/DOWNSCALING_PROCESS/3_DSEN2_S2/SOL_A/'\n",
    "\n",
    "#use = \n",
    "assetname='20190826T153819_20190826T154455_T18TYN_HOPB_LAI_DSen2_20m_net'\n",
    "#assetname='20210808T154809_20210808T155521_T18SUJ_SERC_LAI_DSen2_20m_net'\n",
    "# assetname='20190608T164849_20190608T165019_T15TYL_STEI_LAI_DSen2_20m_net'\n",
    "# assetname='20190606T165901_20190606T170333_T16TCS_UNDE_LAI_DSen2_20m_net'\n",
    "# assetname='20200713T170901_20200713T171937_T14SQJ_MCDI_LAI_DSen2_20m_net'\n",
    "# assetname='20210422T162829_20210422T163638_T16SCA_LENO_LAI_DSen2_20m_net'\n",
    "# assetname=20200627T173909_20200627T174744_T14TLS_NOGP_LAI_DSen2_20m_net'\n",
    "# assetname='20190822T173909_20190822T175453_T13SCS_JORN_LAI_DSen2_20m_net'\n",
    "# assetname='20210401T183919_20210401T184709_T11SKB_SJER_LAI_DSen2_20m_net'\n",
    "\n",
    "#ABBY, HOPB, SERC, STEI, UNDE, MCDI,LENO, NOGP,JORN, SJER\n",
    "\n",
    "#example\n",
    "# assetname='users/GangHong2/Dsen/20210719T190919_20210719T191700_T10TER_ABBY_LAI_DSen2_20m_net'\n",
    "\n",
    "len_parent_directory = len(parent_directory)\n",
    "img=ee.Image(parent_directory+assetname)\n",
    "mapBounds=img.geometry()\n",
    "# print(output_Name)\n",
    "output_Name=assetname[len_parent_directory:]+'_ALR' ### index number neeed to be adjusted to get the meaningful file name '20210719T190919_20210719T191700_T10TER_ABBY_LAI_DSen2_20m_net_ALR'20210401T183919_20210401T184709_T11SKB_SJER_LAI_DSen2_20m_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputName = 'LAI'\n",
    "responseBand = 'estimate'+outputName\n",
    "ALR_result=func_ALR(img, responseBand, outputName, mapBounds)\n",
    "# print (ALR_result.bandNames().getInfo())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export formatted image to GEE asset \n",
    "# assetfolder='users/GangHong2/ALR'\n",
    "export = ee.ImageCollection(ALR_result)\n",
    "export_task = ee_func.export_collection_to_gee(collection=export,\n",
    "                                                 num_images=1,                                                                                              \n",
    "                                                 # image_names=[siteSelect+'_'+outputName+'_ALR'],\n",
    "                                                 image_names=[output_Name],\n",
    "                                                 asset_folder=assetfolder_SOL_C_U,                                                 \n",
    "                                                 scale=10,\n",
    "                                                 data_type='float',\n",
    "                                                 max_pixels=1e13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2 - Neural network predictor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 2.1 - Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mlp for regression\n",
    "from numpy import sqrt\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "# from tensorflow.keras.layers import MaxPooling1D\n",
    "\n",
    "# load the dataset\n",
    "# path = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/housing.csv'\n",
    "path = 'C:/Users/nkalimip/Downloads/Estimate_prediction_process/uncertanity_example/information/ABBY_LAI_trainingdata.csv'\n",
    "df_ = read_csv(path)#, header=None)\n",
    "df_ = df_[[\"B3\",  \"B4\",  \"GVI\", \"NDVI\",  \"NLI\",  \"estimateLAI\"]]\n",
    "df_.to_csv('C:/Users/nkalimip/Downloads/Estimate_prediction_process/uncertanity_example/information/ABBY_LAI_trainingdata2.csv')\n",
    "df = read_csv('C:/Users/nkalimip/Downloads/Estimate_prediction_process/uncertanity_example/information/ABBY_LAI_trainingdata2.csv',header=None)\n",
    "df = df.iloc[1:]\n",
    "\n",
    "\n",
    "#normallize\n",
    "from sklearn import preprocessing\n",
    "import pandas as pd\n",
    "\n",
    "# d = preprocessing.normalize(df)\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "d = scaler.fit_transform(df)\n",
    "\n",
    "df = pd.DataFrame(d, columns=df.columns)\n",
    "print(df)\n",
    "\n",
    "\n",
    "\n",
    "#split into input and output columns\n",
    "X, y = df.values[:, :-1], df.values[:, -1]\n",
    "\n",
    "print(df)\n",
    "X = np.asarray(X).astype('float32')\n",
    "y = np.asarray(y).astype('float32')\n",
    "\n",
    "# split into train and test datasets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
    "\n",
    "# determine the number of input features\n",
    "n_features = X_train.shape[1]\n",
    "# print(X_train.shape[1])\n",
    "# define model\n",
    "model = Sequential()\n",
    "model.add(Dense(20, activation='relu', kernel_initializer='he_normal', input_shape=(n_features,)))\n",
    "model.add(Dense(20, activation='relu', kernel_initializer='he_normal'))\n",
    "# model.add(MaxPooling1D(2))\n",
    "model.add(Dense(1))\n",
    "\n",
    "# compile the model\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "# fit the model\n",
    "model.fit(X_train, y_train, epochs=150, batch_size=32, verbose=0)\n",
    "# evaluate the model\n",
    "error = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('MSE: %.3f, RMSE: %.3f' % (error, sqrt(error)))\n",
    "# # make a prediction\n",
    "# # row = [0.00632,18.00,2.310,0,0.5380,6.5750,65.20,4.0900,1,296.0,15.30,396.90,4.98]\n",
    "row =  [0.00, 0.16, 0.08, 0.58, 0.91, 0.78]\n",
    "# row = [1.00,  0.022062358 , 0.009950795,  6.067018173,  0.880013956,  0.419106492]   \n",
    "yhat = model.predict([row])\n",
    "print('Predicted: %.3f' % yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 2.2 - Tensorflow Probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
