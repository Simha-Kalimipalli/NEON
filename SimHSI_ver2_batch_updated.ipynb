{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "94fe1344-2809-4b3b-8a2b-976a6b1a6797",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import interpolate\n",
    "import numpy as np\n",
    "import h5py\n",
    "import pandas as pd\n",
    "from osgeo import gdal, osr\n",
    "#import gdal, osr\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import os\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9f8d20c3-3e9d-4d32-b1bf-38524e54119e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### function for saving a geotiff file\n",
    "def CreateGeoTiff(Name, Array, driver, NDV, \n",
    "                  GeoT, Projection, DataType):\n",
    "    Array[np.isnan(Array)] = NDV \n",
    "    DataSet = driver.Create(Name, Array.shape[2], Array.shape[1], Array.shape[0], DataType)  ## col, row, bands\n",
    "    DataSet.SetGeoTransform(GeoT)\n",
    "    DataSet.SetProjection( Projection.ExportToWkt() )\n",
    "    # for i in range(Array.shape[2]):\n",
    "    for i in range(Array.shape[0]):       \n",
    "        # DataSet.GetRasterBand(i+1).WriteArray(Array[:,:,i] )\n",
    "        DataSet.GetRasterBand(i+1).WriteArray(Array[i,:,:] )\n",
    "        DataSet.GetRasterBand(i+1).SetNoDataValue(NDV)\n",
    "    DataSet.FlushCache()\n",
    "    return Name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc909ef7-bcfe-44a4-910f-d849b22fc64d",
   "metadata": {},
   "source": [
    "## Read S2 SRF from csv file and prepare S2 SRF array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "74165019-ac5e-4ae8-ab26-00e1fe228bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('S2-SRF_COPE-GSEG-EOPG_S2B.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "64fdac1f-5167-4cd9-9937-66760d7a1430",
   "metadata": {},
   "outputs": [],
   "source": [
    "S2_B= {}\n",
    "for i in  range (1,len(df.columns)):   \n",
    "    S2_B[i-1]= list(zip(df.loc[:,df.columns[0]],df.loc[:,df.columns[i]]))\n",
    "    S2_B[i-1] = {key:val for key, val in list(S2_B[i-1]) if val != 0.0} ## remove all 0 in the value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "579a1e81-5017-41a7-904f-24d6a8113cb0",
   "metadata": {},
   "source": [
    "## loading NEON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "7d3814c9-afd5-465c-a29d-3f7b8195b36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_dir='K:\\\\neon\\\\ABBY\\\\NEON.D16.ABBY.DP1.30006.001.2019-07.basic.20221114T164907Z.RELEASE-2022\\\\'\n",
    "\n",
    "# file_dir='E:\\\\NEON_refl-surf-dir-ortho-lin0e\\\\NEON_refl-surf-dir-ortho-line\\\\NEON.D16.ABBY.DP1.30006.001.2021-07.basic.20221124T030111Z.PROVISIONAL\\\\'\n",
    "file_dir='H:\\\\neon\\\\valid\\\\image\\\\DSNY\\\\'\n",
    "# out_dir='K:\\\\neon\\\\ABBY\\\\NEON.D16.ABBY.DP1.30006.001.2019-07.basic.20221114T164907Z.RELEASE-2022\\\\kml_updated\\\\'\n",
    "# out_dir='E:\\\\NEON_refl-surf-dir-ortho-lin0e\\\\NEON_refl-surf-dir-ortho-line\\\\NEON.D16.ABBY.DP1.30006.001.2021-07.basic.20221124T030111Z.PROVISIONAL\\\\tif\\\\'\n",
    "out_dir='H:\\\\neon\\\\valid\\\\image\\\\DSNY\\\\tif\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "626ae8b7-07e9-4584-b5bb-1abb070136cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(out_dir):\n",
    "    os.makedirs(out_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "7363f169-bb41-45d4-8bc6-74e870b19a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "site='DSNY'\n",
    "S2_Bands=13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "2ee5e037-bd30-43b6-a2b2-5229cc9853ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEON_D03_DSNY_DP1_20210927_165253_reflectance\n",
      "0:18:46.327530\n",
      "H:\\neon\\valid\\image\\DSNY\\tif\\NEON_D03_DSNY_DP1_20210927_165253_reflectance.tif\n",
      "NEON_D03_DSNY_DP1_20210927_165827_reflectance\n",
      "0:20:57.886065\n",
      "H:\\neon\\valid\\image\\DSNY\\tif\\NEON_D03_DSNY_DP1_20210927_165827_reflectance.tif\n",
      "NEON_D03_DSNY_DP1_20210927_170433_reflectance\n",
      "0:19:10.133433\n",
      "H:\\neon\\valid\\image\\DSNY\\tif\\NEON_D03_DSNY_DP1_20210927_170433_reflectance.tif\n"
     ]
    }
   ],
   "source": [
    "for file in os.listdir(file_dir):\n",
    "    if file.endswith('.h5'):\n",
    "        print (file[:-3])\n",
    "        # print (out_dir+file[:-3]+'.tif')\n",
    "        # print(os.path.basename(file))\n",
    "        # with open(file_dir+file) as f5h:\n",
    "        \n",
    "        ##Load NEON and extract parameters from h5 file\n",
    "        f=h5py.File(file_dir+file,rdcc_nbytes =1024**2*10000,rdcc_nslots=1e7)\n",
    "        Ref = f[site]['Reflectance']\n",
    "        RefArray = Ref['Reflectance_Data']\n",
    "        Ref_shape = RefArray.shape\n",
    "        MapInfo = Ref['Metadata']['Coordinate_System']['Map_Info']\n",
    "        epsg_code = int(Ref['Metadata']['Coordinate_System']['EPSG Code'][()]) ### epsg, convert byte to int\n",
    "        noDataValue =RefArray.attrs['Data_Ignore_Value']\n",
    "        scaleFactor = RefArray.attrs['Scale_Factor']\n",
    "        wavelengths = Ref['Metadata']['Spectral_Data']['Wavelength']\n",
    "        neonwave=wavelengths[()] ## NEON wavelength\n",
    "        flighttime = Ref['Metadata']['Flight_Trajectory']['Flight_Time']\n",
    "        \n",
    "        ##Prepare angle parameters\n",
    "        Solar_Az = Ref['Metadata']['Logs']['Solar_Azimuth_Angle'][()] ## The solar azimuth angle , single value\n",
    "        Solar_Zen = Ref['Metadata']['Logs']['Solar_Zenith_Angle'][()] ## The solar zenith angle , single value\n",
    "        ToSensor_Zen= Ref['Metadata']['to-sensor_Zenith_Angle']   ##  The to-sensor zenith angle from the platform, array\n",
    "        ToSensor_Az = Ref['Metadata']['to-sensor_Azimuth_Angle'] ## The to-sensor azimuth angle from the platform,array\n",
    "\n",
    "        ToSensor_Az_np=np.asarray(ToSensor_Az) ### from h5 to numpy array\n",
    "        ToSensor_Zen_np=np.asarray(ToSensor_Zen) ### from h5 to numpy array\n",
    "        ToSensor_Az_np[ToSensor_Az_np==-9999.]=np.nan ## assign nan to -9999.  \n",
    "        ToSensor_Zen_np[ToSensor_Zen_np==-9999.]=np.nan ## assign nan to -9999.\n",
    "        ToSensor_Zen_np=np.radians(ToSensor_Zen_np) ## convert to radians\n",
    "        \n",
    "        cosVZA=np.cos(ToSensor_Zen_np)  ##vza: 'MEAN_INCIDENCE_ZENITH_ANGLE',\n",
    "        Solar_Zen_np=np.copy(ToSensor_Zen_np) ### get a copy of angle file with same nan\n",
    "        Solar_Zen_np[~np.isnan(Solar_Zen_np)]=Solar_Zen  ### assign a single value solar zenith angle to the array not nan\n",
    "        Solar_Zen_np=np.radians(Solar_Zen_np) ## convert to radian\n",
    "        cosSZA=np.cos(Solar_Zen_np)  ## sza: 'MEAN_SOLAR_ZENITH_ANGLE',\n",
    "        Solar_Az_np=np.copy(ToSensor_Az_np) ### get a copy of angle file with same nan\n",
    "        Solar_Az_np[~np.isnan(Solar_Az_np)]=Solar_Az  ### assign a single value solar azimuth angle to the array not nan\n",
    "        # cosRAA=np.cos(np.abs(np.subtract(Solar_Az_np,ToSensor_Az_np)))\n",
    "        cosRAA=np.cos(np.radians(np.abs(np.subtract(Solar_Az_np,ToSensor_Az_np))))\n",
    "        angles=np.stack((cosVZA,cosSZA,cosRAA), axis=0) ## stack angles\n",
    "        \n",
    "        \n",
    "        ##interpolate S2 from Nenon wavelenth\n",
    "        neon_S2_B=np.zeros(shape=(13,426))\n",
    "        for i in range(13):\n",
    "            neon_S2_B[i]=np.interp(neonwave,np.fromiter(S2_B[i].keys(), dtype=float), np.fromiter(S2_B[i].values(), dtype=float), 0, 0)\n",
    "        # Sim_Output=np.zeros(shape=(Ref_shape[0],Ref_shape[1],S2_Bands))\n",
    "        Sim_Output=np.zeros(shape=(S2_Bands,Ref_shape[0],Ref_shape[1]))\n",
    "\n",
    "        # t1=datetime.now()\n",
    "        # for j in range(Ref_shape[1]):                \n",
    "        #     temp=RefArray[:,j,:]# get one row of the array to make the process faster\n",
    "        #     for i in range(Ref_shape[0]):                \n",
    "        #         # pixel_vec = RefArray[i,j,:].astype(np.float); ## get the pixel vector for data cube\n",
    "        #         pixel_vec = temp[i,:].astype(np.float); ## get the pixel vector for data cube\n",
    "        #         pixel_vec[pixel_vec==int(noDataValue)]=np.nan; ## assign np.nan to no data \n",
    "        #         pixel_vec=pixel_vec/scaleFactor; ## divide by scalefactor \n",
    "        #         for k in range(S2_Bands):            \n",
    "        #             Sim_Output[i][j][k]=np.dot(pixel_vec,neon_S2_B[k])/(np.count_nonzero(neon_S2_B[k])); ### pixel_vec dot production with SRF, divided by the number of bands falling in this band seperacal range.\n",
    "        # t2=datetime.now()         \n",
    "        # print (t2-t1)\n",
    "        \n",
    "        t1=datetime.now()\n",
    "        if (Ref_shape[1]>Ref_shape[0]):   ## 'width>height')\n",
    "            # print ('width>height')\n",
    "            for j in range(Ref_shape[1]):\n",
    "            # if (j%100==0):\n",
    "                # print ('j=',j)\n",
    "                temp=RefArray[:,j,:]# get one row of the array to make the process faster\n",
    "                for i in range(Ref_shape[0]):\n",
    "                    # if (j%100==0):\n",
    "                    #     print ('j=',j)\n",
    "                    # pixel_vec = RefArray[i,j,:].astype(np.float); ## get the pixel vector for data cube\n",
    "                    pixel_vec = temp[i,:].astype(np.float); ## get the pixel vector for data cube\n",
    "                    pixel_vec[pixel_vec==int(noDataValue)]=np.nan; ## assign np.nan to no data \n",
    "                    pixel_vec=pixel_vec/scaleFactor; ## divide by scalefactor \n",
    "                    for k in range(S2_Bands):            \n",
    "                        # Sim_Output[i][j][k]=np.dot(pixel_vec,neon_S2_B[k])/(np.count_nonzero(neon_S2_B[k])); ### pixel_vec dot production with SRF, divided by the number of bands falling in this band seperacal range.\n",
    "                         Sim_Output[k][i][j]=np.dot(pixel_vec,neon_S2_B[k])/(np.count_nonzero(neon_S2_B[k])); ### pixel_vec dot production with SRF, divided by the number of bands falling in this band seperacal range.\n",
    "        else: ## 'height>width')\n",
    "            # print ('height>width')\n",
    "            for i in range(Ref_shape[0]):\n",
    "                temp=RefArray[i,:,:]# get one row of the array to make the process faster\n",
    "                for j in range(Ref_shape[1]):       \n",
    "                    #pixel_vec = RefArray[i,j,:].astype(np.float); ## get the pixel vector for data cube\n",
    "                    pixel_vec = temp[j,:].astype(np.float); ## get the pixel vector for data cube\n",
    "                    pixel_vec[pixel_vec==int(noDataValue)]=np.nan; ## assign np.nan to no data \n",
    "                    pixel_vec=pixel_vec/scaleFactor; ## divide by scalefactor \n",
    "                    for k in range(S2_Bands):            \n",
    "                        Sim_Output[k][i][j]=np.dot(pixel_vec,neon_S2_B[k])/(np.count_nonzero(neon_S2_B[k])); ### pixel_vec dot production with SRF, divided by the number of bands falling in this band seperacal range.\n",
    "        t2=datetime.now()         \n",
    "        print (t2-t1)    \n",
    "        \n",
    "        Result_output=np.append(Sim_Output, angles, axis=0)  ### merge band results and angles\n",
    "\n",
    "        ##Prepare coordinate information for outputting file\n",
    "        MapInfo_string = str(MapInfo[()]) #convert to string\n",
    "        MapInfo_split = MapInfo_string.split(\",\") #split the strings using the separator \",\" \n",
    "        # print(MapInfo_split)\n",
    "        xres = float(MapInfo_split[5])\n",
    "        yres=float(MapInfo_split[6])\n",
    "        # print('Resolution:',xres,yres)\n",
    "        #Extract the upper left-hand corner coordinates from mapInfo\n",
    "        xMin = float(MapInfo_split[3]) \n",
    "        yMax = float(MapInfo_split[4])\n",
    "\n",
    "        ## set the projection information \n",
    "        srs = osr.SpatialReference()         \n",
    "        srs.ImportFromEPSG(epsg_code) \n",
    "        geotransform=(xMin,xres,0,yMax,0, -yres) \n",
    "        data_type = gdal.GDT_Float32\n",
    "        driver = gdal.GetDriverByName('GTiff')\n",
    "        print (out_dir+file[:-3]+'.tif')\n",
    "        ## output 1m tiff file\n",
    "        CreateGeoTiff(out_dir+file[:-3]+'.tif', Result_output, driver, -9999, geotransform, srs, data_type)  \n",
    "        ## resample to 10m tiff file\n",
    "        raster_rprj = gdal.Warp(out_dir+file[:-3]+'_10m.tif', out_dir+file[:-3]+'.tif', xRes=10, yRes=10, resampleAlg = \"average\")\n",
    "        raster_rprj = None\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3224709f-3c09-4391-b243-a637a92c1071",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
